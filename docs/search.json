[
  {
    "objectID": "tutorials/s1-introductory-r-session.html",
    "href": "tutorials/s1-introductory-r-session.html",
    "title": "Erste Schritte mit R",
    "section": "",
    "text": "Der folgende Abschnitt soll einen ersten Eindruck vermitteln, was R (R Core Team, 2021) ist und wie es funktioniert. Es wird davon ausgegangen, dass die folgende Software installiert ist:\n\nDas R-System für statistische Berechnungen: https://www.r-project.org\nR Studio, ein Programm, das die Arbeit mit R vereinfacht: https://www.rstudio.org\n\nAnmerkung: Bitte installiere zuerst R bevor du RStudio installierst.\nEin gutes Beispiel für den Anfang ist das kurze Video „R tutorial - The True Basics of R“ von DataCamp, siehe https://youtu.be/SWxoJqTqo08. Außerdem bietet Datacamp ausgezeichnete R-Kurse, die zum Teil sogar kostenlos sind. Ein weiteres nützliches R-Tutorial gibt es bei W3Schools.com.",
    "crumbs": [
      "Tutorials",
      "Erste Schritte mit R"
    ]
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#programmstart-und-hilfesystem",
    "href": "tutorials/s1-introductory-r-session.html#programmstart-und-hilfesystem",
    "title": "Erste Schritte mit R",
    "section": "2.1 Programmstart und Hilfesystem",
    "text": "2.1 Programmstart und Hilfesystem\nDer einfachste Weg, R zu erlernen, ist das kreative Verstehen und Abwandeln von gegebenen Beispielen, die Verwendung von R zur Lösung praktischer Probleme und die Diagnose von Warnungen und Fehlermeldungen. Keine Sorge: Fehlermeldungen sind ein normales Phänomen im wissenschaftlichen Rechnen und kein Hinweis auf eine Funktionsstörung des Computers oder des menschlichen Gehirns. Das Gegenteil ist der Fall: Ein gewisses Maß an Stresshormonen hilft, dauerhafte Lerneffekte zu erzielen. Nach einer gewissen Erfahrung ist dann die offizielle R-Dokumentation „An Introduction to R“ (Venables et al., 2021) oder ein gutes R-Buch sehr zu empfehlen.\nDie ersten Abschnitte dieses „Crashkurses“ sollen einen Überblick über einige der wichtigsten Elemente von R und einen Einblick in einen typischen Arbeitsablauf geben, der für die ersten statistischen Analysen und als Ausgangspunkt für die selbstständige Einarbeitung nützlich sein kann.\nWir beginnen unsere erste Sitzung mit dem Start von RStudio, einer plattformunabhängigen Benutzerumgebung, die das Arbeiten mit R erleichtert. RStudio unterteilt den Bildschirm in 3 (bzw. 4) Fenster (sogenannte Panes), von denen einige zusätzliche Tabs haben, um zwischen verschiedenen Ansichten zu wechseln.\n\nAbbildung 1: R Studio mit 4 Fenstern. Benutze Datei – Neues R-Skript, um das Quellcode-Fenster zu öffnen (siehe oben links). Gib dann etwas Code ein und vergiss nicht, im Hilfesystem zu lesen.\nIn einer neuen RStudio-Sitzung sollte ein „Pane“ die Haupt-Hilfsseite von R sein. Es ist eine gute Idee, ein wenig herumzustöbern, um einen Eindruck über den Umfang und den typischen Stil der verfügbaren Hilfsthemen zu bekommen. Die wichtigsten Abschnitte sind „An Introduction to R“, „Search Engine & Keywords“, „Packages“, die „Frequently Asked Questions“ und eventuell „R Data Import/Export“.\nWir beginnen nun, das R-System selbst zu erkunden.",
    "crumbs": [
      "Tutorials",
      "Erste Schritte mit R"
    ]
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#r-als-taschenrechner",
    "href": "tutorials/s1-introductory-r-session.html#r-als-taschenrechner",
    "title": "Erste Schritte mit R",
    "section": "2.2 R als Taschenrechner",
    "text": "2.2 R als Taschenrechner\nWenn man einen arithmetischen Ausdruck eingibt:\n\n2 + 4\n\nsieht man, dass R als Taschenrechner verwendet werden kann, der das Ergebnis sofort ausgibt:\n\n\n[1] 6\n\n\nAnstatt das Ergebnis auf dem Bildschirm auszugeben, kann man das Ergebnis mit dem Zuweisungsoperator „&lt;-“ in einer benannten Variablen speichern:\n\na &lt;- 2 + 4\n\nEs scheint nichts zu passieren, aber das Ergebnis wird nun in der Variablen a gespeichert, die jederzeit durch Eingabe des Variablennamens allein aufgerufen werden kann:\n\na\n\nVariablennamen in R beginnen immer mit einem Buchstaben (oder für besondere Zwecke mit einem Punkt), gefolgt von weiteren Buchstaben, Ziffern, Punkten oder Unterstrichen. Es wird zwischen Klein- und Großbuchstaben unterschieden, d.h. die Variablen value, Value und VALUE können unterschiedliche Daten enthalten. Einige wenige Zeichenkombinationen sind reservierte Wörter und können nicht als Variablen verwendet werden:\nbreak, for, function, if, in, next, repeat, while und “...” (drei Punkte).\nAndere Bezeichner wie plot können umdefiniert werden, doch dies sollte mit Vorsicht geschehen, um unerwünschte Verwechslungen und Nebenwirkungen zu vermeiden.",
    "crumbs": [
      "Tutorials",
      "Erste Schritte mit R"
    ]
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#vektoren",
    "href": "tutorials/s1-introductory-r-session.html#vektoren",
    "title": "Erste Schritte mit R",
    "section": "2.3 Vektoren",
    "text": "2.3 Vektoren\nVielleicht hast du bemerkt, dass die Ausgabe des obigen Beispiels ein führendes [1] hat. Das bedeutet, dass die Zeile mit dem ersten Element von a beginnt. Dies bringt uns zu einer sehr wichtigen Eigenschaft von R, dass Variablen mehr als nur einzelne Werte enthalten können: Vektoren, Matrizen, Listen, Dataframes (Tabellen) und so weiter.\nDer grundlegendste Datentyp ist der Vektor, der mit Hilfe der Funktion „c“ (combine) mit Daten gefüllt werden kann:\n\nvalues &lt;- c(2, 3, 5, 7, 8.3, 10)\nvalues\n\n[1]  2.0  3.0  5.0  7.0  8.3 10.0\n\n\nUm eine Folge von Werten zu erstellen, kann man den : (Doppelpunkt) verwenden:\n\nx &lt;- 1:10\nx\n\noder, noch flexibler, die Funktion seq:\n\nx &lt;- seq(2, 4, 0.25)\nx\n\nSequenzen von wiederholten gleichen Werten können mit rep erzeugt werden:\n\nx &lt;- rep(2, 4)\nx",
    "crumbs": [
      "Tutorials",
      "Erste Schritte mit R"
    ]
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#übung",
    "href": "tutorials/s1-introductory-r-session.html#übung",
    "title": "Erste Schritte mit R",
    "section": "2.4 Übung",
    "text": "2.4 Übung\nEs gibt viele Möglichkeiten, diese Funktionen zu verwenden, versuche zum Beispiel:\n\nseq(0, 10)\nseq(0, 10, by = 2)\nseq(0, pi, length = 12)\nrep(c(0, 1, 2, 4, 9), times = 5)\nrep(c(0, 1, 2, 4, 9), each = 2)\nrep(c(0, 1, 2, 4, 9), each = 2, times = 5)",
    "crumbs": [
      "Tutorials",
      "Erste Schritte mit R"
    ]
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#zugriff-auf-vektorelemente",
    "href": "tutorials/s1-introductory-r-session.html#zugriff-auf-vektorelemente",
    "title": "Erste Schritte mit R",
    "section": "2.5 Zugriff auf Vektorelemente",
    "text": "2.5 Zugriff auf Vektorelemente\nAnstatt auf Vektoren als Ganzes zuzugreifen, ist es auch möglich, einzelne Elemente zu extrahieren, wobei der Index der angeforderten Daten ebenfalls ein Vektor sein kann:\n\nvalues[5]\nvalues[2:4]\nvalues[c(1, 3, 5)]\n\nManchmal haben die Elemente eines Vektors individuelle Namen, was den Zugriff erleichtert:\n\nnamed &lt;- c(a = 1, b = 2.3, c = 4.5)\nnamed\nnamed[\"a\"]\n\nIn R (und im Gegensatz zu anderen Sprachen wie C/C++) beginnen Vektorindizes mit 1. Negative Indizes sind ebenfalls möglich, haben aber den speziellen Zweck, ein oder mehrere Elemente zu löschen:\n\nvalues[-3]\n\nEs ist auch möglich, einen gegebenen Vektor durch Voranstellen oder Anhängen von Werten mit der Combine-Funktion (c) zu erweitern:\n\nc(1, 1, values, 0, 0)\n\nDie Länge eines Vektors kann mit der Funktion length ermittelt werden:\n\nlength(values)\n\nAuch leere Vektoren sind möglich, d. h. Vektoren, die zwar existieren, aber keine Werte enthalten. Hier bedeutet das Schlüsselwort NULL „nichts“ im Gegensatz zu „0“ (Null), was die Länge 1 hat:\n\nvalues &lt;- NULL\nvalues\nlength(values)\n\nSolche leeren Vektoren werden manchmal als „Container“ zum schrittweisen Anhängen von Daten verwendet:\n\nvalues &lt;- NULL\nvalues\nlength(values)\nvalues &lt;- c(values, 1)\nvalues\nvalues &lt;- c(values, 1.34)\nvalues\n\nSoll ein Datenelement vollständig entfernt werden, so kann dies mit der Funktion remove (kurz rm) geschehen:\nrm(values)\nvalues\nError: Object \"values\" not found\nDer gesamte Arbeitsbereich kann über das Menü von R oder RStudio (Session – Clear workspace) oder über die Kommandozeile mit rm (remove) gelöscht werden:\n\nrm(list = ls(all = TRUE))\n\nDie R-Sitzung kann wie gewohnt über das Menü oder durch Eingabe beendet werden:\n\nq()\n\nManchmal und abhängig von der Konfiguration fragt R, ob der „R Workspace“ auf der Festplatte gespeichert werden soll. Dies kann nützlich sein, um die Arbeit zu einem späteren Zeitpunkt fortzusetzen, birgt aber das Risiko, den Arbeitsbereich zu überladen und bei einer späteren Sitzung nicht reproduzierbare Ergebnisse zu erhalten, so dass es empfehlenswert ist, vorerst „Nein“ zu sagen, es sei denn, man weiß genau, warum.\nSpäter werden wir lernen, wie man nur die Daten (und Befehle) speichert, die benötigt werden.",
    "crumbs": [
      "Tutorials",
      "Erste Schritte mit R"
    ]
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#r-als-funktionsplotter",
    "href": "tutorials/s1-introductory-r-session.html#r-als-funktionsplotter",
    "title": "Erste Schritte mit R",
    "section": "3.1 R als Funktionsplotter",
    "text": "3.1 R als Funktionsplotter\nNun wollen wir sehen, wie man R als Funktionsplotter verwendet, indem man Sinus- oder Kosinusfunktionen innerhalb eines Intervalls zwischen 0 und 10 zeichnet. Zuerst erstellen wir zwei Vektoren mit x und y. Um eine glatte Kurve zu erhalten, ist es sinnvoll, eine kleine Schrittweite zu wählen. Als Faustregel empfehle ich immer, etwa 100…400 kleine Schritte zu verwenden. Das ist ein guter Kompromiss zwischen Glättung und Speicherbedarf. Im Folgenden setzen wir die Schrittweite deshalb auf 0.1:\n\nx &lt;- seq(0, 10, 0.1)\ny &lt;- sin(x)\nplot(x, y)\n\n\n\n\n\n\n\n\nAnstatt Punkte zu plotten, können wir auch durchgehende Linien zeichnen. Dies wird durch die Angabe eines optionalen Arguments angegeben type = \"l\".\nAnmerkung: das hier verwendete Symbol für type ist der kleine Buchstabe „L“ für ‘line’ und nicht die – im Druck sehr ähnliche – Zahl “1” (eins)!\nWir sehen auch, dass optionale Argumente wie type als „keyword = value“ Paar angegeben werden können. Dies hat den Vorteil, dass die Reihenfolge der Argumente keine Rolle spielt, da die Argumente durch ihren Namen referenziert werden:\n\nplot(x, y, type = \"l\")\n\nJetzt wollen wir eine Kosinusfunktion mit einer anderen Farbe zeichnen. Dies kann mit einer der Funktionen lines oder points erreicht werden, um Linien oder Punkte zu einem bestehenden Plot hinzuzufügen:\n\ny1 &lt;- cos(x)\nlines(x, y1, col = \"red\")\n\nMit Hilfe von text ist es auch möglich, beliebigen Text hinzuzufügen, indem man zuerst die x- und y-Koordinaten und dann den Text angibt:\n\nx1 &lt;- 1:10\ntext(x1, sin(x1), x1, col = \"green\")\n\nEs gibt noch viele weitere Optionen, um das Verhalten der Grafikfunktionen zu ändern. Im Folgenden werden benutzerdefinierte Koordinatengrenzen (xlim, ylim), Achsenbeschriftungen und eine Überschrift (xlab, ylab, main) angegeben:\n\nplot(x, y, xlim = c(-10, 10), ylim = c(-2, 2),\n    xlab = \"x-Values\", ylab = \"y-Values\", main = \"Example Graphics\")\n\nCodeformatierung und Zeilenumbrüche\nDas obige Beispiel zeigt einen ziemlich langen Befehl, der möglicherweise nicht auf eine einzelne Zeile passt. In solchen Fällen zeigt R ein + (Pluszeichen) an, um anzuzeigen, dass ein Befehl fortgesetzt werden muss, z.B. weil noch eine schließende Klammer oder ein schließendes Anführungszeichen fehlt. Ein solches + am Anfang einer Zeile ist ein automatischer „Prompt“ ähnlich dem gewöhnlichen &gt;-Prompt und muss niemals manuell eingegeben werden. Wenn die „+“-Fortsetzungsaufforderung jedoch versehentlich auftritt, drücke „ESC“, um diesen Modus abzubrechen.\nIm Gegensatz zur Fortsetzungsaufforderung ist es auch möglich, mehrere Befehle in eine Zeile zu schreiben, getrennt durch ein Semikolon „;“. Das ist in einigen Fällen sinnvoll, aber im Allgemeinen ist es viel besser, den Skript-Editor zu verwenden und dann:\n\njeden Befehl in eine eigene Zeile zu schreiben\nlange Zeilen mit mehr als 80 Zeichen zu vermeiden\neine angemessene Einrückung zu verwenden, z.B. 2 Zeichen pro Einrückungsebene\nLeerzeichen einzufügen, um die Lesbarkeit des Codes zu verbessern, z.B. vor und nach dem Zuweisungsoperator &lt;-.\n\nSchließlich bedeutet ein Zahlensymbol (oder eine Raute) #, dass eine komplette Zeile oder der Teil der Zeile, der auf # folgt, ein Kommentar ist und von R ignoriert wird.",
    "crumbs": [
      "Tutorials",
      "Erste Schritte mit R"
    ]
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#zusätzliche-plotting-optionen",
    "href": "tutorials/s1-introductory-r-session.html#zusätzliche-plotting-optionen",
    "title": "Erste Schritte mit R",
    "section": "3.2 Zusätzliche Plotting-Optionen",
    "text": "3.2 Zusätzliche Plotting-Optionen\nUm die Fülle der grafischen Funktionen zu erkunden, lohnt es sich nun, einen Blick in die Online-Hilfe zu werfen, insbesondere in Bezug auf ?plot oder ?plot.default, und ein wenig mit verschiedenen Plot-Parametern zu experimentieren, wie lty, pch, lwd, type, log usw. R enthält unzählige Möglichkeiten, um die volle Kontrolle über den Stil und Inhalt von Grafiken zu bekommen, z.B. mit benutzerdefinierten Achsen (axis), Legenden (legend) oder benutzerdefinierten Linien und Flächen (abline, rect, polygon). Der allgemeine Stil von Abbildungen wie (Schriftgröße, Ränder, Linienbreite) kann mit der Funktion par beeinflusst werden.",
    "crumbs": [
      "Tutorials",
      "Erste Schritte mit R"
    ]
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#high-level-grafiken",
    "href": "tutorials/s1-introductory-r-session.html#high-level-grafiken",
    "title": "Erste Schritte mit R",
    "section": "3.3 High-Level Grafiken",
    "text": "3.3 High-Level Grafiken\nDarüber hinaus enthalten R und seine Pakete zahlreiche „High-Level“-Grafikfunktionen für bestimmte Zwecke. Um einige davon zu demonstrieren, erzeugen wir zunächst einen Datensatz mit normalverteilten Zufallszahlen (Mittelwert = 0, Standardabweichung sd = 1), dann plotten wir sie und erstellen ein Histogramm. In diesem Fall teilt die Funktion par(mfrow = c(2, 2)) den Darstellungsbereich in 2 Zeilen und 2 Spalten, um 4 separate Abbildungen anzuzeigen:\n\npar(mfrow = c(2, 2))\nx &lt;- rnorm(100)\nplot(x)\nhist(x)\n\nNun erzeugen wir ein sogenanntes Normalwahrscheinlichkeitsdiagramm und ein zweites Histogramm mit relativen Häufigkeiten zusammen mit der glockenförmigen Dichtekurve der Standardnormalverteilung. Das optionale Argument probability = TRUE sorgt dafür, dass das Histogramm die gleiche Skalierung wie die Dichtefunktion hat, so dass beide überlagert werden können:\n\nqqnorm(x)\nqqline(x, col = \"red\")\nhist(x, probability = TRUE)\nxx &lt;- seq(-3, 3, 0.1)\nlines(xx, dnorm(xx, 0, 1), col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\nHier bietet sich eine gute Gelegenheit, verschiedene Funktionen der zusammenfassenden Statistik auszuprobieren: z.B. mean(x), var(x), sd(x), range(x), summary(x), min(x), max(x), …\nAlternativ können wir prüfen, ob die generierten Zufallszahlen x annähernd normalverteilt sind, indem wir den Shapiro-Wilks-W-Test verwenden:\n\nx &lt;- rnorm(100)\nshapiro.test(x)\n\nEin p-Wert größer als 0.05 sagt uns, dass der Test keine Einwände gegen die Normalverteilung der Daten hat. Die konkreten Ergebnisse können abweichen, da x Zufallszahlen enthält, so dass es sinnvoll ist, den Test mehrmals zu wiederholen. Es kann auch sinnvoll sein, die mit rnorm erzeugten normalverteilten Zufallszahlen mit gleichverteilten Zufallszahlen zu vergleichen, die mit runif erzeugt wurden:\n\npar(mfrow=c(2,2))\ny &lt;- runif(100)\nplot(y)\nhist(y)\nqqnorm(y)\nqqline(y, col=\"red\")\nmean(y)\nvar(y)\nmin(y)\nmax(y)\nhist(y, probability=TRUE)\nyy &lt;- seq(min(y), max(y), length = 50)\nlines(yy, dnorm(yy, mean(y), sd(y)), col = \"red\")\nshapiro.test(y)\n\nZum Schluss vergleichen wir die Muster beider Datensätze mit Box-and-Whisker-Diagrammen:\n\npar(mfrow=c(1, 1))\nboxplot(x, y)",
    "crumbs": [
      "Tutorials",
      "Erste Schritte mit R"
    ]
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#übungen",
    "href": "tutorials/s1-introductory-r-session.html#übungen",
    "title": "Erste Schritte mit R",
    "section": "3.4 Übungen",
    "text": "3.4 Übungen\nWiederhole dieses Beispiel mit neuen Zufallszahlen und variiere die Stichprobengröße (n), den Mittelwert (mean) und die Standardabweichung (sd) für Zufallszahlen, die mit rnorm erzeugt wurden, und verwende verschiedene min und max für runif. Konsultiere die Hilfeseiten, um eine Erklärung der Funktionen und ihrer Argumente zu erhalten, und erstelle Boxplots mit verschiedenen Datensätzen.",
    "crumbs": [
      "Tutorials",
      "Erste Schritte mit R"
    ]
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#numerische-und-zeichen-vektoren",
    "href": "tutorials/s1-introductory-r-session.html#numerische-und-zeichen-vektoren",
    "title": "Erste Schritte mit R",
    "section": "4.1 Numerische und Zeichen-Vektoren",
    "text": "4.1 Numerische und Zeichen-Vektoren\nAlle Datenobjekte haben die beiden eingebauten Attribute mode (Datentyp) und length (Anzahl der Daten im Objekt).\nModi können „numerisch“ (numeric) für Berechnungen oder „Zeichen“ (character) für Textelemente sein.\n\nx &lt;- c(1, 3, 4, 5)       # numeric\na &lt;- c(\"hello\", \"world\") # character\n\nDas Folgende ist ebenfalls eine Zeichenvariable, da die Zahlen in Anführungszeichen stehen. Es ist damit nicht möglich, Berechnungen durchzuführen:\n\nx &lt;- c(\"1\", \"3\", \"4\", \"5\")  # character\nsum(x)\n\nError in sum(x) : invalid 'type' (character) of argument\n\nHier ist es notwendig, das Zeichen zuerst in eine Zahl umzuwandeln:\n\ny &lt;- as.numeric(x)\nsum(y)\n\n[1] 9.040591",
    "crumbs": [
      "Tutorials",
      "Erste Schritte mit R"
    ]
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#faktoren",
    "href": "tutorials/s1-introductory-r-session.html#faktoren",
    "title": "Erste Schritte mit R",
    "section": "4.2 Faktoren",
    "text": "4.2 Faktoren\nEine besondere Art von Modus ist factor. Dies ist, statistisch gesehen, eine nominale Variable die wie eine Zeichenvariable aussieht, z. B. „control“, „treatment A“, „treatment B“ …, aber ihre Faktorstufen sind intern als Ganzzahl kodiert.\nHier ein typisches Beispiel mit drei Faktorstufen. In einem ersten Schritt erstellen wir eine Zeichenvariable:\n\ntext &lt;- rep(c(\"control\", \"treatment A\", \"treatment B\"), each = 5)\ntext\n\n [1] \"control\"     \"control\"     \"control\"     \"control\"     \"control\"    \n [6] \"treatment A\" \"treatment A\" \"treatment A\" \"treatment A\" \"treatment A\"\n[11] \"treatment B\" \"treatment B\" \"treatment B\" \"treatment B\" \"treatment B\"\n\n\nund konvertieren sie dann in einen Faktor:\n\nf &lt;- factor(text)\nf\n\n [1] control     control     control     control     control     treatment A\n [7] treatment A treatment A treatment A treatment A treatment B treatment B\n[13] treatment B treatment B treatment B\nLevels: control treatment A treatment B\n\n\nWir sehen, dass die Zeichenvariable mit Anführungszeichen ausgedruckt wird und der Faktor ohne Anführungszeichen, aber mit einer zusätzlichen Information über die Faktorstufen. Der Grund dafür ist, dass der Faktor intern als Ganzzahlwerte mit zugewiesenen Stufen als Übersetzungstabelle kodiert ist:\n\nlevels(f)\n\n[1] \"control\"     \"treatment A\" \"treatment B\"\n\n\nUm die Kodierung zu zeigen, können wir den Faktor in eine ganze Zahl umwandeln\n\nas.integer(f)\n\n [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3\n\n\nDie Kodierung wird standardmäßig in alphabetischer Reihenfolge vorgenommen. Sie kann durch ein zusätzliches Argument levels geändert werden:\n\nf2 &lt;- factor(text, levels=c(\"treatment A\", \"treatment B\", \"control\"))\nf2\n\n [1] control     control     control     control     control     treatment A\n [7] treatment A treatment A treatment A treatment A treatment B treatment B\n[13] treatment B treatment B treatment B\nLevels: treatment A treatment B control\n\nas.numeric(f2)\n\n [1] 3 3 3 3 3 1 1 1 1 1 2 2 2 2 2\n\n\nFaktoren sind für statistische Analysen wie ANOVA und statistische Tests nützlich oder auch als Kategorien für die Darstellung:\n\nx &lt;- c(7.44, 6.45, 6.04, 5.58, 4.5, 8.13, 5.54, 7.34, 8.91, 5.16, 8.7, 7.74, 6.8, 6.49, 6.2)\nplot(x ~ f)\n\n\n\n\n\n\n\n\nWir sehen, dass ein Boxplot erstellt wird und kein x-y-Plot, weil die Erklärungsvariable ein Faktor ist.\nNumerische Variablen (insbesondere ordinale) können ebenfalls in Faktoren umgewandelt werden. Dies ist nützlich, wenn wir deutlich machen wollen, dass Zahlen als Namen ohne Reihenfolge zu behandeln sind.\nBei der Rückkonvertierung solcher Faktoren in numerische Variablentypen ist große Vorsicht geboten, da ein Zeichen „123“ mit einem anderen Wert (z. B. 1) und nicht mit 123 kodiert werden kann, siehe die folgende Demonstration einer korrekten und einer falschen Faktorumwandlung:\n\nx &lt;- c(2, 4, 6, 5, 8)\nf &lt;- as.factor(x)\nas.numeric(f)               # falsch !!!\nas.numeric(as.character(f)) # richtig\nas.numeric(levels(f))[f]    # noch besser\n\nEine derartige Faktorkodierung ist nicht spezifisch für R und kommt auch in anderen Statistikpaketen vor. Sie werden dann manchmal als „Dummy-Variablen“ bezeichnet.",
    "crumbs": [
      "Tutorials",
      "Erste Schritte mit R"
    ]
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#matrizen-und-arrays",
    "href": "tutorials/s1-introductory-r-session.html#matrizen-und-arrays",
    "title": "Erste Schritte mit R",
    "section": "4.3 Matrizen und Arrays",
    "text": "4.3 Matrizen und Arrays\nEine Matrix ist eine zweidimensionale Datenstruktur, die für Matrixalgebra verwendet werden kann. Um eine Matrix zu erhalten, können wir zunächst einen eindimensionalen Vektor erstellen und ihn dann als zweidimensionale Matrix mit „nrow“-Zeilen und „ncol“-Spalten umformatieren:\n\nx &lt;- 1:20\nx\n\ny &lt;- matrix(x, nrow = 5, ncol = 4)\ny\n\nWir sehen, dass die Matrix zeilenweise gefüllt aufgefüllt wird. Wir können sie auch wieder in einen Vektor umwandeln:\n\nas.vector(y) # reduziert die Matrix auf einen Vektor\n\nEin „Array“ erweitert das Matrixkonzept auf mehr als zwei Dimensionen:\n\nx &lt;- array(1:24, dim=c(3, 4, 2))\n\nVektoren, Matrizen und Arrays haben eine wichtige Einschränkung: Sie können nur einen Datentyp (Modus) enthalten, entweder einen numerischen oder einen Zeichentyp. Wenn mindestens ein einzelnes Element vom Typ Zeichen ist, hat die gesamte Matrix den Modus Zeichen und erscheint in Anführungszeichen:\n\nx &lt;- c(1, 2, 5, 2, \"a\")\nmode(x)\nx",
    "crumbs": [
      "Tutorials",
      "Erste Schritte mit R"
    ]
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#listen",
    "href": "tutorials/s1-introductory-r-session.html#listen",
    "title": "Erste Schritte mit R",
    "section": "4.4 Listen",
    "text": "4.4 Listen\nDer flexibelste Datentyp von R ist die Liste. Sie kann beliebige Daten unterschiedlicher Art enthalten. Listen können verschachtelt werden, um eine baumartige Struktur zu bilden:\n\nl &lt;- list(x = 1:3, y = c(1,2,3,4), a = \"hello\", L = list(x = 1, y = 2))\n\nListen sind äußerst leistungsfähig und flexibel und werden später behandelt. Die Ungeduldigen können einen Blick auf das Tutorial von w3schools.com werfen.",
    "crumbs": [
      "Tutorials",
      "Erste Schritte mit R"
    ]
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#dataframes",
    "href": "tutorials/s1-introductory-r-session.html#dataframes",
    "title": "Erste Schritte mit R",
    "section": "4.5 Dataframes",
    "text": "4.5 Dataframes\nDie typische Datenstruktur für die Datenanalyse in R ist der sogenannte data.frame. Er kann sowohl Spalten mit numerischen Daten als auch Spalten mit Zeichenvariablen enthalten. Einige Pakete verwenden eine von Dataframes abgeleitete Objektklasse, das so genannte tibble.\nEin Dataframe kann von Grund auf direkt im R-Code erstellt werden oder aus einer Datei oder dem Internet gelesen werden. Als Beispiel wurden die Studierenden eines Kurses in verschiedenen Jahren nach ihrer Lieblingszahl von eins bis 9 gefragt. Die Ergebnisse können wie folgt in einen Dataframe eingetragen werden:\n\nfavnum &lt;- data.frame(\n  favorite = 1:9,\n  obs2019  = c(1, 1, 6, 2, 2,  5,  8, 6, 3),\n  obs2020  = c(1, 2, 8, 1, 2,  2, 20, 2, 4),\n  obs2021  = c(2, 6, 8, 1, 6,  4, 13, 2, 4),\n  obs2022  = c(2, 3, 7, 8, 2, 10, 12, 6, 1)\n)",
    "crumbs": [
      "Tutorials",
      "Erste Schritte mit R"
    ]
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#direkte-eingabe",
    "href": "tutorials/s1-introductory-r-session.html#direkte-eingabe",
    "title": "Erste Schritte mit R",
    "section": "5.1 Direkte Eingabe",
    "text": "5.1 Direkte Eingabe\nDiese Methode haben wir bereits bei der Erstellung von Vektoren mit der c (combine)-Funktion verwendet:\n\nx &lt;- c(1, 2, 5, 7, 3, 4, 5, 8)\nx\n\nAuf die gleiche Weise ist es möglich, andere Datentypen wie z.B. Dataframes zu erstellen:\n\ndat &lt;- data.frame(f = c(\"a\", \"a\", \"a\", \"b\", \"b\", \"b\"),\n                  x = c(1,   4,   3,   3,   5,   7)\n       )\ndat\n\noder Matrizen:\n\nA &lt;- matrix(c(1:9), nrow = 3)\nA\n\nWie wir sehen, unterscheidet sich eine Matrix nicht wesentlich von einem Vektor, nur dass er in Zeilen und Spalten formatiert ist.",
    "crumbs": [
      "Tutorials",
      "Erste Schritte mit R"
    ]
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#daten-aus-einer-textdatei-lesen",
    "href": "tutorials/s1-introductory-r-session.html#daten-aus-einer-textdatei-lesen",
    "title": "Erste Schritte mit R",
    "section": "5.2 Daten aus einer Textdatei lesen",
    "text": "5.2 Daten aus einer Textdatei lesen\nR hat sehr flexible Funktionen zum Lesen von Daten aus Textdateien. Nehmen wir zum Beispiel eine Tabelle, die einige Daten aus einem Seegebiet in Nord-Ost-Deutschland enthält (Tabelle 1).\nTabelle 1:  Morphometrische und chemische Eigenschaften ausgewählter Seen (S=Stechlinsee, NN=Nehmitzsee Nord, NS=Nehmitzsee Süd, BL=Breiter Luzin, SL = Schmaler Luzin, DA = Dagowsee, HS = Feldberger Haussee; z=mittlere Tiefe (m), t=theoretische Retentionszeit (a), P=Phosphorkonzentration (\\(\\mathrm{\\mu g L^{-1}}\\)), N=Stickstoffkonzentration (\\(\\mathrm{mg L{^-1}}\\)), Chl=Chlorophyllkonzentration (\\(\\mathrm{\\mu g L^{-1}}\\)), PP=jährliche Primärproduktion (\\(\\mathrm{g C m^{-2} a^{-1}}\\)), SD = Secchi-Tiefe (m)). Die Daten sind eine angepasste und vereinfachte „Spielzeugversion“ aus Casper (1985) und Koschel & Scheffler (1985).\n\n\n\n\n\nLake\nz\nt\nP\nN\nChl\nPP\nSD\n\n\n\n\nS\n23.7\n40\n2.5\n0.20\n0.7\n95\n8.4\n\n\nNN\n5.9\n10\n2.0\n0.20\n1.1\n140\n7.4\n\n\nNS\n7.1\n10\n2.5\n0.10\n0.9\n145\n6.5\n\n\nBL\n25.2\n17\n50.0\n0.10\n6.1\n210\n3.8\n\n\nSL\n7.8\n2\n30.0\n0.10\n4.7\n200\n3.7\n\n\nDA\n5.0\n4\n100.0\n0.50\n14.9\n250\n1.9\n\n\nHS\n6.3\n4\n1150.0\n0.75\n17.5\n420\n1.6\n\n\n\n\n\nDie Daten können von https://tpetzoldt.github.io/datasets/data/lakes.csv heruntergeladen werden.\n\n5.2.1 Arbeitsverzeichnis (working directory) festlegen\nR muss wissen, wo die Daten auf deinem Computer zu finden sind. Eine Möglichkeit ist, den vollständigen Pfad zum Datensatz anzugeben, z.B. wenn er c:/users/&lt;Benutzername&gt;/documents lautet, dann\n\nlakes &lt;- read.csv(\"c:/users/julia/documents/lakes.csv\")\n\nDies kann umständlich und fehleranfällig sein, so dass die bevorzugte Methode darin besteht, das Arbeitsverzeichnis von R auf das Datenverzeichnis zu setzen. Dies kann in RStudio wie folgt gemacht werden:\n\nSuche nach dem Ordner mit den Daten im Fenster „Files“.\nWähle „More“\nWähle „Set As Working Directory“\n\n Abbildung 2: Festlegen des Arbeitsverzeichnisses in RStudio\nDanach können die Daten direkt aus dem Arbeitsverzeichnis abgerufen werden:\n\nlakes &lt;- read.csv(\"lakes.csv\", header = TRUE)\n\nWir können auch einen Unterordner data des Arbeitsverzeichnisses erstellen und die Daten dort ablegen. Dann könnten wir zum Beispiel verwenden:\n\nlakes &lt;- read.csv(\"../data/lakes.csv\", header = TRUE)\n\nBeachte auch, dass wir immer den gewöhnlichen Schrägstrich „/“ und nicht den Backslash „\\“ verwenden, auch unter Windows.\nIn einigen Ländern, in denen das Komma und nicht der Punkt als Dezimaltrennzeichen und dann z.B. ein Semikolon als Spaltentrennzeichen verwendet wird, können zusätzliche Argumente dec = \",\", sep=\";\" erforderlich sein. Die Details sind auf der Hilfeseite read.table zu finden.",
    "crumbs": [
      "Tutorials",
      "Erste Schritte mit R"
    ]
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#daten-aus-dem-internet-lesen",
    "href": "tutorials/s1-introductory-r-session.html#daten-aus-dem-internet-lesen",
    "title": "Erste Schritte mit R",
    "section": "5.3 Daten aus dem Internet lesen",
    "text": "5.3 Daten aus dem Internet lesen\nWenn die Daten auf einem Internet-Server verfügbar sind, können sie direkt von dort gelesen werden:\n\nlakes &lt;- read.csv(\"https://tpetzoldt.github.io/datasets/data/lakes.csv\")\n\nDa die Daten im Dataframe lakes` gespeichert sind, ist es nun möglich, wie gewohnt auf sie zuzugreifen:\n\nlakes\nsummary(lakes)\nboxplot(lakes[-1])\n\nHier zeigt summary einen schnellen Überblick und boxplot erstellt ein Boxplot für alle Spalten außer der ersten, die keine Zahlen enthält.\nJetzt können wir den Inhalt der neuen Variable lakes untersuchen. Wenn wir RStudio verwenden, kann eine Ansicht (“View”) aufgerufen werden, indem man auf lakes im Environment-Fenster klickt.",
    "crumbs": [
      "Tutorials",
      "Erste Schritte mit R"
    ]
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#datensatz-importieren-in-rstudio",
    "href": "tutorials/s1-introductory-r-session.html#datensatz-importieren-in-rstudio",
    "title": "Erste Schritte mit R",
    "section": "5.4 „Datensatz importieren“ in RStudio",
    "text": "5.4 „Datensatz importieren“ in RStudio\nRStudio enthält eine praktische Funktion, die das Importieren von Daten vereinfacht. Im Wesentlichen hilft uns dieser „Import Dataset“-Assistent dabei, interaktiv die richtige read.table, read.csv oder read_delim Funktion zu konstruieren. Es ist möglich, verschiedene Optionen auszuprobieren, bis ein zufriedenstellendes Ergebnis erzielt wird. Aktuelle Versionen von RStudio enthalten mehrere verschiedene Möglichkeiten dafür. Hier demonstrieren wir den Assistenten „Import Dataset From Text (readr)“:\n\nWähle aus dem Menü: File – Import DataSet – From CSV.\nWähle die gewünschte Datei und gib geeignete Optionen an, wie den Namen der Variablen, der die Daten zugeordnet werden sollen, das Trennzeichen (Komma oder Tabulator) und ob die erste Zeile der Datei Variablennamen enthalten soll.\n\n\n“Import Dataset From Text (readr)” Assistent von RStudio.\nHinweis: Im obigen Beispiel ist der Name des Dataframes identisch mit dem Dateinamen, d.h „lakes“. Wenn wir ihn anders benennen wollen (z.B.: dat), dürfen wir nicht vergessen, diese Einstellung zu ändern.\nHierbei zeigt die Code-Vorschau die Befehle, die der Assistent erstellt hat. Wenn wir diese Befehle in das Skriptfenster kopieren, können die Daten mehrmals gelesen werden ohne zum Menüsystem zurückkehren zu müssen:\n\nlibrary(readr)\nlakes &lt;- read_csv(\"D:/DATA/lakes.csv\")\nView(lakes)",
    "crumbs": [
      "Tutorials",
      "Erste Schritte mit R"
    ]
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#den-inhalt-des-dataframes-anzeigen",
    "href": "tutorials/s1-introductory-r-session.html#den-inhalt-des-dataframes-anzeigen",
    "title": "Erste Schritte mit R",
    "section": "6.1 Den Inhalt des Dataframes anzeigen",
    "text": "6.1 Den Inhalt des Dataframes anzeigen\nAm einfachsten ist es, den Namen des Dataframes in die R-Konsole einzugeben, z.B.:\n\nlakes\n\noder man klickt auf den Namen des Dataframes im „Environment“-Explorer von RStudio. Dies führt dann View(lakes) aus und die Daten werden angezeigt.\nBei großen Tabellen ist es manchmal unbersichtlich, den gesamten Inhalt mit View anzuzeigen, so dass es besser sein kann, die Funktion str (Struktur) zu verwenden, die einen kompakten Überblick über Typ, Größe und Inhalt einer Variablen gibt:\n\nstr(mydata)\n\nDie Funktion str ist universell und auch für komplizierte Objekttypen wie Listen geeignet. Natürlich gibt es noch viele weitere Möglichkeiten, den Inhalt einer Variablen zu untersuchen:\n\nnames(lakes)\nmode(lakes)\nlength(lakes)\n\nund manchmal sogar:\n\nplot(lakes)",
    "crumbs": [
      "Tutorials",
      "Erste Schritte mit R"
    ]
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#zugriff-auf-einzelne-spalten-mit",
    "href": "tutorials/s1-introductory-r-session.html#zugriff-auf-einzelne-spalten-mit",
    "title": "Erste Schritte mit R",
    "section": "6.2 Zugriff auf einzelne Spalten mit $",
    "text": "6.2 Zugriff auf einzelne Spalten mit $\nAuf einzelne Spalten eines Dataframes kann durch die Indizes (mit []), ähnlich wie bei einem Vektor oder einer Matrix oder mit dem Operator $ und dem Spaltennamen) zugegriffen werden:\n\nmean(lakes[,2])\nmean(lakes$z)\nmean(lakes[,\"z\"])\nmean(lakes[[\"z\"]])\nplot(lakes$z, lakes$t)\n\nwobei z die mittlere Tiefe der Seen und t die sogenannte mittlere Verweilzeit ist.\nWir sollten auch den subtilen Unterschied zwischen der Ausgabe der [] und der [[]]- Version beachten. Der Unterschied ist folgender: einfache Klammern geben einen Dataframe mit einer Spalte zurück, aber doppelte eckige Klammern ergeben den Inhalt der Spalte als Vektor ohne den Spaltennamen.\nWarnung: In einigen älteren Büchern wird der $-Stil manchmal mit den Funktionen attach und detach abgekürzt. Von diesem „prähistorischen Relikt“ wird dringend abgeraten, da es zu Dateninkonsistenz und seltsamen Fehlern führen kann. Wenn man es irgendwo findet, wo es noch benutzt wird, dann ist es eine gute Idee, detach wiederholt zu benutzen, bis eine Fehlermeldung uns bestätigt, dass es nichts mehr gibt, was abgetrennt werden kann. Schließlich: Verwende niemals attach/detach in einem Paket.\nStattdessen ist es viel besser, eine andere Funktion width zu verwenden, die den Dataframe nur vorübergehend öffnet:\n\nwith(lakes, plot(z, t))",
    "crumbs": [
      "Tutorials",
      "Erste Schritte mit R"
    ]
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#teilmengen-und-logische-indizes",
    "href": "tutorials/s1-introductory-r-session.html#teilmengen-und-logische-indizes",
    "title": "Erste Schritte mit R",
    "section": "6.3 Teilmengen und logische Indizes",
    "text": "6.3 Teilmengen und logische Indizes\nIm Folgenden verwenden wir einen weiteren Datensatz, den wir direkt aus dem Internet eingelesen haben:\n\nfruits &lt;- read.csv(\"https://tpetzoldt.github.io/datasets/data/clementines.csv\")\n\nEr enthält das Gewicht, die Breite und die Höhe von zwei Marken von Clementinenfrüchten. Nach dem Laden der Daten können wir sie mit View(fruits) oder dem Environment Explorer von Rstudio betrachten.\nEine sehr leistungsfähige Funktion von R ist die Verwendung von logischen Vektoren als Indizes, mit ähnlichen Ergebnissen wie bei Datenbankabfragen. Als Beispiel können wir das Gewicht aller Früchte der Marke „A“ anzeigen mit\n\nfruits[fruits$brand == \"A\", c(\"brand\", \"weight\")]\n\n   brand weight\n6      A     81\n7      A    113\n8      A     94\n9      A     86\n10     A    108\n11     A     91\n12     A     94\n13     A     86\n14     A     91\n15     A     88\n\n\nHier gibt der erste Index in den eckigen Klammern die gewünschte Teilmenge der Zeilen an und das zweite Argument die Spalten. Wenn wir alle Spalten sehen wollen, lassen wir das Argument nach dem Komma leer:\n\nfruits[fruits$brand == \"A\", ]\n\n   id no brand weight width height\n6   6  7     A     81    53     54\n7   7  8     A    113    61     60\n8   8  9     A     94    62     49\n9   9  3     A     86    58     53\n10 10  6     A    108    64     50\n11 11  1     A     91    59     51\n12 12 10     A     94    59     51\n13 13  4     A     86    55     55\n14 14  2     A     91    61     51\n15 15  5     A     88    54     55\n\n\nEin logischer Vergleich erfordert immer ein doppeltes „==“. Logische Operationen wie & (und) und | (oder) sind ebenfalls möglich. Beachte, dass „und“ immer Vorrang vor „oder“ hat, außer dies wird durch Klammern geändert.\nEine Teilmenge eines Dataframes kann auch mit der Funktion subset extrahiert werden:\n\nbrand_B &lt;- subset(fruits, brand == \"B\")\nbrand_B\n\nWie im Beispiel zuvor, erlaubt das Bedingungsargument auch logische Ausdrücke mit & (und) und | (oder).\nWir können auch auf einzelne Elemente in Matrix-ähnlicher Weise zugreifen, z.B. auf das Element aus der 2. Zeile und der 4. Spalte mit:\n\nfruits[2, 4]\n\ndie komplette 5. Zeile mit:\n\nfruits[5, ]\n\nund die Zeilen 5:10 der 4. Spalte (Gewicht) mit:\n\nfruits[5:10, 4]\n\nWeitere Methoden für die Arbeit mit Matrizen, Dataframes und Listen sind in R-Lehrbüchern oder in der offiziellen R-Dokumentation zu finden.",
    "crumbs": [
      "Tutorials",
      "Erste Schritte mit R"
    ]
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#pipelines-und-zusammenfassungen",
    "href": "tutorials/s1-introductory-r-session.html#pipelines-und-zusammenfassungen",
    "title": "Erste Schritte mit R",
    "section": "7.1 Pipelines und Zusammenfassungen",
    "text": "7.1 Pipelines und Zusammenfassungen\nDie letzten Beispiele sollen zeigen, wie mächtig eine einzelne Zeile in R sein kann. Die Art und Weise, wie Datensätze analysiert werden können, hat sich im Laufe der Geschichte von R weiterentwickelt, so gibt es z.B. eine Funktion aggregate, um Statistiken (z.B. Mittelwerte) in Abhängigkeit von bestimmten Kriterien zu berechnen.\nDies funktioniert gut und wird immer noch verwendet, aber die modernen Methoden aus dem sogenannten „tidyverse“ sind kompakter und einfacher zu verstehen. Hier wollen wir zunächst ein modernes Konzept vorstellen, das „Pipelining“ genannt wird. Die Idee ist, dass das Ergebnis einer Funktion direkt an eine andere Funktion weitergeleitet wird, also anstatt zu schreiben:\n\nbrand_B   &lt;- subset(fruits, brand == \"B\")\ncolumns_B &lt;- brand_B[c(\"weight\", \"width\", \"height\")]\nmeans_B   &lt;- colMeans(columns_B)\nmeans_B\n\nkönnen wir direkt schreiben:\n\nlibrary(\"dplyr\")\nfruits |&gt; filter(brand == \"B\") |&gt; select(weight, width, height) |&gt; colMeans()\n\nHier laden wir zunächst ein Zusatzpaket dplyr, das viele hilfreiche Funktionen für die Datenverwaltung enthält, z.B. filter, das Zeilen auswählt und select, das Spalten auswählt. Der Pipeline-Operator |&gt; leitet dann die Datenmenge fruits zur filter- Funktion und anschließend zur nächsten. Der „native Pipeline-Operator“ |&gt; wurde mit R 4.1 eingeführt. Alternativ können wir auch den %&gt;%-Pipelineoperator verwenden, der vom dplyr-Paket geladen wird. Die Funktionsweise ist in diesem Fall identisch.\nZwei weitere äußerst nützliche dplyr-Funktionen sind group_by und summary, die es ermöglichen, beliebige zusammenfassende Statistiken in Abhängigkeit von gruppierenden Variablen zu berechnen. Wenn wir die „Marke“ (“brand”) zur Gruppierung verwenden, können wir alle Gruppen gleichzeitig zusammenfassen:\n\nfruits |&gt; \n  group_by(brand) |&gt;\n  summarise(mean(weight), mean(width), mean(height))\n\nDie obige Zeile summarise kann immer noch verbessert werden, und es gibt viele andere verblüffende Möglichkeiten, daher werden wir später darauf zurückkommen.",
    "crumbs": [
      "Tutorials",
      "Erste Schritte mit R"
    ]
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#ausgabe-von-ergebnissen",
    "href": "tutorials/s1-introductory-r-session.html#ausgabe-von-ergebnissen",
    "title": "Erste Schritte mit R",
    "section": "7.2 Ausgabe von Ergebnissen",
    "text": "7.2 Ausgabe von Ergebnissen\nDie einfachste Methode, die Ergebnisse von R zu speichern, besteht darin, sie direkt von der R-Konsole über die Zwischenablage in ein beliebiges anderes Programm (z. B. LibreOffice, Microsoft Word oder Powerpoint) zu kopieren. Dies ist bequem, kann aber nicht automatisiert werden. Daher ist es besser, einen Programmieransatz zu verwenden.\nNehmen wir das obige Beispiel und speichern wir die Ergebnisse in einen neue Dataframe results:\n\nresults &lt;-\n  fruits |&gt; \n  group_by(brand) |&gt;\n  summarise(mean(weight), mean(width), mean(height))\n\nDataframes können als Textdateien mit write.table, write.csv oder write_csv gespeichert werden. Hier verwenden wir write_csv (mit Unterstrich, nicht Punkt) aus dem Paket readr:\n\nlibrary(\"readr\")\nwrite_csv(results, file=\"output-data.csv\")\n\nZusätzlich zu diesen Grundfunktionen verfügt R über eine Fülle von Möglichkeiten, Ausgaben und Daten für die spätere Verwendung in Berichten und Präsentationen zu speichern. Alle sind selbstverständlich in der Online-Hilfe dokumentiert, z.B. print, print.table, cat für Textdateien, und pdf, png für Abbildungen. Das Zusatzpaket xtable enthält Funktionen zur Erstellung von LaTeX- oder HTML-Tabellen, während die vollständige HTML-Ausgabe von den Paketen R2HTML oder knitr unterstützt wird.",
    "crumbs": [
      "Tutorials",
      "Erste Schritte mit R"
    ]
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#plots-mit-ggplot2",
    "href": "tutorials/s1-introductory-r-session.html#plots-mit-ggplot2",
    "title": "Erste Schritte mit R",
    "section": "7.3 Plots mit ggplot2",
    "text": "7.3 Plots mit ggplot2\nZusätzlich zu den bisher verwendeten Plot-Funktionen gibt es noch andere Plot-Pakete, zum Beispiel lattice oder ggplot2. Hier ein paar kleine Beispiele mit dem sehr populären **ggplot2*-Paket:\n\nlibrary(\"ggplot2\")\nfruits |&gt;\n  ggplot(aes(brand, weight)) + geom_boxplot()\n\n\n\n\n\n\n\n\nOder ein Streudiagramm zum Vergleich von Gewicht (“weight”) und Breite (“width”) der Früchte\n\nfruits |&gt; ggplot(aes(weight, width)) + geom_point(aes(color=brand))\n\n\n\n\n\n\n\n\nwobei die Marke als Farbe angegeben ist. Eine andere Option könnte sein:\n\nfruits |&gt; ggplot(aes(weight, width)) + \n  geom_point() + \n  geom_smooth(method=\"lm\") + \n  facet_grid(~brand)\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "Tutorials",
      "Erste Schritte mit R"
    ]
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#übungen-1",
    "href": "tutorials/s1-introductory-r-session.html#übungen-1",
    "title": "Erste Schritte mit R",
    "section": "7.4 Übungen",
    "text": "7.4 Übungen\nR enthält viele Datensätze zum Ausprobieren seiner grafischen und statistischen Funktionen, die mit der data-Funktion aktiviert werden können, z.B. data(iris) oder data(cars). Eine Beschreibung des Datensatzes findet sich wie üblich in den Hilfedateien, z.B. ?iris, ?cars.\nVerwende einen dieser Datensätze und probiere aus\n\nwie man auf Spalten zugreift, Zeilen auswählt und Teilmengen erstellt\nwie man Statistiken zusammenfasst und mit R’s Basisplotfunktionen und optional mit ggplot visualisiert.",
    "crumbs": [
      "Tutorials",
      "Erste Schritte mit R"
    ]
  },
  {
    "objectID": "slides/x5-quarto-intro.html#markdown-rmarkdown-and-quarto",
    "href": "slides/x5-quarto-intro.html#markdown-rmarkdown-and-quarto",
    "title": "x05-Creation of Reports with Quarto",
    "section": "Markdown, RMarkdown and Quarto",
    "text": "Markdown, RMarkdown and Quarto\n\nMarkdown .md\n\n” … is a lightweight markup language for creating formatted text using a plain-text editor” (Wikipedia, 2022).\nCan be written with any text editor, less perfect than Latex, but much easier.\nMarkdown supported by many programs and services (e.g. Github, StackOverflow, Matrix, RStudio, …)\n\nRMarkdown .Rmd\n\nis an extension of markdown that can embed R code.\nsuperseeded by Quarto\n\nQuarto .qmd\n\nis an extension of Markdown that can embed R, Python, Julia and Observable code.\nimproved capabilities to create reports, slides, websites, papers, books.",
    "crumbs": [
      "Selected Programming Topics",
      "x05-Creation of Reports with Quarto"
    ]
  },
  {
    "objectID": "slides/x5-quarto-intro.html#why-markdown-or-quarto",
    "href": "slides/x5-quarto-intro.html#why-markdown-or-quarto",
    "title": "x05-Creation of Reports with Quarto",
    "section": "Why Markdown or Quarto",
    "text": "Why Markdown or Quarto\n\n\nQuick note taking (documentation of ideas, experiments, SOPs, …)\nDocumentation of statistical analyses (Quarto + R)\nClearly structured documents (outline clearly visible)\nEasy literature referencing\nMuch easier than LaTeX \nWidely used technology, useful for Stackoverflow, Github or Matrix",
    "crumbs": [
      "Selected Programming Topics",
      "x05-Creation of Reports with Quarto"
    ]
  },
  {
    "objectID": "slides/x5-quarto-intro.html#software",
    "href": "slides/x5-quarto-intro.html#software",
    "title": "x05-Creation of Reports with Quarto",
    "section": "Software",
    "text": "Software\n\n\nYou can use any text editor, e.g. Notepad++, your mail client … or even Word\n\n\n\nBetter: use an editor with Markdown support\n\nRStudio\nPanWriter, a basic writing program with an almost empty screen \\(\\rightarrow\\) distraction free writing\nJoplin, a note taking program with cloud connectivity and encryption\nmany online services: Github, Gitlab, StackOverflow, Matrix\nand more",
    "crumbs": [
      "Selected Programming Topics",
      "x05-Creation of Reports with Quarto"
    ]
  },
  {
    "objectID": "slides/x5-quarto-intro.html#many-markdown-programs-available-e.g.-panwriter",
    "href": "slides/x5-quarto-intro.html#many-markdown-programs-available-e.g.-panwriter",
    "title": "x05-Creation of Reports with Quarto",
    "section": "Many Markdown Programs Available, e.g. Panwriter",
    "text": "Many Markdown Programs Available, e.g. Panwriter\n\nPanwriter with live preview",
    "crumbs": [
      "Selected Programming Topics",
      "x05-Creation of Reports with Quarto"
    ]
  },
  {
    "objectID": "slides/x5-quarto-intro.html#lets-use-rstudio.-supports-markdown-and-quarto",
    "href": "slides/x5-quarto-intro.html#lets-use-rstudio.-supports-markdown-and-quarto",
    "title": "x05-Creation of Reports with Quarto",
    "section": "Let’s use RStudio. Supports Markdown and Quarto",
    "text": "Let’s use RStudio. Supports Markdown and Quarto\n\nRStudio",
    "crumbs": [
      "Selected Programming Topics",
      "x05-Creation of Reports with Quarto"
    ]
  },
  {
    "objectID": "slides/x5-quarto-intro.html#example",
    "href": "slides/x5-quarto-intro.html#example",
    "title": "x05-Creation of Reports with Quarto",
    "section": "Example",
    "text": "Example\n\nSection titles are introduced with one or several hash symbols #, ##, praragraphs with empty lines, italic and bold face are indicated with one or two starts before and after a phrase, bullet points with a leading dash - or a star *. Weblinks are automatically activated. Here an example:\n    # First level\n\n    Text can be written with any editor, that can be formatted, e.g. *slanted*, **boldface**,\n    `verbatim text` weblinks: https://tu-dresden.de or bullet points:\n\n    * point 1\n    * point 2\n\n    Section titles start with one or more hash tags\n    \n    \n    ## Second level\n    \n    ### Third level\nThere are of course more formatting options, found in the docs or explained later.",
    "crumbs": [
      "Selected Programming Topics",
      "x05-Creation of Reports with Quarto"
    ]
  },
  {
    "objectID": "slides/x5-quarto-intro.html#yaml-header",
    "href": "slides/x5-quarto-intro.html#yaml-header",
    "title": "x05-Creation of Reports with Quarto",
    "section": "YAML Header",
    "text": "YAML Header\n\nQuarto and markdown documents can have a few special lines on top, enclosed within three dashes ---. This so called “YAML header” is used to set text settings and formatting options:\n    ---\n    title: \"Test\"\n    author: \"Who wrote this\"\n    date: '2024-11-12'\n    format: html\n    ---\n    \n    # First Section\n\n    Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy\n    eirmod tempor invidunt ut labore et dolore magna aliquyam erat.\n    \n    At vero eos et accusam et justo duo dolores et ea rebum.\n    \n    # Second Section\n     \n    Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum \n    dolor sit amet. \nYAML: yet another markup language. A list format coming from the python world.",
    "crumbs": [
      "Selected Programming Topics",
      "x05-Creation of Reports with Quarto"
    ]
  },
  {
    "objectID": "slides/x5-quarto-intro.html#layout-and-format-conversion",
    "href": "slides/x5-quarto-intro.html#layout-and-format-conversion",
    "title": "x05-Creation of Reports with Quarto",
    "section": "Layout and format conversion",
    "text": "Layout and format conversion\n\nUser can concentrate on writing, formatting is done automatically.\nSeveral tools exist to convert markdown to other document formats.\nOne of the most popular is pandoc. It is built-in in Rstudio.\n\n\n\n\n\n\n\nRendering is done with the pandoc utility to convert Quarto or Markdown text to\nHTML for web pages, pdf for printing, or Word for further editing.",
    "crumbs": [
      "Selected Programming Topics",
      "x05-Creation of Reports with Quarto"
    ]
  },
  {
    "objectID": "slides/x5-quarto-intro.html#what-is-pandoc",
    "href": "slides/x5-quarto-intro.html#what-is-pandoc",
    "title": "x05-Creation of Reports with Quarto",
    "section": "What is Pandoc?",
    "text": "What is Pandoc?\n\n\nPandoc is a universal text conversion tool\nIt is said to be the “swiss-army knife” to convert between formats\nOpen Source licensed: GPL 2.0 resp. MIT license\nAvailable from: https://pandoc.org/\n… or embedded in RStudio",
    "crumbs": [
      "Selected Programming Topics",
      "x05-Creation of Reports with Quarto"
    ]
  },
  {
    "objectID": "slides/x5-quarto-intro.html#exercise",
    "href": "slides/x5-quarto-intro.html#exercise",
    "title": "x05-Creation of Reports with Quarto",
    "section": "Exercise",
    "text": "Exercise\n\n\nWrite your first Quarto document in RStudio.\nRender it to HTML and Word\n\nOptional without warranty\n\nCreate PDF output\nNeeds LaTeX type setting system installed\nCan be done with R’s tinytex package:\n\n::: {.cell}\n\n:::\n… or by installing tinytex from the Terminal of RStudio\nquarto install tinytex\nand then include format: pdf in the YAML header\ntitle: \"My document\"\nformat: pdf\nSee more at: https://quarto.org/docs/output-formats/pdf-basics.html",
    "crumbs": [
      "Selected Programming Topics",
      "x05-Creation of Reports with Quarto"
    ]
  },
  {
    "objectID": "slides/x5-quarto-intro.html#section-titles",
    "href": "slides/x5-quarto-intro.html#section-titles",
    "title": "x05-Creation of Reports with Quarto",
    "section": "Section Titles",
    "text": "Section Titles\n\nSection titles can be formatted with hashtags or by underlining:\n# A Section\n\n## A subsection\nor:\nA Section\n=========\n\nA Subsection\n------------\nAutomatic numbering can optionally be enabled in the YAML header:\n---\ntitle: \"My document\"\nformat:\n  html:\n    toc: true\n    number-sections: true\n---",
    "crumbs": [
      "Selected Programming Topics",
      "x05-Creation of Reports with Quarto"
    ]
  },
  {
    "objectID": "slides/x5-quarto-intro.html#weblinks",
    "href": "slides/x5-quarto-intro.html#weblinks",
    "title": "x05-Creation of Reports with Quarto",
    "section": "Weblinks",
    "text": "Weblinks\n\nFormatted weblinks\n[further reading](https://rmarkdown.rstudio.com)\nis then formatted as: further reading\nExample\nThe [*Markdown Wikipedia page*](https://de.wikipedia.org/wiki/Markdown) contains examples.\nThe Markdown Wikipedia page contains examples.",
    "crumbs": [
      "Selected Programming Topics",
      "x05-Creation of Reports with Quarto"
    ]
  },
  {
    "objectID": "slides/x5-quarto-intro.html#images",
    "href": "slides/x5-quarto-intro.html#images",
    "title": "x05-Creation of Reports with Quarto",
    "section": "Images",
    "text": "Images\nImages are similar to weblinks, but with a leading !\n![figure title](mushrooms.jpg)\n\nfigure title",
    "crumbs": [
      "Selected Programming Topics",
      "x05-Creation of Reports with Quarto"
    ]
  },
  {
    "objectID": "slides/x5-quarto-intro.html#verbatim-text",
    "href": "slides/x5-quarto-intro.html#verbatim-text",
    "title": "x05-Creation of Reports with Quarto",
    "section": "Verbatim Text",
    "text": "Verbatim Text\nVerbatim text can be created with several methods:\n\nInline: enclose text within single backticks `verbatim text` \\(\\rightarrow\\) verbatim text\nIndentation by 4 spaces\nUse so-called fencing with ``` before and after a tect or code block.\n\n```\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy\neirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam\nvoluptua.\n```\nappears as:\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy\neirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam\nvoluptua.",
    "crumbs": [
      "Selected Programming Topics",
      "x05-Creation of Reports with Quarto"
    ]
  },
  {
    "objectID": "slides/x5-quarto-intro.html#tables",
    "href": "slides/x5-quarto-intro.html#tables",
    "title": "x05-Creation of Reports with Quarto",
    "section": "Tables",
    "text": "Tables\nSource code:\n| Right | Left | Default | Center |\n|------:|:-----|---------|:------:|\n|    12 | 34   |   56    |   78   |\n| this  | is   |   a     | table  |\nHTML Output:\n\n\n\nRight\nLeft\nDefault\nCenter\n\n\n\n\n12\n34\n56\n78\n\n\nthis\nis\na\ntable\n\n\n\nPDF output:\n\nStyle similar to a scientific paper.\n\nBigger or more complex tables: create the table in Excel or LibreOffice and add markdown formatting, or use R and kable to create the table from data.",
    "crumbs": [
      "Selected Programming Topics",
      "x05-Creation of Reports with Quarto"
    ]
  },
  {
    "objectID": "slides/x5-quarto-intro.html#citations",
    "href": "slides/x5-quarto-intro.html#citations",
    "title": "x05-Creation of Reports with Quarto",
    "section": "Citations",
    "text": "Citations\n\nCreate database file in .bib-format, e.g. references.bib\n\ncan be exported from Zotero\nput bibliography file to the document folder\n\nUse @bib_key-syntax\n\ntextual citation: American Psychological Association (2020b) \\(\\leftarrow\\) @APA2020b\nparenthetical citation: (American Psychological Association, 2020a) \\(\\leftarrow\\) [@APA2020a]\n\n\nDeclare bibliography in YAML header\nbibliography: references.bib\ncsl: apa\n\nand optionally a .csl-style e.g. apa.csl, that is copied to the folder of the document\ncsl styles can be found here: https://citationstyles.org/authors/",
    "crumbs": [
      "Selected Programming Topics",
      "x05-Creation of Reports with Quarto"
    ]
  },
  {
    "objectID": "slides/x5-quarto-intro.html#mathematical-formulae",
    "href": "slides/x5-quarto-intro.html#mathematical-formulae",
    "title": "x05-Creation of Reports with Quarto",
    "section": "Mathematical Formulae",
    "text": "Mathematical Formulae\n\nMarkdown and Quarto support a subset of the LaTeX formula syntax\n\nInline formula\n$s_x = \\frac{\\sum_{i=1}^{N} (x_i - \\bar{x})^2}{N-1}$ \\(\\quad \\rightarrow \\qquad s_x = \\frac{\\sum_{i=1}^{N} (x_i - \\bar{x})^2}{N-1}\\)\n #### Display formula\n$$s_x = \\frac{\\sum_{i=1}^{N} (x_i - \\bar{x})^2}{N-1}$$\n\\[s_x = \\frac{\\sum_{i=1}^{N} (x_i - \\bar{x})^2}{N-1}\\]\nMathematical symbols\n\\(\\rightarrow, \\le, \\approx, \\mu, \\delta, \\int, \\infty, \\mathrm{m^3s^{-1}}\\)\n$\\rightarrow, \\le, \\approx, \\mu, \\delta, \\int, \\infty, \\mathrm{m^3s^{-1}}$",
    "crumbs": [
      "Selected Programming Topics",
      "x05-Creation of Reports with Quarto"
    ]
  },
  {
    "objectID": "slides/x5-quarto-intro.html#more-maths-and-chemistry",
    "href": "slides/x5-quarto-intro.html#more-maths-and-chemistry",
    "title": "x05-Creation of Reports with Quarto",
    "section": "More maths and chemistry",
    "text": "More maths and chemistry\n\n\\[\\begin{align}\n\\frac{dX_1}{dt} &=    k_1 \\cdot X_1 -  k_2 X_1 X_2 \\\\\n\\frac{dX_2}{dt} &=  - k_4 \\cdot X_2 + k_3 X_1 X_2 \\\\\n\\end{align}\\]\n\\begin{align}\n\\frac{dX_1}{dt} &=  k_1 \\cdot X_1 -  k_2 X_1 X_2 \\\\\n\\frac{dX_2}{dt} &=  k_3 X_1 X_2 - k_4 \\cdot X_2 \\\\\n\\end{align}\n\n\\[\\rm 6CO_2 + 6H_2O \\rightarrow C_6H_{12}O_6 + 6O_2\n\\quad \\Delta H^0 = +2870 kJ mol^{-1}\\]\n$$\\rm 6CO_2 + 6H_2O \\rightarrow C_6H_{12}O_6 + 6O_2 \\quad \\Delta H^0 = +2870 kJ mol^{-1}$$",
    "crumbs": [
      "Selected Programming Topics",
      "x05-Creation of Reports with Quarto"
    ]
  },
  {
    "objectID": "slides/x5-quarto-intro.html#embedding-of-r-in-quarto-documents",
    "href": "slides/x5-quarto-intro.html#embedding-of-r-in-quarto-documents",
    "title": "x05-Creation of Reports with Quarto",
    "section": "Embedding of R in Quarto Documents",
    "text": "Embedding of R in Quarto Documents\n\nCreate a Quarto template from the File menu in RStudio. Then make your changes and click the Render button. Then, a document will be generated that includes both content as well as the output of any embedded R code chunks.\n\nThen embed your own R code chunks like this:\n```{r iris_summary}\nsummary(iris)\n```\n To show both, the code and the output\n\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50",
    "crumbs": [
      "Selected Programming Topics",
      "x05-Creation of Reports with Quarto"
    ]
  },
  {
    "objectID": "slides/x5-quarto-intro.html#tables-from-r",
    "href": "slides/x5-quarto-intro.html#tables-from-r",
    "title": "x05-Creation of Reports with Quarto",
    "section": "Tables from R",
    "text": "Tables from R\n\nIf you want to include real tables, you can create the table in R and then format it with knitr::kable\n\n```{r iris_table}\nknitr::kable(iris[1:4, ])\n```\n\n\n\n\n\nSepal.Length\nSepal.Width\nPetal.Length\nPetal.Width\nSpecies\n\n\n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n\n\n\nThe kable function has several functions for configuring table layout, see kable help page for details.",
    "crumbs": [
      "Selected Programming Topics",
      "x05-Creation of Reports with Quarto"
    ]
  },
  {
    "objectID": "slides/x5-quarto-intro.html#include-plots",
    "href": "slides/x5-quarto-intro.html#include-plots",
    "title": "x05-Creation of Reports with Quarto",
    "section": "Include Plots",
    "text": "Include Plots\nYou can also embed plots, for example:\n```{r iris_sepal}\nplot(Sepal.Width ~ Sepal.Length, data=iris, pch=16, col=Species)\n```",
    "crumbs": [
      "Selected Programming Topics",
      "x05-Creation of Reports with Quarto"
    ]
  },
  {
    "objectID": "slides/x5-quarto-intro.html#suppress-code",
    "href": "slides/x5-quarto-intro.html#suppress-code",
    "title": "x05-Creation of Reports with Quarto",
    "section": "Suppress Code",
    "text": "Suppress Code\nThe code chunks can be modified with additional options. In the following example the figure size is adjusted and an option echo = FALSE was added to prevent printing of the R code that generated the plot.\n```{r iris_sepal3, fig.width=3, fig.height=3, echo=FALSE}\nplot(Sepal.Width ~ Sepal.Length, data=iris, pch=16, col=Species)\n```\nShows the plot without the code:",
    "crumbs": [
      "Selected Programming Topics",
      "x05-Creation of Reports with Quarto"
    ]
  },
  {
    "objectID": "slides/x5-quarto-intro.html#flowcharts-and-graphs",
    "href": "slides/x5-quarto-intro.html#flowcharts-and-graphs",
    "title": "x05-Creation of Reports with Quarto",
    "section": "Flowcharts and graphs",
    "text": "Flowcharts and graphs\n\n… can be created with the DiagrammeR package that supports the graphviz language.",
    "crumbs": [
      "Selected Programming Topics",
      "x05-Creation of Reports with Quarto"
    ]
  },
  {
    "objectID": "slides/x5-quarto-intro.html#r-code-of-the-flowchart",
    "href": "slides/x5-quarto-intro.html#r-code-of-the-flowchart",
    "title": "x05-Creation of Reports with Quarto",
    "section": "R code of the flowchart",
    "text": "R code of the flowchart\n\nlibrary(\"DiagrammeR\")\ngrViz(\"digraph pandoc {\n         graph [rankdir = LR]\n           node [shape = 'box']\n                Markdown HTML PDF Word\n           node [shape = cds]\n             pandoc\n           node [shape = oval]\n             figs bib\n           edge [penwidth=2]\n             Markdown -&gt; pandoc\n             {figs bib} -&gt; {pandoc}\n             pandoc -&gt; {HTML PDF Word}\n}\")\nMore at: https://graphviz.org/",
    "crumbs": [
      "Selected Programming Topics",
      "x05-Creation of Reports with Quarto"
    ]
  },
  {
    "objectID": "slides/x5-quarto-intro.html#further-reading",
    "href": "slides/x5-quarto-intro.html#further-reading",
    "title": "x05-Creation of Reports with Quarto",
    "section": "Further reading",
    "text": "Further reading\n\n\\(\\rightarrow\\) Quarto cheat sheetFor more details, see https://quarto.org and R Core Team (2024)“, RStudio Team (2021), Xie (2015) and The Quarto Dev Team (2024).\nThesis templates for Hydrobiology students at TU Dresden: https://github.com/tpetzoldt/hyb-tud-thesis-starterkit in Word, Latex and Quarto format. It may also be useful for you.",
    "crumbs": [
      "Selected Programming Topics",
      "x05-Creation of Reports with Quarto"
    ]
  },
  {
    "objectID": "slides/x5-quarto-intro.html#references",
    "href": "slides/x5-quarto-intro.html#references",
    "title": "x05-Creation of Reports with Quarto",
    "section": "References",
    "text": "References\n\n\n\n\nAmerican Psychological Association. (2020a). Concise guide to APA style: The official APA style guide for students (7th ed.).\n\n\nAmerican Psychological Association. (2020b). Publication manual of the American Psychological Association: The official guide to APA style. (7th ed.).\n\n\nR Core Team. (2024). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRStudio Team. (2021). RStudio: Integrated development environment for R. RStudio, PBC. http://www.rstudio.com/\n\n\nThe Quarto Dev Team. (2024). Quarto. An open-source scientific and technical publishing system. https://quarto.org\n\n\nWikipedia. (2022). Markdown. Wikipedia. https://en.wikipedia.org/w/index.php?title=Markdown&oldid=1079645429\n\n\nXie, Y. (2015). Dynamic documents with R and knitr (2nd ed.). Chapman; Hall/CRC. https://yihui.org/knitr/",
    "crumbs": [
      "Selected Programming Topics",
      "x05-Creation of Reports with Quarto"
    ]
  },
  {
    "objectID": "slides/x3-r-functions.html#functions-bring-life-to-the-r-language",
    "href": "slides/x3-r-functions.html#functions-bring-life-to-the-r-language",
    "title": "x3-Functions Everywhere",
    "section": "Functions bring life to the R language",
    "text": "Functions bring life to the R language\n\nsin(x), log(x), plot(x, y), summary(x), anova(lm.object), mean(x), monod(S, vmax, ks), simulate_phytoplankton(N, P, T, Zoo, ...)\n\nFunctions in R\n\nhave a name, followed by parenthesis ()\ncan have 1, 2 or more arguments (or no argument)\nusually return something (an object)\ncan have side-effects (e.g. plotting)",
    "crumbs": [
      "Selected Programming Topics",
      "x3-Functions Everywhere"
    ]
  },
  {
    "objectID": "slides/x3-r-functions.html#what-are-functions",
    "href": "slides/x3-r-functions.html#what-are-functions",
    "title": "x3-Functions Everywhere",
    "section": "What are functions",
    "text": "What are functions\n\nParentheses and arguments\n\nall functions are followed by parentheses and arguments\nfunctions: log(x) par()\npar &lt;- c(a=5, b=3)\n\n\\(\\rightarrow\\) here, par is a variable, c() a function\nReturn value and/or side effect\n\nsin(x), log(x), mean(x) are functions with return value\nprint(x), plot(x, y) are functions with side effect\nhist(x) is a function with both, side effect and return value\n\nPredefined and user-defined functions\n\npredefined: available in R\nuser defined: users become programmers",
    "crumbs": [
      "Selected Programming Topics",
      "x3-Functions Everywhere"
    ]
  },
  {
    "objectID": "slides/x3-r-functions.html#arguments-of-functions",
    "href": "slides/x3-r-functions.html#arguments-of-functions",
    "title": "x3-Functions Everywhere",
    "section": "Arguments of functions",
    "text": "Arguments of functions\nUsage\n\ndnorm(x, mean = 0, sd = 1, log = FALSE)\npnorm(q, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)\nqnorm(p, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)\nrnorm(n, mean = 0, sd = 1)\n\n\n\n\n\n\n\n\nx, q\nvector of quantiles.\n\n\np\nvector of probabilities.\n\n\nn\nnumber of observations. If length(n) &gt; 1, the length is taken to be …\n\n\nlog.p\nif TRUE, probabilities p are given as log(p).\n\n\nlower.tail\nif TRUE (default), …\n\n\n\nArguments\n\nrequired arguments: have no default\noptional arguments: have default values\nnamed arguments: argument mathing with = allows to specify arguments in arbitrary order\nargument order: arguments can occur without names when in defined order\n“…”: dots-arguments are passed down to other called functions",
    "crumbs": [
      "Selected Programming Topics",
      "x3-Functions Everywhere"
    ]
  },
  {
    "objectID": "slides/x3-r-functions.html#examples",
    "href": "slides/x3-r-functions.html#examples",
    "title": "x3-Functions Everywhere",
    "section": "Examples",
    "text": "Examples\n\n\n\nrnorm(10)                       # x given, other arguments = defaults\nrnorm(10, 0, 1)                 # order matters\nrnorm(n = 10, mean = 0, sd = 1) # use argument names\nrnorm(10, sd = 1, mean = 0)     # named arguments in arbitrary order\nrnorm(10, m = 5, s = 1)         # abbreviated arguments: = bad style\nargs(rnorm)                     # all arguments from rnorm",
    "crumbs": [
      "Selected Programming Topics",
      "x3-Functions Everywhere"
    ]
  },
  {
    "objectID": "slides/x3-r-functions.html#the-ellipsis-argument",
    "href": "slides/x3-r-functions.html#the-ellipsis-argument",
    "title": "x3-Functions Everywhere",
    "section": "The ellipsis argument",
    "text": "The ellipsis argument\n\nplot(x, y, ...)\n\n\nSome functions have a … argument, called “ellipsis”.\nThis means that additional arguments are passed to other functions.\nMakes R flexible and extensible, but is sometimes tricky.\n\n\npar(mfrow=c(1, 3))\nx &lt;- 1:10; y &lt;- rnorm(10)\nplot(x, y)\nplot(x, y, type = \"h\")\nplot(x, y, type = \"s\", col=\"red\")",
    "crumbs": [
      "Selected Programming Topics",
      "x3-Functions Everywhere"
    ]
  },
  {
    "objectID": "slides/x3-r-functions.html#plot.default",
    "href": "slides/x3-r-functions.html#plot.default",
    "title": "x3-Functions Everywhere",
    "section": "plot.default",
    "text": "plot.default\n\nplot(x, y = NULL, type = \"p\",  xlim = NULL, ylim = NULL,\n     log = \"\", main = NULL, sub = NULL, xlab = NULL, ylab = NULL,\n     ann = par(\"ann\"), axes = TRUE, frame.plot = axes,\n     panel.first = NULL, panel.last = NULL, asp = NA, ...)\n\nObject orientation\n\nplot is a generic function\nworks automagic differently for different classes of objects\nplot.default is the basic function\n... see ?par for additional graphical parameters, e.g.:\n\n\n\n\ncol\ncolor\n\n\nbg\nbackground color for two-color symbols\n\n\npch\nsymbol (plotting character)\n\n\ncex\nsize of symbol (character extension)\n\n\nlty\nline type\n\n\nlwd\nline width",
    "crumbs": [
      "Selected Programming Topics",
      "x3-Functions Everywhere"
    ]
  },
  {
    "objectID": "slides/x3-r-functions.html#a-user-defined-monod-function",
    "href": "slides/x3-r-functions.html#a-user-defined-monod-function",
    "title": "x3-Functions Everywhere",
    "section": "A user-defined Monod function",
    "text": "A user-defined Monod function\n\n\ndescribes substrate dependence of biochemical turnover\nwidely used in biochemistry and in models\ne.g. organic matter turnover in wastewater treatment\n\n\\[\nv = \\frac{v_{max} \\cdot S}{k_S + S}\n\\]\n\npar(mar=c(4,4,1,1))\npar(mfrow=c(3, 1))\nmonod &lt;- function(S, vmax, ks) {\n  vmax * S / (ks + S)\n}\n\n\nS &lt;- 1:10\nP &lt;- seq(0, 20, 0.1)\nkP &lt;- 5; mumax &lt;- 1.2;\n\n## different ways to call the function\nplot(S, monod(S, 2, 2))                # simple call\nplot(P, monod(S=P, vmax=mumax, ks=kP)) # named arguments\nplot(P, monod(P, mumax, kP))           # argument position\n\n\nnames of caller and function can be different",
    "crumbs": [
      "Selected Programming Topics",
      "x3-Functions Everywhere"
    ]
  },
  {
    "objectID": "slides/x3-r-functions.html#seasonal-light-intensity-in-dresden",
    "href": "slides/x3-r-functions.html#seasonal-light-intensity-in-dresden",
    "title": "x3-Functions Everywhere",
    "section": "Seasonal Light Intensity in Dresden",
    "text": "Seasonal Light Intensity in Dresden\n\n\\[\nI_t = 997 - 816 \\cos(2 \\pi t / 365) + 126 \\sin(2 \\pi t / 365)\n\\]\n\nFunctions as a knowledge base\n\nput knowledge in function and use it\nforget what is inside\n\n\n\nrad &lt;- function(t) {\n  ## fill equation in\n}\n\nt &lt;- 1:365\nplot(t, rad(t), type = \"l\")",
    "crumbs": [
      "Selected Programming Topics",
      "x3-Functions Everywhere"
    ]
  },
  {
    "objectID": "slides/x3-r-functions.html#oxygen-saturation-in-fresh-and-sea-water",
    "href": "slides/x3-r-functions.html#oxygen-saturation-in-fresh-and-sea-water",
    "title": "x3-Functions Everywhere",
    "section": "Oxygen saturation in fresh and sea water",
    "text": "Oxygen saturation in fresh and sea water\n\\[\nc_{O_2, 100\\%} = ... ?\n\\]\n\no2sat &lt;- function(t) {\n  K &lt;- t + 273.15 # Celsius to Kelvin\n  exp(-139.34411 + (157570.1/K) - (66423080/K^2) +\n   (1.2438e+10/K^3) - (862194900000/K^4))\n}\n\no2sat(20)\n\n[1] 9.092426\n\n\n A more precise formula is found in package marelac\n\nlibrary(marelac)\ngas_O2sat(t = 20, S = 0, method = \"APHA\")\n\n[1] 9.092426\n\n\nconsult ?gas_O2sat for citations.",
    "crumbs": [
      "Selected Programming Topics",
      "x3-Functions Everywhere"
    ]
  },
  {
    "objectID": "slides/x3-r-functions.html#local-and-global-variables",
    "href": "slides/x3-r-functions.html#local-and-global-variables",
    "title": "x3-Functions Everywhere",
    "section": "Local and global variables",
    "text": "Local and global variables\n\nVariables in a function are local:\n\nnot visible from outside.\nno collisions with existing variables in the calling environment\n\nLexical Scoping\n\nfunctions can see variables of the calling function\nuseful for interactive work\ndangerous for (exported) functions in packages\nexcept in special cases, e.g. for functions within functions",
    "crumbs": [
      "Selected Programming Topics",
      "x3-Functions Everywhere"
    ]
  },
  {
    "objectID": "slides/x3-r-functions.html#local-and-global-variables-ii",
    "href": "slides/x3-r-functions.html#local-and-global-variables-ii",
    "title": "x3-Functions Everywhere",
    "section": "Local and global variables II",
    "text": "Local and global variables II\n\n\nrm(list = ls()) # remove all objects\no2sat &lt;- function(t) {\n  K &lt;- t + 273.15 # Celsius to Kelvin\n  exp(-139.34411 + (157570.1/K) - (66423080/K^2) +\n   (1.2438e+10/K^3) - (862194900000/K^4))\n}\n\no2sat(20)\nK\n\nK &lt;- 0\no2sat(20)\n\nNow outcomment:\n\n# K &lt;- t + 273.15\n\nand try again.",
    "crumbs": [
      "Selected Programming Topics",
      "x3-Functions Everywhere"
    ]
  },
  {
    "objectID": "slides/x3-r-functions.html#logistic-growth",
    "href": "slides/x3-r-functions.html#logistic-growth",
    "title": "x3-Functions Everywhere",
    "section": "Logistic growth",
    "text": "Logistic growth\n\nThe logistic growth function describes saturated growth of a population abundance \\(N_t\\), dependent of an initial value \\(N_0\\), growth rate \\(r\\) and carrying capacity \\(K\\).\n\\[\nN_t = \\frac{K N_0 e^{rt}}{K + N_0 (e^{rt}-1)}\n\\]\n\nlogistic &lt;- function(t, r, K, N0) {\n  K*N0*exp(r*t)/(K+N0*(exp(r*t)-1))\n}\n\n\nmu &lt;- 0.1; K = 10; N0 = 0.1\ntimes &lt;- 1:100",
    "crumbs": [
      "Selected Programming Topics",
      "x3-Functions Everywhere"
    ]
  },
  {
    "objectID": "slides/x3-r-functions.html#functional-response-types-in-ecology",
    "href": "slides/x3-r-functions.html#functional-response-types-in-ecology",
    "title": "x3-Functions Everywhere",
    "section": "Functional response types in Ecology",
    "text": "Functional response types in Ecology\n\nHolling type I \\(P = \\min(k \\cdot N, P_{max})\\)\nHolling type II \\(P = \\frac{\\alpha N}{1 + \\alpha H N}\\)\nHolling type III \\(P = \\frac{\\alpha N^b}{1 + \\alpha H N^b}\\)\n\nwith\n\n\n\n\\(P\\)\npredation rate\n\n\n\\(N\\)\nabundance of prey\n\n\n\\(P_{max}\\)\nmaximum predation rate\n\n\n\\(k\\)\na constant\n\n\n\\(\\alpha\\)\nattack rate\n\n\n\\(H\\)\nhandling time\n\n\n\\(b\\)\nexponent \\(&gt;1\\)\n\n\n\n\nWrite a function for each functional reponse type and plot it.\nWrite a universal function for all types.",
    "crumbs": [
      "Selected Programming Topics",
      "x3-Functions Everywhere"
    ]
  },
  {
    "objectID": "slides/x3-r-functions.html#further-reading",
    "href": "slides/x3-r-functions.html#further-reading",
    "title": "x3-Functions Everywhere",
    "section": "Further Reading",
    "text": "Further Reading\n\nMore presentations\n\nR Basics\nGraphics in R\n\nManuals\nMore details in the official R manuals, especially in An Introduction to R\nVideos\nMany videos can be found on Youtube, at the Posit webpage and somewhere else.",
    "crumbs": [
      "Selected Programming Topics",
      "x3-Functions Everywhere"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#r-is-more-convenient-with-rstudio",
    "href": "slides/x1-r-basics.html#r-is-more-convenient-with-rstudio",
    "title": "x1-R Basics",
    "section": "R is more convenient with RStudio",
    "text": "R is more convenient with RStudio",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#r-and-rstudio",
    "href": "slides/x1-r-basics.html#r-and-rstudio",
    "title": "x1-R Basics",
    "section": "R and RStudio",
    "text": "R and RStudio\n\nEngine and Control\n\nR The main engine for computations and graphics.\nRstudio the IDE (integrated development environment) that embeds and controls R and provides additional facilities.\nR can also be used without RStudio.\n\n\nCitation\nCite R and optionally RStudio.\nR Core Team (2022). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. https://www.R-project.org/\nRStudio Team (2022). RStudio: Integrated Development Environment for R. RStudio, PBC, Boston, MA URL http://www.rstudio.com/",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#expressions-and-assignments",
    "href": "slides/x1-r-basics.html#expressions-and-assignments",
    "title": "x1-R Basics",
    "section": "Expressions and Assignments",
    "text": "Expressions and Assignments\n\n\nExpression\n\n\n1 - pi + exp(1.7)\n\n[1] 3.332355\n\n\n\n\nresult is printed to the screen\nthe [1] indicates that the value shown at the beginning of the line is the first (and here the only) element\n\n\nAssignment\n\n\na &lt;- 1 - pi + exp(1.7)\n\n\n\nThe expression on the left hand side is assigned to the variable on the right.\nThe arrow is spelled as “a gets …”\nTo avoid confusion: use &lt;- for assignment and let = for parameter matching",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#constants-variables-and-assignments",
    "href": "slides/x1-r-basics.html#constants-variables-and-assignments",
    "title": "x1-R Basics",
    "section": "Constants, variables and assignments",
    "text": "Constants, variables and assignments\nAssignment of constants and variables to a variable\n\n\nx &lt;- 1.3      # numeric constant\ny &lt;- \"hello\"  # character constant\na &lt;- x        # a and x both variables\n\nAssignment in opposite direction (rarely used)\n\nx -&gt; b\n\nMultiple assignment\n\nx &lt;- a &lt;- b\n\n\nDo not use the following constructs\n\n# Equal sign has two meanings: parameter matching and assignment\n# - Don't use it for assignment!\nx = a\n\n# Super assignment, useful for programmers in special cases\nx &lt;&lt;- 2",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#objects-constants-variables",
    "href": "slides/x1-r-basics.html#objects-constants-variables",
    "title": "x1-R Basics",
    "section": "Objects, constants, variables",
    "text": "Objects, constants, variables\n\nEverything stored in R’s memory is an object:\n\ncan be simple or complex\ncan be constants or variables\nconstants: 1, 123, 5.6, 5e7, “hello”\nvariables: can change their value, are referenced by variable names\n\n\n\nx &lt;- 2.0 # x is a variable, 2.0 is a constant\n\nA syntactically valid variable name consists of:\n\nletters, numbers, underline (_), dot (.)\nstarts with a letter or the dot\nif starting with the dot, not followed by a number\n\nSpecial characters, except _ and . (underscore and dot) are not allowed.\nInternational characters (e.g German umlauts ä, ö, ü, …) are possible, but not recommended.",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#allowed-and-disallowed-identifiers",
    "href": "slides/x1-r-basics.html#allowed-and-disallowed-identifiers",
    "title": "x1-R Basics",
    "section": "Allowed and disallowed identifiers",
    "text": "Allowed and disallowed identifiers\n\ncorrect:\n\nx, y, X, x1, i, j, k\nvalue, test, myVariableName, do_something\n`.hidden, .x1``\n\nforbidden:\n\n1x, .1x (starts with a number)\n!, @, \\$, #, space, comma, semicolon and other special characters\n\nreserved words cannot be used as variable names:\n\nif, else, repeat, while, function, for, in, next, break\nTRUE, FALSE, NULL, Inf, NaN, NA, NA_integer_, NA_real_, NA_complex_, NA_character\\_\n..., ..1, ..2\n\nNote: R is case sensitive, x and X, value and Value are different.",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#operators",
    "href": "slides/x1-r-basics.html#operators",
    "title": "x1-R Basics",
    "section": "Operators",
    "text": "Operators\n\n\n\n\n\n\noperator\nsymbol\n\n\n\n\nAddition\n+\n\n\nSubtraction\n-\n\n\nNegation\n-\n\n\nMultiplication\n*\n\n\nDivision\n/\n\n\nModulo\n%%\n\n\nInteger Divison\n%/%\n\n\nPower\n^\n\n\nMatrix product\n%*%\n\n\nOuter product\n%o%\n\n\n\n\n\n\n\n\n\n\n\noperator\nsymbol\n\n\n\n\nNegation\n!\n\n\nAnd\n&\n\n\nOr\n|\n\n\nEqual\n==\n\n\nUnequal\n!=\n\n\nLess than\n&lt;\n\n\nGreater than\n&gt;\n\n\nLess or equal\n&lt;=\n\n\nGreater or equal\n&gt;=\n\n\nAssignment\n&lt;-\n\n\nElement of a list\n$\n\n\nPipeline\n|&gt;\n\n\n\n\n\n… and more",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#functions",
    "href": "slides/x1-r-basics.html#functions",
    "title": "x1-R Basics",
    "section": "Functions",
    "text": "Functions\nPre-defined functions:\n\nwith return value: sin(x), log(x)\nwith side effect: plot(x), print(x)\nwith both return value and side efect: hist(x)\n\nArguments: mandatory or optional, un-named or named\n\nplot(1:4, c(3, 4, 3, 6), type = \"l\", col = \"red\")\nif named arguments are used (with the “=” sign), argument order does not matter\n\nUser-defined functions:\n\ncan be used to extend R\nwill be discussed later\n\n\\(\\rightarrow\\) Functions have always a name followed by arguments in round parentheses.",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#parentheses",
    "href": "slides/x1-r-basics.html#parentheses",
    "title": "x1-R Basics",
    "section": "Parentheses",
    "text": "Parentheses",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#vectors-matrices-and-arrays",
    "href": "slides/x1-r-basics.html#vectors-matrices-and-arrays",
    "title": "x1-R Basics",
    "section": "Vectors, matrices and arrays",
    "text": "Vectors, matrices and arrays\n\nvectors = 1D, matrices = 2D and arrays = n-dimensional\ndata are arranged into rows, columns, layers, …\ndata filled in column-wise, can be changed\ncreate vector\n\n\nx &lt;- 1:20\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n\n\n\nconvert it to matrix\n\n\ny &lt;- matrix(x, nrow = 5, ncol = 4)\ny\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    6   11   16\n[2,]    2    7   12   17\n[3,]    3    8   13   18\n[4,]    4    9   14   19\n[5,]    5   10   15   20\n\n\n\nback-convert (flatten) to vector\n\n\nas.vector(y) # flattens the matrix to a vector\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#vectors-matrices-and-arrays-ii",
    "href": "slides/x1-r-basics.html#vectors-matrices-and-arrays-ii",
    "title": "x1-R Basics",
    "section": "Vectors, matrices and arrays II",
    "text": "Vectors, matrices and arrays II\n\nrecycling rule if the number of elements is too small\n\n\nx &lt;- matrix(0, nrow=5, ncol=4)\nx\n\n     [,1] [,2] [,3] [,4]\n[1,]    0    0    0    0\n[2,]    0    0    0    0\n[3,]    0    0    0    0\n[4,]    0    0    0    0\n[5,]    0    0    0    0\n\nx &lt;- matrix(1:4, nrow=5, ncol=4)\nx\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    2    3    4\n[2,]    2    3    4    1\n[3,]    3    4    1    2\n[4,]    4    1    2    3\n[5,]    1    2    3    4",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#transpose-rows-and-columns",
    "href": "slides/x1-r-basics.html#transpose-rows-and-columns",
    "title": "x1-R Basics",
    "section": "Transpose rows and columns",
    "text": "Transpose rows and columns\n\nrow-wise creation of a matrix\n\n\nx &lt;- matrix(1:20, nrow = 5, ncol = 4, byrow = TRUE)\nx\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    2    3    4\n[2,]    5    6    7    8\n[3,]    9   10   11   12\n[4,]   13   14   15   16\n[5,]   17   18   19   20\n\n\n\ntranspose of a matrix\n\n\nx &lt;- t(x)\nx\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    1    5    9   13   17\n[2,]    2    6   10   14   18\n[3,]    3    7   11   15   19\n[4,]    4    8   12   16   20",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#access-array-elements",
    "href": "slides/x1-r-basics.html#access-array-elements",
    "title": "x1-R Basics",
    "section": "Access array elements",
    "text": "Access array elements\n\n\na three dimensional array\nrow, column, layer/page\nsub-matrices (slices)\n\n\nx &lt;- array(1:24, dim=c(3, 4, 2))\nx\n\n, , 1\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    4    7   10\n[2,]    2    5    8   11\n[3,]    3    6    9   12\n\n, , 2\n\n     [,1] [,2] [,3] [,4]\n[1,]   13   16   19   22\n[2,]   14   17   20   23\n[3,]   15   18   21   24\n\n\n\n\n\n\nelements of a matrix or array\n\n\nx[1, 3, 1] # single element\n\n[1] 7\n\nx[ , 3, 1] # 3rd column of 1st layer\n\n[1] 7 8 9\n\nx[ ,  , 2] # second layer\n\n     [,1] [,2] [,3] [,4]\n[1,]   13   16   19   22\n[2,]   14   17   20   23\n[3,]   15   18   21   24\n\nx[1,  ,  ] # another slice\n\n     [,1] [,2]\n[1,]    1   13\n[2,]    4   16\n[3,]    7   19\n[4,]   10   22",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#reordering-and-indirect-indexing",
    "href": "slides/x1-r-basics.html#reordering-and-indirect-indexing",
    "title": "x1-R Basics",
    "section": "Reordering and indirect indexing",
    "text": "Reordering and indirect indexing\n\nOriginal matrix\n\n(x &lt;- matrix(1:20, nrow = 4))\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    1    5    9   13   17\n[2,]    2    6   10   14   18\n[3,]    3    7   11   15   19\n[4,]    4    8   12   16   20\n\n\nInverted row order\n\nx[4:1, ]\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    4    8   12   16   20\n[2,]    3    7   11   15   19\n[3,]    2    6   10   14   18\n[4,]    1    5    9   13   17\n\n\n\nIndirect index\n\nx[c(1, 2, 1, 2), c(1, 3, 2, 5, 4)]\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    1    9    5   17   13\n[2,]    2   10    6   18   14\n[3,]    1    9    5   17   13\n[4,]    2   10    6   18   14\n\n\nLogical selection\n\nx[c(FALSE, TRUE, FALSE, TRUE), ]\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    2    6   10   14   18\n[2,]    4    8   12   16   20\n\n\nSurprise?\n\nx[c(0, 1, 0, 1), ]\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    1    5    9   13   17\n[2,]    1    5    9   13   17",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#matrix-multiplication-explained",
    "href": "slides/x1-r-basics.html#matrix-multiplication-explained",
    "title": "x1-R Basics",
    "section": "Matrix multiplication explained",
    "text": "Matrix multiplication explained\n\n\nTwo matrices: A and B\n\nA &lt;- matrix(c(1, 2, 3,\n              5, 4, 2), \n            nrow = 2, byrow = TRUE)\n\nB &lt;- matrix(c(1, 2, 3, 4,\n              6, 8, 4, 2,\n              3, 1, 3, 2), \n            nrow = 3, byrow = TRUE)\n\nMultiplication: \\(A \\cdot B\\)\n\nA %*% B\n\n     [,1] [,2] [,3] [,4]\n[1,]   22   21   20   14\n[2,]   35   44   37   32",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#transpose-and-inverse",
    "href": "slides/x1-r-basics.html#transpose-and-inverse",
    "title": "x1-R Basics",
    "section": "Transpose and inverse",
    "text": "Transpose and inverse\nMatrix\n\nX &lt;- matrix(c(1, 2, 3, \n              4, 3, 2, \n              5, 4, 6),\n            nrow = 3)\nX\n\n     [,1] [,2] [,3]\n[1,]    1    4    5\n[2,]    2    3    4\n[3,]    3    2    6\n\n\nTranspose\n\nt(X)\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    3    2\n[3,]    5    4    6\n\n\nInverse (\\(X^{-1}\\))\n\nsolve(X)\n\n\n\n        [,1]    [,2]    [,3]\n[1,] -0.6667  0.9333 -0.0667\n[2,]  0.0000  0.6000 -0.4000\n[3,]  0.3333 -0.6667  0.3333",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#multiplication-of-a-matrix-with-its-inverse",
    "href": "slides/x1-r-basics.html#multiplication-of-a-matrix-with-its-inverse",
    "title": "x1-R Basics",
    "section": "Multiplication of a matrix with its inverse",
    "text": "Multiplication of a matrix with its inverse\n\n\n\\[X \\cdot X^{-1} = I\\]\n\nX %*% solve(X)\n\n     [,1] [,2] [,3]\n[1,]    1    0    0\n[2,]    0    1    0\n[3,]    0    0    1\n\n\n\n\n\\(I\\): identity matrix",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#linear-system-of-equations",
    "href": "slides/x1-r-basics.html#linear-system-of-equations",
    "title": "x1-R Basics",
    "section": "Linear system of equations",
    "text": "Linear system of equations\n\n\\[\\begin{align}\n3x && +  && 2y   && -  && z  && =  && 1 \\\\\n2x && -  && 2y   && +  && 4z && =  && -2 \\\\\n-x && +  && 1/2y && -  && z  && =  && 0\n\\end{align}\\]\n\n\nA &lt;- matrix(c(3,  2,   -1,\n             2,  -2,    4,\n            -1,   0.5, -1), nrow=3, byrow=TRUE)\nb &lt;- c(1, -2, 0)\n\n\n\\[\\begin{align}\nAx &= b\\\\\nx  &= A^{-1}b\n\\end{align}\\]\n\n\nsolve(A) %*% b\n\n     [,1]\n[1,]    1\n[2,]   -2\n[3,]   -2",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#data-frames",
    "href": "slides/x1-r-basics.html#data-frames",
    "title": "x1-R Basics",
    "section": "Data frames",
    "text": "Data frames\n\nrepresent tabular data\nsimilar to matrices, but different types of data in columns possible\ntypically imported from a file with read.table or read.csv\n\n\n\ncities &lt;- read.csv(\"cities.csv\")\ncities\n\n\n\n\n               Name    Country Population Latitude Longitude IsCapital\n1  Fürstenfeldbruck    Germany      34033  48.1690   11.2340     FALSE\n2             Dhaka Bangladesh   13000000  23.7500   90.3700      TRUE\n3       Ulaanbaatar   Mongolia    3010000  47.9170  106.8830      TRUE\n4           Shantou      China    5320000  23.3500  116.6700     FALSE\n5           Kampala     Uganda    1659000   0.3310   32.5830      TRUE\n6           Cottbus    Germany     100000  51.7650   14.3280     FALSE\n7           Nairobi      Kenya    3100000   1.2833   36.8167      TRUE\n8             Hanoi    Vietnam    1452055  21.0300  105.8400      TRUE\n9          Bacgiang    Vietnam      53739  21.2800  106.1900     FALSE\n10       Addis Abba   Ethiopia    2823167   9.0300   38.7400      TRUE\n11        Hyderabad      India    3632094  17.4000   78.4800     FALSE\n\n\n\\(\\rightarrow\\) download data set",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#what-is-a-csv-file",
    "href": "slides/x1-r-basics.html#what-is-a-csv-file",
    "title": "x1-R Basics",
    "section": "What is a CSV file?",
    "text": "What is a CSV file?\n\ncomma separated values.\nfirst line contains column names\ndecimal is dec=\".\", column separator is sep=\",\"\n\nExample CSV file (Data from Wikipedia, 2023)\n\nName,Country,Population,Latitude,Longitude\nDhaka,Bangladesh,10278882,23.75,90.37\nUlaanbaatar,Mongolia,1672627,47.917,106.883\nShantou,China,5502031,23.35,116.67\nKampala,Uganda,1680600,0.331,32.583\nBerlin,Germany,3850809,52.52,13.405\nNairobi,Kenya,4672000,1.2833,36.8167\nHanoi,Vietnam,8435700,21.03,105.84\nAddis Abba,Ethiopia,3945000,9.03,38.74\nHyderabad,India,9482000,17.4,78.48\n\nHints\n\nsome countries use dec = \",\" and sep = \";\"\nExcel may export mixed style with dec = \".\" and sep = \";\"\ncomments above the header line can be skipped",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#different-read-funktions",
    "href": "slides/x1-r-basics.html#different-read-funktions",
    "title": "x1-R Basics",
    "section": "Different read-Funktions",
    "text": "Different read-Funktions\n\nR contains several read-functions for different file types.\nSome are more flexible, some more automatic, some faster, some more robust …\n\nTo avoid confusion, we use only the following:\nBase R\n\nread.table(): this is the most flexible standard function, see help file for details\nread.csv(): default options for standard csv files (with dec=\".\" and sep=,)\n\nTidyverse readr-package\n\nread_delim(): similar to read.table() but more modern, automatic and faster\nread_csv(): similar to read.csv() with more automatism, e.g. date detection",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#the-most-versatile-read.table",
    "href": "slides/x1-r-basics.html#the-most-versatile-read.table",
    "title": "x1-R Basics",
    "section": "The most versatile: read.table()",
    "text": "The most versatile: read.table()\n\nread.table(file, header = FALSE, sep = \"\", quote = \"\\\"'\",\n           dec = \".\", numerals = c(\"allow.loss\", \"warn.loss\", \"no.loss\"),\n           row.names, col.names, as.is = !stringsAsFactors, tryLogical = TRUE,\n           na.strings = \"NA\", colClasses = NA, nrows = -1,\n           skip = 0, check.names = TRUE, fill = !blank.lines.skip,\n           strip.white = FALSE, blank.lines.skip = TRUE,\n           comment.char = \"#\",\n           allowEscapes = FALSE, flush = FALSE,\n           stringsAsFactors = FALSE,\n           fileEncoding = \"\", encoding = \"unknown\", text, skipNul = FALSE)\n\nExamples\n\nread.table(\"cities.csv\", sep = \",\",  dec = \".\")  # same as read.csv\nread.table(\"cities.txt\", sep = \"\\t\", dec = \".\")  # tab delimited\nread.table(\"cities.csv\", sep = \";\",  dec = \",\")  # German csv\n\nread.table(\"cities.csv\", sep = \",\", dec = \".\", skip = 5) # skip first 5 lines",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#recommendation",
    "href": "slides/x1-r-basics.html#recommendation",
    "title": "x1-R Basics",
    "section": "Recommendation",
    "text": "Recommendation\n\nMost of our course examples are plain CSV files, so we can use read.csv() or read_csv().\n\n\nlibrary(\"readr\")\ncities &lt;- read_csv(\"cities.csv\")\ncities\n\n\n\n\n# A tibble: 11 × 6\n   Name             Country    Population Latitude Longitude IsCapital\n   &lt;chr&gt;            &lt;chr&gt;           &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;lgl&gt;    \n 1 Fürstenfeldbruck Germany         34033   48.2        11.2 FALSE    \n 2 Dhaka            Bangladesh   13000000   23.8        90.4 TRUE     \n 3 Ulaanbaatar      Mongolia      3010000   47.9       107.  TRUE     \n 4 Shantou          China         5320000   23.4       117.  FALSE    \n 5 Kampala          Uganda        1659000    0.331      32.6 TRUE     \n 6 Cottbus          Germany        100000   51.8        14.3 FALSE    \n 7 Nairobi          Kenya         3100000    1.28       36.8 TRUE     \n 8 Hanoi            Vietnam       1452055   21.0       106.  TRUE     \n 9 Bacgiang         Vietnam         53739   21.3       106.  FALSE    \n10 Addis Abba       Ethiopia      2823167    9.03       38.7 TRUE     \n11 Hyderabad        India         3632094   17.4        78.5 FALSE",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#data-import-assistant-of-rstudio",
    "href": "slides/x1-r-basics.html#data-import-assistant-of-rstudio",
    "title": "x1-R Basics",
    "section": "Data import assistant of RStudio",
    "text": "Data import assistant of RStudio\n\nFile –&gt; Import Dataset\nSeveral options are available:\n\n“From text (base)” uses the classical R functions\n“From text (readr)” is more modern and uses an add-on package\n“From Excel” can read Excel files if (and only if) they have a clear tabular structure",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#from-text-base",
    "href": "slides/x1-r-basics.html#from-text-base",
    "title": "x1-R Basics",
    "section": "From text (base)",
    "text": "From text (base)",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#from-text-readr",
    "href": "slides/x1-r-basics.html#from-text-readr",
    "title": "x1-R Basics",
    "section": "From text (readr)",
    "text": "From text (readr)",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#save-data-to-excel-compatible-format",
    "href": "slides/x1-r-basics.html#save-data-to-excel-compatible-format",
    "title": "x1-R Basics",
    "section": "Save data to Excel-compatible format",
    "text": "Save data to Excel-compatible format\nEnglish number format (“.” as decimal):\n\nwrite.table(cities, \"output.csv\", row.names = FALSE, sep=\",\")\n\nGerman number format (“,” as decimal):\n\nwrite.table(cities, \"output.csv\", row.names = FALSE, sep=\";\", dec=\",\")\n\n ## Creation of data frames\n\n\ntypical: read data from external file, e.g. csv-files.\nsmall data frames can be created inline in a script\n\nInline creation of a data frame\n\nclem &lt;- data.frame(\n  brand = c(\"EP\", \"EB\", \"EB\", \"EB\", \"EB\", \"EB\", \"EB\", \"EB\", \"EB\", \"EB\", \"EB\", \n            \"EB\", \"EB\", \"EB\", \"EP\", \"EP\", \"EP\", \"EP\", \"EP\", \"EP\", \"EP\", \"EB\", \"EP\"),\n  weight = c(88, 96, 100, 96, 90, 100, 92, 92, 102, 99, 86, 89, 99, 89, 75, 80, \n             81, 96, 82, 98, 80, 107, 88)\n)",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#conversion-between-matrices-and-data-frames",
    "href": "slides/x1-r-basics.html#conversion-between-matrices-and-data-frames",
    "title": "x1-R Basics",
    "section": "Conversion between matrices and data frames",
    "text": "Conversion between matrices and data frames\n\nMatrix to data frame\n\nx &lt;- matrix(1:16, nrow=4)\ndf &lt;- as.data.frame(x)\ndf\n\n  V1 V2 V3 V4\n1  1  5  9 13\n2  2  6 10 14\n3  3  7 11 15\n4  4  8 12 16\n\n\n\nData frame to matrix\n\nas.matrix(df)\n\n     V1 V2 V3 V4\n[1,]  1  5  9 13\n[2,]  2  6 10 14\n[3,]  3  7 11 15\n[4,]  4  8 12 16\n\n\n\nAppend column\n\ndf2 &lt;- cbind(df,\n         id = c(\"first\", \"second\", \"third\", \"fourth\")\n       )\n\nOr simply\n\ndf2$id &lt;- c(\"first\", \"second\", \"third\", \"fourth\")\n\n\nData frame with character column\n\nas.matrix(df2)\n\n     V1  V2  V3   V4   id      \n[1,] \"1\" \"5\" \" 9\" \"13\" \"first\" \n[2,] \"2\" \"6\" \"10\" \"14\" \"second\"\n[3,] \"3\" \"7\" \"11\" \"15\" \"third\" \n[4,] \"4\" \"8\" \"12\" \"16\" \"fourth\"\n\n\n\nall columns are now character\nmatrix does not support mixed data",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#selection-of-data-frame-columns",
    "href": "slides/x1-r-basics.html#selection-of-data-frame-columns",
    "title": "x1-R Basics",
    "section": "Selection of data frame columns",
    "text": "Selection of data frame columns\nCreate a data frame from a matrix\n\nx &lt;- matrix(1:16, nrow=4)\ndf &lt;- as.data.frame(x)\ndf\n\n  V1 V2 V3 V4\n1  1  5  9 13\n2  2  6 10 14\n3  3  7 11 15\n4  4  8 12 16\n\n\nAdd names to the columns\n\nnames(df) &lt;- c(\"N\", \"P\", \"O2\", \"C\")\ndf\n\n  N P O2  C\n1 1 5  9 13\n2 2 6 10 14\n3 3 7 11 15\n4 4 8 12 16\n\n\nSelect 3 columns and change order\n\ndf2 &lt;- df[c(\"C\", \"N\", \"P\")]\ndf2\n\n   C N P\n1 13 1 5\n2 14 2 6\n3 15 3 7\n4 16 4 8",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#data-frame-indexing-like-a-matrix",
    "href": "slides/x1-r-basics.html#data-frame-indexing-like-a-matrix",
    "title": "x1-R Basics",
    "section": "Data frame indexing like a matrix",
    "text": "Data frame indexing like a matrix\n\nA data frame\n\ndf\n\n  N P O2  C\n1 1 5  9 13\n2 2 6 10 14\n3 3 7 11 15\n4 4 8 12 16\n\n\nA single value\n\ndf[2, 3]\n\n[1] 10\n\n\nComplete column\n\ndf[,1]\n\n[1] 1 2 3 4\n\n\nComplete row\n\ndf[2,]\n\n  N P O2  C\n2 2 6 10 14\n\n\n\nConditional selection of rows\n\ndf[df$P &gt; 6, ]\n\n  N P O2  C\n3 3 7 11 15\n4 4 8 12 16\n\n\n\nDifferences between [], [[]] and $\n\ndf[\"P\"]     # a single column data frame\n\n  P\n1 5\n2 6\n3 7\n4 8\n\ndf[[\"P\"]]   # a vector\n\n[1] 5 6 7 8\n\ndf$P        # a vector\n\n[1] 5 6 7 8",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#lists-1",
    "href": "slides/x1-r-basics.html#lists-1",
    "title": "x1-R Basics",
    "section": "Lists",
    "text": "Lists\n\nmost flexible data type in R\ncan contain arbitrary data objects as elements of the list\nallows tree-like structure\n\nExamples\n\nOutput of many R functions, e.g. return value of hist:\n\n\nL &lt;- hist(rnorm(100), plot=FALSE)\nstr(L)\n\nList of 6\n $ breaks  : num [1:11] -3 -2.5 -2 -1.5 -1 -0.5 0 0.5 1 1.5 ...\n $ counts  : int [1:10] 1 1 6 14 15 17 20 12 10 4\n $ density : num [1:10] 0.02 0.02 0.12 0.28 0.3 0.34 0.4 0.24 0.2 0.08\n $ mids    : num [1:10] -2.75 -2.25 -1.75 -1.25 -0.75 -0.25 0.25 0.75 1.25 1.75\n $ xname   : chr \"rnorm(100)\"\n $ equidist: logi TRUE\n - attr(*, \"class\")= chr \"histogram\"",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#creation-of-lists",
    "href": "slides/x1-r-basics.html#creation-of-lists",
    "title": "x1-R Basics",
    "section": "Creation of lists",
    "text": "Creation of lists\n\nL1 &lt;- list(a=1:10, b=c(1,2,3), x=\"hello\")\n\nNested list (lists within a list)\n\nL2 &lt;- list(a=5:7, b=L1)\n\nstr shows tree-like structure\n\nstr(L2)\n\nList of 2\n $ a: int [1:3] 5 6 7\n $ b:List of 3\n  ..$ a: int [1:10] 1 2 3 4 5 6 7 8 9 10\n  ..$ b: num [1:3] 1 2 3\n  ..$ x: chr \"hello\"\n\n\n\nAccess to list elements by names\n\nL2$a\n\n[1] 5 6 7\n\nL2$b$a\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\n\n\n\nor with indices\n\nL2[1]   # a list with 1 element\n\n$a\n[1] 5 6 7\n\nL2[[1]] # content of 1st element\n\n[1] 5 6 7",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#lists-ii",
    "href": "slides/x1-r-basics.html#lists-ii",
    "title": "x1-R Basics",
    "section": "Lists II",
    "text": "Lists II\n\nConvert list to vector\n\n\nL &lt;- unlist(L2)\nstr(L)\n\n Named chr [1:17] \"5\" \"6\" \"7\" \"1\" \"2\" \"3\" \"4\" \"5\" \"6\" \"7\" \"8\" \"9\" \"10\" \"1\" ...\n - attr(*, \"names\")= chr [1:17] \"a1\" \"a2\" \"a3\" \"b.a1\" ...\n\n\n\n\nFlatten list (remove only top level of list)\n\n\nL &lt;- unlist(L2, recursive = FALSE)\nstr(L)\n\nList of 6\n $ a1 : int 5\n $ a2 : int 6\n $ a3 : int 7\n $ b.a: int [1:10] 1 2 3 4 5 6 7 8 9 10\n $ b.b: num [1:3] 1 2 3\n $ b.x: chr \"hello\"",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#naming-of-list-elements",
    "href": "slides/x1-r-basics.html#naming-of-list-elements",
    "title": "x1-R Basics",
    "section": "Naming of list elements",
    "text": "Naming of list elements\nDuring creation\n\nx &lt;- c(a=1.2, b=2.3, c=6)\nL &lt;- list(a=1:3, b=\"hello\")\n\nWith names-function\nOriginal names:\n\nnames(L)\n\n[1] \"a\" \"b\"\n\n\nRename list elements:\n\nnames(L) &lt;- c(\"numbers\", \"text\")\nnames(L)\n\n[1] \"numbers\" \"text\"   \n\n\nThe names-functions works also with vectors. The pre-defined vectors letters contains lower case and LETTERS uppercase letters:\n\nx &lt;- 1:5\nnames(x) &lt;- letters[1:5]\nx\n\na b c d e \n1 2 3 4 5",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#apply-a-function-to-multiple-rows-and-columns",
    "href": "slides/x1-r-basics.html#apply-a-function-to-multiple-rows-and-columns",
    "title": "x1-R Basics",
    "section": "Apply a function to multiple rows and columns",
    "text": "Apply a function to multiple rows and columns\n\nExample data frame\n\ndf  # data frame of previous slide\n\n  N P O2  C\n1 1 5  9 13\n2 2 6 10 14\n3 3 7 11 15\n4 4 8 12 16\n\n\nApply a function to all elements of a list\n\nlapply(df, mean)  # returns list\n\n$N\n[1] 2.5\n\n$P\n[1] 6.5\n\n$O2\n[1] 10.5\n\n$C\n[1] 14.5\n\nsapply(df, mean)  # returns vector\n\n   N    P   O2    C \n 2.5  6.5 10.5 14.5 \n\n\n\n\n\nRow wise apply\n\napply(df, MARGIN = 1, sum)\n\n[1] 28 32 36 40\n\n\nColumn wise apply\n\napply(df, MARGIN = 2, sum)\n\n N  P O2  C \n10 26 42 58 \n\n\nApply user defined function\n\nse &lt;- function(x)\n  sd(x)/sqrt(length(x))\n\nsapply(df, se)\n\n\n\n     N      P     O2      C \n0.6455 0.6455 0.6455 0.6455",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#for-loop",
    "href": "slides/x1-r-basics.html#for-loop",
    "title": "x1-R Basics",
    "section": "for-loop",
    "text": "for-loop\nA simple for-loop\n\n\nfor (i in 1:4) {\n  cat(i, 2*i, \"\\n\")\n}\n\n1 2 \n2 4 \n3 6 \n4 8 \n\n\n\nNested for-loops\n\n\nfor (i in 1:3) {\n  for (j in c(1,3,5)) {\n    cat(i, i*j, \"\\n\")\n  }\n}\n\n1 1 \n1 3 \n1 5 \n2 2 \n2 6 \n2 10 \n3 3 \n3 9 \n3 15",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#repeat-and-while-loops",
    "href": "slides/x1-r-basics.html#repeat-and-while-loops",
    "title": "x1-R Basics",
    "section": "repeat and while-loops",
    "text": "repeat and while-loops\nRepeat until a break condition occurs\n\n\nx &lt;- 1\nrepeat {\n x &lt;- 0.1*x\n cat(x, \"\\n\")\n if (x &lt; 1e-4) break\n}\n\n0.1 \n0.01 \n0.001 \n1e-04 \n1e-05 \n\n\nLoop as long as a whilecondition is TRUE:\n\nj &lt;- 1; x &lt;- 0\nwhile (j &gt; 1e-3) {\n  j &lt;- 0.1 * j\n  x &lt;- x + j\n  cat(j, x, \"\\n\")\n}\n\n0.1 0.1 \n0.01 0.11 \n0.001 0.111 \n1e-04 0.1111 \n\n\n\nIn many cases, loops can be avoided by using vectors and matrices or apply.",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#avoidable-loops",
    "href": "slides/x1-r-basics.html#avoidable-loops",
    "title": "x1-R Basics",
    "section": "Avoidable loops",
    "text": "Avoidable loops\n\nColumn means of a data frame\n\n## a data frame\ndf &lt;- data.frame(\n  N=1:4, P=5:8, O2=9:12, C=13:16\n)\n\n## loop\nm &lt;- numeric(4)\nfor(i in 1:4) {\n m[i] &lt;- mean(df[,i])\n}\nm\n\n[1]  2.5  6.5 10.5 14.5\n\n\n\\(\\rightarrow\\) easier without loop\n\nsapply(df, mean)\n\n   N    P   O2    C \n 2.5  6.5 10.5 14.5 \n\n\n… also possible colMeans\n\n\n\nAn infinite series:\n\\[\n\\sum_{k=1}^{\\infty}\\frac{(-1)^{k-1}}{2k-1} = 1 - \\frac{1}{3} + \\frac{1}{5} - \\frac{1}{7}\n\\]\n\nx &lt;- 0\nfor (k in seq(1, 1e5)) {\n  enum  &lt;- (-1)^(k-1)\n  denom &lt;- 2*k-1\n  x &lt;- x + enum/denom\n}\n4 * x\n\n[1] 3.141583\n\n\n\\(\\Rightarrow\\) Can you vectorize this?",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#unavoidable-loop",
    "href": "slides/x1-r-basics.html#unavoidable-loop",
    "title": "x1-R Basics",
    "section": "Unavoidable loop",
    "text": "Unavoidable loop\nThe same series:\n\\[\n\\sum_{k=1}^{\\infty}\\frac{(-1)^{k-1}}{2k-1} = 1 - \\frac{1}{3} + \\frac{1}{5} - \\frac{1}{7}\n\\]\n\nx &lt;- 0\nk &lt;- 0\nrepeat {\n  k &lt;- k + 1\n  enum  &lt;- (-1)^(k-1)\n  denom &lt;- 2*k-1\n  delta &lt;- enum/denom\n  x &lt;- x + delta\n  if (abs(delta) &lt; 1e-6) break\n}\n4 * x\n\n[1] 3.141595\n\n\n\nnumber of iterations not known in advance\nconvergence criterium, stop when required precision is reached\nno allocation of long vectors –&gt; less memory than for loop\n\n\n\nNote: there are more efficient methods to calculate \\(\\pi\\).",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#if-clause",
    "href": "slides/x1-r-basics.html#if-clause",
    "title": "x1-R Basics",
    "section": "if-clause",
    "text": "if-clause\n\nThe example before showed already an if-clause. The syntax is as follows:\n\nif (&lt;condition&gt;)\n  &lt;statement&gt;\nelse if (&lt;condition&gt;)\n  &lt;statement&gt;\nelse\n  &lt;statement&gt;\n\n\nProper indentation improves readability.\nRecommended: 2 characters\nProfessionals indent always.\nPlease do!\n\n\n\n\nUse of {} to group statements\n\nstatement can of be a compound statement with curly brackets {}\nto avoid common mistakes and be on the safe side, use always {}:\n\nExample:\n\nif (x == 0) {\n  print(\"x is Null\")\n} else if (x &lt; 0) {\n  print(\"x is negative\")\n} else {\n  print(\"x is positive\")\n}",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#vectorized-if",
    "href": "slides/x1-r-basics.html#vectorized-if",
    "title": "x1-R Basics",
    "section": "Vectorized if",
    "text": "Vectorized if\nOften, a vectorized ifelse is more appropropriate than an if-function.\nLet’s assume we have a data set of chemical measurements x with missing NA values, and “nondetects” that are encoded with -99. First we want to replace the nontetects with half of the detection limit (e.g. 0.5):\n\nx &lt;- c(3, 6, NA, 5, 4, -99, 7, NA,  8, -99, -99, 9)\nx2 &lt;- ifelse(x == -99, 0.5, x)\nx2\n\n [1] 3.0 6.0  NA 5.0 4.0 0.5 7.0  NA 8.0 0.5 0.5 9.0\n\n\nNow let’s remove the NAs:\n\nx3 &lt;- na.omit(x2)\nx3\n\n [1] 3.0 6.0 5.0 4.0 0.5 7.0 8.0 0.5 0.5 9.0\nattr(,\"na.action\")\n[1] 3 8\nattr(,\"class\")\n[1] \"omit\"",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/x1-r-basics.html#further-reading",
    "href": "slides/x1-r-basics.html#further-reading",
    "title": "x1-R Basics",
    "section": "Further reading",
    "text": "Further reading\n\nFollow-up presentations:\n\nFunctions everywhere\nGraphics in R\n\nMore details in the official R manuals, especially in “An Introduction to R”\nMany videos can be found on Youtube, at the Posit webpage and somewhere else.\nThis tutorial was made with Quarto\nAuthor: tpetzoldt +++ Homepage +++ Github page",
    "crumbs": [
      "Selected Programming Topics",
      "x1-R Basics"
    ]
  },
  {
    "objectID": "slides/07-anova.html#anova---analyse-der-varianzen",
    "href": "slides/07-anova.html#anova---analyse-der-varianzen",
    "title": "07-ANOVA und ANCOVA",
    "section": "ANOVA - Analyse der Varianzen",
    "text": "ANOVA - Analyse der Varianzen\n\n\nPrüfung komplexer Hypothesen als Ganzes, z.B.:\n\nmehr als zwei Stichproben (Problem des Mehrfachtests),\nmehrere multiple Faktoren (multiway ANOVA)\nEliminierung von Kovariaten (ANCOVA)\nfeste und/oder zufällige Effekte (Varianzzerlegungsmethoden, Modelle mit gemischten Effekten)\n\nVerschiedene Anwendungsszenarien:\n\nexplorative Anwendung: Welche Einflussfaktoren sind wichtig?\ndeskriptive Anwendung: Anpassen von Modellen zur Prozessbeschreibung und Vorhersage.\nSignifikanztests.\n\nANOVA-Methoden basieren (in den meisten Fällen) auf linearen Modellen.",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#ein-praxisbezogenes-beispiel",
    "href": "slides/07-anova.html#ein-praxisbezogenes-beispiel",
    "title": "07-ANOVA und ANCOVA",
    "section": "Ein praxisbezogenes Beispiel",
    "text": "Ein praxisbezogenes Beispiel\n\nSuche nach einem geeigneten Medium für Wachstumsexperimente mit Grünalgen\n\nbillig, einfach zu handhaben\ngeeignet für Schülerkurse und Experimente im Unterricht\n\n\n\nIdee\n\nVerwendung eines kommerziellen Düngers mit den Hauptnährstoffen N und P\nMineralwasser mit Spurenelementen\nEnthält Mineralwasser ohne Kohlensäure genügend \\(\\mathrm{CO_2}\\)?\ntesten, wie man die Verfügbarkeit von \\(\\mathrm{CO_2}\\) für die Photosynthese verbessern kann",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#anwendung",
    "href": "slides/07-anova.html#anwendung",
    "title": "07-ANOVA und ANCOVA",
    "section": "Anwendung",
    "text": "Anwendung\n\n7 Verschiedene Behandlungen\n\n\nDüngemittellösung in geschlossenen Flaschen\nDüngemittellösung in offenen Flaschen (\\(\\mathrm{CO_2}\\) aus der Luft)\nDüngemittel + Zucker (organische C-Quelle)\nDünger + zusätzliches \\(\\mathrm{HCO_3^-}\\) (Zusatz von \\(\\mathrm{CaCO_3}\\) zu sprudelndem Mineralwasser)\nein Standard-Algenwachstumsmedium („Basalmedium“) zum Vergleich\ndeionisiertes („destilliertes“) Wasser und\nLeitungswasser zum Vergleich",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#versuchsaufbau",
    "href": "slides/07-anova.html#versuchsaufbau",
    "title": "07-ANOVA und ANCOVA",
    "section": "Versuchsaufbau",
    "text": "Versuchsaufbau\n\n\njede Behandlung mit 3 Wiederholungen\nzufällige Platzierung auf einem Schüttler\n16:8 Licht:Dunkel-Zyklus\nMessung direkt in den Flaschen mit einem selbstgebauten Trübungsmessgerät",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#ergebnisse",
    "href": "slides/07-anova.html#ergebnisse",
    "title": "07-ANOVA und ANCOVA",
    "section": "Ergebnisse",
    "text": "Ergebnisse\n\n\n\n\n Dünger – Offene Flasche– D. + Zucker – D. + CaCO3 – Basalmedium – A. dest – Leitungswasser",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#der-datensatz",
    "href": "slides/07-anova.html#der-datensatz",
    "title": "07-ANOVA und ANCOVA",
    "section": "Der Datensatz",
    "text": "Der Datensatz\n\n\n\n\n\nTable 1: Wachstum von Tag 2 bis Tag 6 (relative Einheiten)\n\n\n\n\n\n\ntreat\nreplicate 1\nreplicate 2\nreplicate 3\n\n\n\n\nFertilizer\n0.020\n-0.217\n-0.273\n\n\nF. open\n0.940\n0.780\n0.555\n\n\nF.+sugar\n0.188\n-0.100\n0.020\n\n\nF.+CaCO3\n0.245\n0.236\n0.456\n\n\nBas.med.\n0.699\n0.727\n0.656\n\n\nA.dest\n-0.010\n0.000\n-0.010\n\n\nTap water\n0.030\n-0.070\nNA\n\n\n\n\n\n\n\n\n\n\n\nNA bedeutet „nicht verfügbar“, d.h. ein fehlender Wert\nDie Crosstable-Struktur ist kompakt und leicht zu lesen, aber nicht ideal für die Datenanalyse.\n\\(\\Rightarrow\\) konvertiere sie in ein Long-Format",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#daten-im-long-format",
    "href": "slides/07-anova.html#daten-im-long-format",
    "title": "07-ANOVA und ANCOVA",
    "section": "Daten im Long-Format",
    "text": "Daten im Long-Format\n\n\nVorteile\n\nsieht „blöd“ aus, ist aber besser für die Datenanalyse\nabhängige Variable Wachstum und Erklärungsvariable Behandlung deutlich sichtbar\nModellformel: growth ~ treat\nleicht erweiterbar auf \\(&gt;1\\) Erklärungsvariable\n\n\n\n\n\n\n\ntreat\nrep\ngrowth\n\n\n\n\nFertilizer\n1\n0.020\n\n\nFertilizer\n2\n-0.217\n\n\nFertilizer\n3\n-0.273\n\n\nF. open\n1\n0.940\n\n\nF. open\n2\n0.780\n\n\nF. open\n3\n0.555\n\n\nF.+sugar\n1\n0.188\n\n\nF.+sugar\n2\n-0.100\n\n\nF.+sugar\n3\n0.020\n\n\nF.+CaCO3\n1\n0.245\n\n\nF.+CaCO3\n2\n0.236\n\n\nF.+CaCO3\n3\n0.456",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#die-daten-in-r",
    "href": "slides/07-anova.html#die-daten-in-r",
    "title": "07-ANOVA und ANCOVA",
    "section": "Die Daten in R",
    "text": "Die Daten in R\n\n\nalgae &lt;- data.frame(\n  treat  = factor(c(\"Fertilizer\", \"Fertilizer\", \"Fertilizer\", \n             \"F. open\", \"F. open\", \"F. open\", \n             \"F.+sugar\", \"F.+sugar\", \"F.+sugar\", \n             \"F.+CaCO3\", \"F.+CaCO3\", \"F.+CaCO3\", \n             \"Bas.med.\", \"Bas.med.\", \"Bas.med.\", \n             \"A.dest\", \"A.dest\", \"A.dest\", \n             \"Tap water\", \"Tap water\"),\n             levels=c(\"Fertilizer\", \"F. open\", \"F.+sugar\", \n                    \"F.+CaCO3\", \"Bas.med.\", \"A.dest\", \"Tap water\")),\n  rep   = c(1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2), \n  growth = c(0.02, -0.217, -0.273, 0.94, 0.78, 0.555, 0.188, -0.1, 0.02, \n             0.245, 0.236, 0.456, 0.699, 0.727, 0.656, -0.01, 0, -0.01, 0.03, -0.07)\n)\n\n… können direkt in den Code eingegeben werden. Eine csv-Datei im Long-Format ist ebenfalls möglich.",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#boxplot",
    "href": "slides/07-anova.html#boxplot",
    "title": "07-ANOVA und ANCOVA",
    "section": "Boxplot",
    "text": "Boxplot\n\nboxplot(growth ~ treat, data = algae)\nabline(h = 0, lty = \"dashed\", col = \"grey\")",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#streifendiagramm",
    "href": "slides/07-anova.html#streifendiagramm",
    "title": "07-ANOVA und ANCOVA",
    "section": "Streifendiagramm",
    "text": "Streifendiagramm\n\nstripchart(growth ~ treat, data = algae, vertical = TRUE)\n\n\nBesser, denn wir haben nur 2-3 Wiederholungen. Boxplot braucht mehr.",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#umwandlung-einer-wissenschaftlichen-frage-in-eine-statistische-hypothese",
    "href": "slides/07-anova.html#umwandlung-einer-wissenschaftlichen-frage-in-eine-statistische-hypothese",
    "title": "07-ANOVA und ANCOVA",
    "section": "Umwandlung einer wissenschaftlichen Frage in eine statistische Hypothese",
    "text": "Umwandlung einer wissenschaftlichen Frage in eine statistische Hypothese\n\nWissenschaftliche Fragen\n\nSind die Behandlungen unterschiedlich?\nWelches Medium ist das beste?\nIst das beste Medium signifikant besser als die anderen?\n\n Statistische Hypothesen\n\n\\(H_0\\): das Wachstum ist bei allen Behandlungen gleich\n\\(H_A\\): Unterschiede zwischen den Medien",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#warum-können-wir-nicht-einfach-mehrere-t-tests-anwenden",
    "href": "slides/07-anova.html#warum-können-wir-nicht-einfach-mehrere-t-tests-anwenden",
    "title": "07-ANOVA und ANCOVA",
    "section": "Warum können wir nicht einfach mehrere t-Tests anwenden?",
    "text": "Warum können wir nicht einfach mehrere t-Tests anwenden?\n\n\nWenn wir 7 Behandlungen haben und alle gegeneinander testen wollen, brauchen wir:\n\n\\[7 \\cdot (7 - 1) / 2 = 21 \\qquad\\text{Tests.}\\]\n\nWenn wir \\(\\alpha = 0,05\\) setzen, erhalten wir 5% falsch positive Ergebnisse. \\(\\Rightarrow\\) Einer von 20 Tests ist im Durchschnitt ein falsch positiver\nWenn wir \\(N\\) Tests durchführen, erhöht sich der Gesamtfehler von \\(\\alpha\\) im schlimmsten Fall auf \\(N\\cdot\\alpha\\).\nDies wird alpha-Fehler-Inflation oder das Bonferroni-Gesetz genannt:\n\n\\[\n\\alpha_{total} \\le \\sum_{i=1}^{N} \\alpha_i = N \\cdot \\alpha\n\\]\nWenn wir das Bonferroni-Gesetz ignorieren, landen wir beim statistischen Fischen und erhalten zufällige falsche Ergebnisse.",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#anova-analyse-der-varianzen",
    "href": "slides/07-anova.html#anova-analyse-der-varianzen",
    "title": "07-ANOVA und ANCOVA",
    "section": "ANOVA: Analyse der Varianzen",
    "text": "ANOVA: Analyse der Varianzen\n\nGrundgedanke\n\nAufteilung der Gesamtvarianz in Wirkung(en) und Fehler:\n\n\n\\[\ns_y^2 = s^2_\\mathrm{effect} + s^2_{\\varepsilon}\n\\]\n\n\nEtwas überraschend: Wir verwenden Varianzen, um Mittelwerte zu vergleichen.\nErklärung: Mittelwertunterschiede tragen zur Gesamtvarianz der ganzen Stichprobe bei.\nDie Varianzkomponenten können als Varianz innerhalb (\\(s^2_\\varepsilon\\)) und Varianz zwischen Stichproben bezeichnet werden.\nDie Art und Weise, wie man die Varianzen trennt, ist ein lineares Modell.",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#beispiel",
    "href": "slides/07-anova.html#beispiel",
    "title": "07-ANOVA und ANCOVA",
    "section": "Beispiel",
    "text": "Beispiel\n\nZwei Marken von Clementinenfrüchten aus einem Geschäft „E“, die wir als „EB“ und „EP“ kodieren. Wir wollen wissen, ob die Premiummarke („P“) und die Basismarke („B“) ein unterschiedliches Gewicht haben.\n\nclem &lt;- data.frame(\n  brand = c(\"EP\", \"EB\", \"EB\", \"EB\", \"EB\", \"EB\", \"EB\", \"EB\", \"EB\", \"EB\", \"EB\", \n            \"EB\", \"EB\", \"EB\", \"EP\", \"EP\", \"EP\", \"EP\", \"EP\", \"EP\", \"EP\", \"EB\", \"EP\"),\n  weight = c(88, 96, 100, 96, 90, 100, 92, 92, 102, 99, 86, 89, 99, 89, 75, 80, \n             81, 96, 82, 98, 80, 107, 88))\n\n Wir kodieren eine Stichprobe („EB“) mit 1 und die andere Stichprobe („EP“) mit 2:\n\nclem$code &lt;- as.numeric(factor(clem$brand))\nclem$code\n\n [1] 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 1 2",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#dann-wird-eine-lineare-regression-angewandt",
    "href": "slides/07-anova.html#dann-wird-eine-lineare-regression-angewandt",
    "title": "07-ANOVA und ANCOVA",
    "section": "Dann wird eine lineare Regression angewandt:",
    "text": "Dann wird eine lineare Regression angewandt:\n\nplot(weight ~ code, data = clem, axes = FALSE)\nm &lt;- lm(weight ~ code, data = clem)\naxis(1, at = c(1,2), labels = c(\"EB\", \"EP\")); axis(2); box()\nabline(m, col = \"blue\")",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#varianzkomponenten",
    "href": "slides/07-anova.html#varianzkomponenten",
    "title": "07-ANOVA und ANCOVA",
    "section": "Varianzkomponenten",
    "text": "Varianzkomponenten\n\nWir passen ein lineares Modell an und vergleichen die Varianzen:\n\nm &lt;- lm(weight ~ code, data = clem)\n\nGesamtvarianz\n\n(var_tot &lt;- var(clem$weight))\n\n[1] 68.98814\n\n\nRestvarianz (= innere Varianz)\n\n(var_res &lt;- var(residuals(m)))\n\n[1] 43.25\n\n\nErklärte Varianz (= Zwischenvarianz)\n\nvar_tot - var_res\n\n[1] 25.73814\n\n\nNun können wir analysieren, ob die Zwischenvarianz groß genug ist, um einen signifikanten Effekt zu begründen.\nDies nennt man eine ANOVA.",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#anova",
    "href": "slides/07-anova.html#anova",
    "title": "07-ANOVA und ANCOVA",
    "section": "ANOVA",
    "text": "ANOVA\n\nanova(m)\n\nAnalysis of Variance Table\n\nResponse: weight\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \ncode       1 566.24  566.24  12.497 0.001963 **\nResiduals 21 951.50   45.31                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nEin t-Test zum Vergleich\n\nt.test(weight ~ code, data = clem, var.equal=TRUE)\n\n\n    Two Sample t-test\n\ndata:  weight by code\nt = 3.5351, df = 21, p-value = 0.001963\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n  4.185911 16.147423\nsample estimates:\nmean in group 1 mean in group 2 \n       95.50000        85.33333 \n\n\n\\(\\Rightarrow\\) die p-Werte sind genau gleich.",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#anova-mit-mehr-als-2-stichproben",
    "href": "slides/07-anova.html#anova-mit-mehr-als-2-stichproben",
    "title": "07-ANOVA und ANCOVA",
    "section": "ANOVA mit mehr als 2 Stichproben",
    "text": "ANOVA mit mehr als 2 Stichproben\nZurück zu den Daten über das Algenwachstum. Nennen wir das lineare Modell „m“:\n\nm &lt;- lm(growth ~ treat, data = algae)\n\n\n\nWir können die Koeffizienten des linearen Modells mit summary(m) ausgeben.\nWir interessieren uns aber für den Gesamteffekt und verwenden anova.\n\n\nanova(m)\n\nAnalysis of Variance Table\n\nResponse: growth\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \ntreat      6 2.35441 0.39240  25.045 1.987e-06 ***\nResiduals 13 0.20368 0.01567                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nDie ANOVA-Tabelle zeigt F-Tests, die die Signifikanz aller Faktoren prüfen.\nIn der obigen Tabelle haben wir nur einen einzigen Faktor.\n\n\\(\\Rightarrow\\) Wir sehen, dass die Behandlung einen signifikanten Effekt hat.",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#posthoc-tests",
    "href": "slides/07-anova.html#posthoc-tests",
    "title": "07-ANOVA und ANCOVA",
    "section": "Posthoc-Tests",
    "text": "Posthoc-Tests\n\nDer Test zeigte, dass der Faktor „Behandlung“ einen signifikanten Effekt hatte.\nWir wissen noch nicht, welche Faktorlevel unterschiedlich waren.\n\nDer Tukey-HSD-Test ist der häufigste.\n\ntk &lt;- TukeyHSD(aov(m))\ntk\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = m)\n\n$treat\n                            diff         lwr         upr     p adj\nF. open-Fertilizer    0.91500000  0.56202797  1.26797203 0.0000103\nF.+sugar-Fertilizer   0.19266667 -0.16030537  0.54563870 0.5211198\nF.+CaCO3-Fertilizer   0.46900000  0.11602797  0.82197203 0.0069447\nBas.med.-Fertilizer   0.85066667  0.49769463  1.20363870 0.0000231\nA.dest-Fertilizer     0.15000000 -0.20297203  0.50297203 0.7579063\nTap water-Fertilizer  0.13666667 -0.25796806  0.53130140 0.8837597\nF.+sugar-F. open     -0.72233333 -1.07530537 -0.36936130 0.0001312\nF.+CaCO3-F. open     -0.44600000 -0.79897203 -0.09302797 0.0102557\nBas.med.-F. open     -0.06433333 -0.41730537  0.28863870 0.9943994\nA.dest-F. open       -0.76500000 -1.11797203 -0.41202797 0.0000721\nTap water-F. open    -0.77833333 -1.17296806 -0.38369860 0.0001913\nF.+CaCO3-F.+sugar     0.27633333 -0.07663870  0.62930537 0.1727182\nBas.med.-F.+sugar     0.65800000  0.30502797  1.01097203 0.0003363\nA.dest-F.+sugar      -0.04266667 -0.39563870  0.31030537 0.9994197\nTap water-F.+sugar   -0.05600000 -0.45063473  0.33863473 0.9985686\nBas.med.-F.+CaCO3     0.38166667  0.02869463  0.73463870 0.0307459\nA.dest-F.+CaCO3      -0.31900000 -0.67197203  0.03397203 0.0879106\nTap water-F.+CaCO3   -0.33233333 -0.72696806  0.06230140 0.1247914\nA.dest-Bas.med.      -0.70066667 -1.05363870 -0.34769463 0.0001792\nTap water-Bas.med.   -0.71400000 -1.10863473 -0.31936527 0.0004507\nTap water-A.dest     -0.01333333 -0.40796806  0.38130140 0.9999997",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#grafische-darstellung",
    "href": "slides/07-anova.html#grafische-darstellung",
    "title": "07-ANOVA und ANCOVA",
    "section": "Grafische Darstellung",
    "text": "Grafische Darstellung\n\npar(las = 1)             # las = 1 macht y-Anmerkung horizontal\npar(mar = c(4, 10, 3, 1)) # mehr Platz auf der linken Seite für Achsenbeschriftungen\nplot(tk)",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#anova-annahmen-und-diagnosen",
    "href": "slides/07-anova.html#anova-annahmen-und-diagnosen",
    "title": "07-ANOVA und ANCOVA",
    "section": "ANOVA Annahmen und Diagnosen",
    "text": "ANOVA Annahmen und Diagnosen\n\nFür die ANOVA gelten dieselben Annahmen wie für das lineare Modell.\n\n\nUnabhängigkeit von Fehlern\nHomogenität der Varianz\nAnnähernde Normalität der Fehler\n\nGrafische Überprüfungen werden bevorzugt.\n\n\npar(mfrow=c(2, 2))\nplot(m)",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#numerische-tests",
    "href": "slides/07-anova.html#numerische-tests",
    "title": "07-ANOVA und ANCOVA",
    "section": "Numerische Tests",
    "text": "Numerische Tests\n\n\nTest der Varianzhomogenität\n\nDer F-Test vergleicht nur zwei Varianzen.\nVerschiedene Tests für multiple Varianzen, z.B. Bartlett, Levene, Fligner-Killeen\nEmpfohlen: Fligner-Killeen-Test\n\n\nfligner.test(growth ~ treat, \n             data = algae)\n\n\n    Fligner-Killeen test of homogeneity of variances\n\ndata:  growth by treat\nFligner-Killeen:med chi-squared = 4.2095, df = 6, p-value = 0.6483\n\n\n\nTest der Normalverteilung\n\nDer Shapiro-Wilks-Test kann irreführend sein.\nVerwende eine grafische Methode!\n\n\nqqnorm(residuals(m))\nqqline(residuals(m))",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#einseitige-anova-mit-heterogenen-varianzen",
    "href": "slides/07-anova.html#einseitige-anova-mit-heterogenen-varianzen",
    "title": "07-ANOVA und ANCOVA",
    "section": "Einseitige ANOVA mit heterogenen Varianzen",
    "text": "Einseitige ANOVA mit heterogenen Varianzen\n\n\nErweiterung des Welch-Tests für \\(\\ge 2\\) Stichproben\nin R genannt oneway.test\n\n\noneway.test(growth ~ treat, data = algae)\n\n\n    One-way analysis of means (not assuming equal variances)\n\ndata:  growth and treat\nF = 115.09, num df = 6.0000, denom df = 4.6224, p-value = 6.57e-05",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#zweiseitige-anova",
    "href": "slides/07-anova.html#zweiseitige-anova",
    "title": "07-ANOVA und ANCOVA",
    "section": "Zweiseitige ANOVA",
    "text": "Zweiseitige ANOVA\n\nBeispiel aus einem Statistik-Lehrbuch (Crawley, 2002), angewandt auf einen neuen Kontext\nAuswirkungen von Dünger und Lichtregime auf das Wachstum der Pflanzenhöhe in cm pro Zeit\n\n\n\n\nDünger\nhelles Licht\nschwaches Licht\n\n\n\n\nA\n8.3\n6.6\n\n\nA\n8.7\n7.2\n\n\nB\n8.1\n6.9\n\n\nB\n8.5\n8.3\n\n\nC\n9.1\n7.9\n\n\nC\n9.0\n9.2\n\n\n\n\n\n\n\n\n\nfaktorielles Experiment (mit Wiederholungen): jede Faktorkombination hat mehr als eine Beobachtung.\nohne Wiederholungen:\n\nkeine Wiederholungen pro Faktorkombination\ndies ist möglich, erlaubt aber keine Identifizierung von Wechselwirkungen",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#daten-im-long-format-eingeben",
    "href": "slides/07-anova.html#daten-im-long-format-eingeben",
    "title": "07-ANOVA und ANCOVA",
    "section": "Daten im Long-Format eingeben",
    "text": "Daten im Long-Format eingeben\n\n\n\nplants &lt;- data.frame(No = 1:12,\n                    growth = c(6.6, 7.2, 6.9, 8.3, 7.9, 9.2,\n                               8.3, 8.7, 8.1, 8.5, 9.1, 9.0),\n                    fert   = rep(c(\"A\", \"B\", \"C\"), each=2),\n                    light   = rep(c(\"low\", \"high\"), each=6)\n          )\n\n\n\n\n\n\n\nNo\ngrowth\nfert\nlight\n\n\n\n\n1\n6.6\nA\nlow\n\n\n2\n7.2\nA\nlow\n\n\n3\n6.9\nB\nlow\n\n\n4\n8.3\nB\nlow\n\n\n5\n7.9\nC\nlow\n\n\n6\n9.2\nC\nlow\n\n\n7\n8.3\nA\nhigh\n\n\n8\n8.7\nA\nhigh\n\n\n9\n8.1\nB\nhigh\n\n\n10\n8.5\nB\nhigh\n\n\n11\n9.1\nC\nhigh\n\n\n12\n9.0\nC\nhigh",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#beispiele-für-modellformeln",
    "href": "slides/07-anova.html#beispiele-für-modellformeln",
    "title": "07-ANOVA und ANCOVA",
    "section": "Beispiele für Modellformeln",
    "text": "Beispiele für Modellformeln\n\n\n\n\n\n\n\nModell Typ\nFormel\n\n\n\n\nNullmodell\ny ~ 1\n\n\nEinfache lineare Regression\ny ~ x\n\n\nLineares Modell ohne Achsenschnittpunkt\ny ~ x - 1\n\n\nMultiple Regression, keine Interaktion\ny ~ x1 + x2 + x3\n\n\nMultiple Regression mit Interaktion\ny ~ x1 * x2 * x3\n\n\nMultiple Regression, keine 3-fache Interaktion\ny ~ x1 * x2 * x3 - x1 : x2 : x3\n\n\nTransformiert mit ‘as is’ Funktion\ny ~ x + I(x^2)\n\n\nEinseitige ANOVA\ny ~ f\n\n\nANOVA mit Interaktion\ny ~ f1 * f2\n\n\nANCOVA mit Interaktion\ny ~ x * f\n\n\nVerschachtelte ANOVA\ny ~ x + (1 | a / b)\n\n\nGAM mit glättendem s\ny ~ s(x) + f\n\n\n\n\n\n\n\n\ny = Antwortvariable (abhängig, Ziel)\nx = metrische Erklärungsvariable (Prädiktor, unabhängig)\nf = Faktorvariable (nominal)",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#lineares-modell-und-anova",
    "href": "slides/07-anova.html#lineares-modell-und-anova",
    "title": "07-ANOVA und ANCOVA",
    "section": "Lineares Modell und ANOVA",
    "text": "Lineares Modell und ANOVA\n\nANOVA\n\nm &lt;- lm(growth ~ light * fert, data = plants)\nanova(m)\n\nAnalysis of Variance Table\n\nResponse: growth\n           Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \nlight       1 2.61333 2.61333  7.2258 0.03614 *\nfert        2 2.66000 1.33000  3.6774 0.09069 .\nlight:fert  2 0.68667 0.34333  0.9493 0.43833  \nResiduals   6 2.17000 0.36167                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#interaktionsplot",
    "href": "slides/07-anova.html#interaktionsplot",
    "title": "07-ANOVA und ANCOVA",
    "section": "Interaktionsplot",
    "text": "Interaktionsplot\n\nwith(plants, interaction.plot(fert, light, growth, \n                            col = c(\"orange\", \"brown\"), lty = 1, lwd = 2))",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#diagnostik",
    "href": "slides/07-anova.html#diagnostik",
    "title": "07-ANOVA und ANCOVA",
    "section": "Diagnostik",
    "text": "Diagnostik\nAnnahmen\n\nUnabhängigkeit der Messungen (innerhalb von Stichproben)\nHomogenität der Varianz der Residuen\nNormalverteilung der Residuen\n\n Der Test der Annahmen benötigt Residuen des angepassten Modells.  \\(\\Rightarrow\\) Passe zuerst das ANOVA-Modell an und prüfe dann, ob es richtig war!\n\nDiagnoseinstrumente\n\nBoxplot\nPlot der Residuen im Vergleich zu den Mittelwerten\nQ-Q-Diagramm der Residuen\nFligner-Killeen-Test (alternativ: von manchen wird der Levene-Test empfohlen)",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#diagnostik-ii",
    "href": "slides/07-anova.html#diagnostik-ii",
    "title": "07-ANOVA und ANCOVA",
    "section": "Diagnostik II",
    "text": "Diagnostik II\n\npar(mfrow=c(1, 2))\npar(cex=1.2, las=1)\nqqnorm(residuals(m))\nqqline(residuals(m))\n\nplot(residuals(m)~fitted(m))\nabline(h=0)\n\n\n\nfligner.test(growth ~ interaction(light, fert), data=plants)\n\n\n    Fligner-Killeen test of homogeneity of variances\n\ndata:  growth by interaction(light, fert)\nFligner-Killeen:med chi-squared = 10.788, df = 5, p-value = 0.05575\n\n\nResiduen: sehen in Ordnung aus und der p-Wert des Fligner-Tests \\(&gt; 0,05\\), \\(\\rightarrow\\) sieht gut aus.",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#anmerkungen",
    "href": "slides/07-anova.html#anmerkungen",
    "title": "07-ANOVA und ANCOVA",
    "section": "Anmerkungen",
    "text": "Anmerkungen\nLineare Regression oder ANOVA?\n\nim Wesentlichen dasselbe\nunabhängige Variablen sind metrisch: lineares Modell\nunabhängige Variablen sind nominal (= Faktor): ANOVA\nMischung aus metrischen und nominalen Variablen: ANCOVA\n\nVerwendung von Pre-Tests\nPre-Tests sind im Allgemeinen aus theoretischen Gründen fragwürdig:\n\nDie Nullhypothesen \\(H_0\\) können nur verworfen und nicht endgültig bestätigt werden.\nWenn der Stichprobenumfang groß ist, ist die Normalität der Residuen nicht erforderlich\nWenn \\(p\\) in der Nähe des Schwellenwerts liegt und der Stichprobenumfang klein ist, bleiben wir im Ungewissen.\n\nAll dies lässt sich nur durch sorgfältiges Nachdenken und mit etwas Erfahrung überwinden.\nEs ist immer eine gute Idee, die Ergebnisse mit Kollegen und Vorgesetzten zu besprechen.",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#sequentielles-holm-bonferroni-verfahren",
    "href": "slides/07-anova.html#sequentielles-holm-bonferroni-verfahren",
    "title": "07-ANOVA und ANCOVA",
    "section": "Sequentielles Holm-Bonferroni-Verfahren",
    "text": "Sequentielles Holm-Bonferroni-Verfahren\n\nAuch Holm-Verfahren genannt (Holm, 1979)\nEinfach zu verwenden\nKann auf jedes Problem mit Mehrfachtests angewendet werden\nWeniger konservativ als die normale Bonferroni-Korrektur, aber …\n… immer noch ein sehr konservativer Ansatz\nsiehe auch Wikipedia\n\nAlgorithmus\n\nWähle den kleinsten \\(p\\)-Wert aus allen \\(n\\) \\(p\\)-Werten\nWenn \\(p \\cdot n &lt; \\alpha\\) \\(\\Rightarrow\\) signifikant, sonst STOPP\nSetze \\(n - 1 \\rightarrow n\\), entferne das kleinste \\(p\\) aus der Liste und gehe zu Schritt 1.",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#beispiel-1",
    "href": "slides/07-anova.html#beispiel-1",
    "title": "07-ANOVA und ANCOVA",
    "section": "Beispiel",
    "text": "Beispiel\n\nWachstumsrate pro Tag (\\(d^{-1}\\)) von Blaualgenkulturen (Pseudanabaena) nach Zugabe toxischer Peptide einer anderen Blaualge (Microcystis).\nDie ursprüngliche Hypothese war, dass Microcystin LR (MCYST) oder ein Derivat davon (Substanz A) das Wachstum hemmt.\n\n\nmcyst &lt;-  data.frame(treat = factor(c(rep(\"Control\", 5),\n                                       rep(\"MCYST\", 5),\n                                       rep(\"Subst A\", 5)),\n                                levels=c(\"Control\", \"MCYST\", \"Subst A\")),\n                      mu   = c(0.086, 0.101, 0.086, 0.086, 0.099,\n                               0.092, 0.088, 0.093, 0.088, 0.086,\n                               0.095, 0.102, 0.106, 0.106, 0.106)\n                     )",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#ansatz-1-einseitige-anova",
    "href": "slides/07-anova.html#ansatz-1-einseitige-anova",
    "title": "07-ANOVA und ANCOVA",
    "section": "Ansatz 1: einseitige ANOVA",
    "text": "Ansatz 1: einseitige ANOVA\n\npar(mar=c(4, 8, 2, 1), las=1)\nm &lt;- lm(mu ~ treat, data=mcyst)\nanova(m)\n\nAnalysis of Variance Table\n\nResponse: mu\n          Df     Sum Sq    Mean Sq F value   Pr(&gt;F)   \ntreat      2 0.00053293 2.6647e-04   8.775 0.004485 **\nResiduals 12 0.00036440 3.0367e-05                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nplot(TukeyHSD(aov(m)))",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#ansatz-2-multiple-t-tests-mit-sequentieller-bonferroni-korrektur",
    "href": "slides/07-anova.html#ansatz-2-multiple-t-tests-mit-sequentieller-bonferroni-korrektur",
    "title": "07-ANOVA und ANCOVA",
    "section": "Ansatz 2: multiple t-Tests mit sequentieller Bonferroni-Korrektur",
    "text": "Ansatz 2: multiple t-Tests mit sequentieller Bonferroni-Korrektur\nWir trennen den Datensatz in einzelne Teilmengen:\n\nControl &lt;- mcyst$mu[mcyst$treat == \"Control\"]\nMCYST   &lt;- mcyst$mu[mcyst$treat == \"MCYST\"]\nSubstA  &lt;- mcyst$mu[mcyst$treat == \"Subst A\"]\n\nund führen 3 t-Tests durch:\n\np1 &lt;- t.test(Control, MCYST)$p.value\np2 &lt;- t.test(Control, SubstA)$p.value\np3 &lt;- t.test(MCYST, SubstA)$p.value\n\nIm Folgenden sind die rohen p-Werte ohne Korrektur dargestellt:\n\nc(p1, p2, p3)\n\n[1] 0.576275261 0.027378832 0.001190592\n\n\n… und mit Holm-Korrektur:\n\np.adjust(c(p1, p2, p3))\n\n[1] 0.576275261 0.054757664 0.003571775",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#schlussfolgerungen",
    "href": "slides/07-anova.html#schlussfolgerungen",
    "title": "07-ANOVA und ANCOVA",
    "section": "Schlussfolgerungen",
    "text": "Schlussfolgerungen\nStatistische Methoden\n\nIm Falle der Holm-korrigierten t-Tests bleibt nur ein einziger p-Wert (MCYST vs. Subst A) signifikant. Dies zeigt, dass die Holm-Methode in diesem Fall konservativer ist als TukeyHSD (nur ein signifikanter Effekt im Vergleich zu zwei signifikanten).\nEine ANOVA mit Posthoc-Test ist im Allgemeinen vorzuziehen,\naber die sequentielle Holm-Bonferroni-Methode kann in besonderen Fällen hilfreich sein.\nAußerdem zeigt es deutlich, dass massive Mehrfachtests vermieden werden müssen.\n\n\\(\\Rightarrow\\) ANOVA ist zu bevorzugen, wenn möglich.\nInterpretation\n\nHinsichtlich unserer ursprünglichen Hypothese können wir feststellen, dass MCYST und SubstA das Wachstum von Pseudanabaena nicht hemmen. Vielmehr stimulierte SubstA das Wachstum.\nDies widersprach unseren Erwartungen - der biologische Grund wurde dann 10 Jahre später gefunden.\n\nMehr dazu ist zu finden in Jähnichen et al. (2001), Jähnichen et al. (2007), Jähnichen et al. (2011), Zilliges et al. (2011) oder Dziallas & Grossart (2011).",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#ancova",
    "href": "slides/07-anova.html#ancova",
    "title": "07-ANOVA und ANCOVA",
    "section": "ANCOVA",
    "text": "ANCOVA\nStatistische Frage\n\nVergleich von Regressionslinien\nÄhnlich wie bei der ANOVA, enthält aber auch metrische Variablen (Kovariaten)\n\nBeispiel\nAnnette Dobsons Daten zum Geburtsgewicht. Ein Datensatz aus einem Statistik-Lehrbuch (Dobson, 2013), Geburtsgewicht von Jungen und Mädchen in Abhängigkeit von der Schwangerschaftswoche.",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#der-datensatz-zum-geburtsgewicht",
    "href": "slides/07-anova.html#der-datensatz-zum-geburtsgewicht",
    "title": "07-ANOVA und ANCOVA",
    "section": "Der Datensatz zum Geburtsgewicht",
    "text": "Der Datensatz zum Geburtsgewicht\n\nDer Datensatz ist an verschiedenen Stellen im Internet und in verschiedenen Versionen zu finden.\nHier die Version, die in einer R-Demo zu finden ist: demo(lm.glm)\n\n## Daten zum Geburtsgewicht siehe stats/demo/lm.glm.R\ndobson &lt;- data.frame(\n  week = c(40, 38, 40, 35, 36, 37, 41, 40, 37, 38, 40, 38,\n     40, 36, 40, 38, 42, 39, 40, 37, 36, 38, 39, 40),\n  weight = c(2968, 2795, 3163, 2925, 2625, 2847, 3292, 3473, 2628, 3176,\n        3421, 2975, 3317, 2729, 2935, 2754, 3210, 2817, 3126, 2539,\n        2412, 2991, 2875, 3231),\n  gender = gl(2, 12, labels=c(\"M\", \"F\"))\n)\n\n\nAnmerkung: Dies ist ein künstlicher Datensatz, nicht die Realität.",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#anette-dobsons-daten-zum-geburtsgewicht",
    "href": "slides/07-anova.html#anette-dobsons-daten-zum-geburtsgewicht",
    "title": "07-ANOVA und ANCOVA",
    "section": "Anette Dobsons Daten zum Geburtsgewicht",
    "text": "Anette Dobsons Daten zum Geburtsgewicht\nWarum nicht einfach einen t-Test durchführen?\n\nboxplot(weight ~ gender,data = dobson, ylab = \"weight\")\n\nt.test(weight ~ gender, data = dobson, var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  weight by gender\nt = 0.97747, df = 22, p-value = 0.339\nalternative hypothesis: true difference in means between group M and group F is not equal to 0\n95 percent confidence interval:\n -126.3753  351.7086\nsample estimates:\nmean in group M mean in group F \n       3024.000        2911.333 \n\n\nDer Boxplot zeigt viele Überschneidungen, und der Unterschied ist nicht signifikant, weil der t-Test wichtige Informationen außer Acht lässt: die Schwangerschaftswoche.",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#ancova-verwendet-kovariaten",
    "href": "slides/07-anova.html#ancova-verwendet-kovariaten",
    "title": "07-ANOVA und ANCOVA",
    "section": "ANCOVA verwendet Kovariaten",
    "text": "ANCOVA verwendet Kovariaten\n\nm &lt;- lm(weight ~ week * gender, data = dobson)\nanova(m)\n\nAnalysis of Variance Table\n\nResponse: weight\n            Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nweek         1 1013799 1013799 31.0779 1.862e-05 ***\ngender       1  157304  157304  4.8221   0.04006 *  \nweek:gender  1    6346    6346  0.1945   0.66389    \nResiduals   20  652425   32621                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#bisher-beschriebene-tücken-von-anova-und-ancova",
    "href": "slides/07-anova.html#bisher-beschriebene-tücken-von-anova-und-ancova",
    "title": "07-ANOVA und ANCOVA",
    "section": "Bisher beschriebene Tücken von ANOVA und ANCOVA",
    "text": "Bisher beschriebene Tücken von ANOVA und ANCOVA\n\n\nHeterogenität der Varianz\n\np-Werte können verzerrt sein (d. h. irreführend oder falsch)\nVerwendung einer einseitigen ANOVA für ungleiche Varianzen (in R: oneway.test)\n\nUnausgeglichener Fall: Ungleiche Anzahl von Stichproben für jede Faktorkombination \\(\\rightarrow\\) Die Ergebnisse der ANOVA hängen von der Reihenfolge der Faktoren in der Modellformel ab.\n\nKlassische Methode: Typ II oder Typ III ANOVA\nModerner Ansatz: Modellauswahl und Likelihood-Ratio-Tests",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#typ-ii-und-typ-iii-anova",
    "href": "slides/07-anova.html#typ-ii-und-typ-iii-anova",
    "title": "07-ANOVA und ANCOVA",
    "section": "Typ II und Typ III ANOVA",
    "text": "Typ II und Typ III ANOVA\n\n\nFunktion Anova (mit Großbuchstabe A) im Paket car\nHilfsdatei der Funktion Anova:\n\n\n„Typ-II-Tests werden nach dem Prinzip der Marginalität berechnet, wobei jeder Term nach allen anderen getestet wird, ohne die Verwandten höherer Ordnung zu berücksichtigen; so genannte Typ-III-Tests verletzen die Marginalität, indem sie jeden Term im Modell nach allen anderen testen.“\n\n\nSchlussfolgerung: Verwende Typ II und nicht Typ III.\nVersuche nicht, einzelne Terme im Falle signifikanter Wechselwirkungen zu interpretieren.",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#typ-ii-anova-beispiel",
    "href": "slides/07-anova.html#typ-ii-anova-beispiel",
    "title": "07-ANOVA und ANCOVA",
    "section": "Typ II ANOVA: Beispiel",
    "text": "Typ II ANOVA: Beispiel\n\n\nlibrary(\"car\")\nm &lt;- lm(growth ~ light * fert, data = plants)\nAnova(m, type=\"II\")\n\nAnova Table (Type II tests)\n\nResponse: growth\n            Sum Sq Df F value  Pr(&gt;F)  \nlight      2.61333  1  7.2258 0.03614 *\nfert       2.66000  2  3.6774 0.09069 .\nlight:fert 0.68667  2  0.9493 0.43833  \nResiduals  2.17000  6                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#auswahl-eines-optimalen-modells-aus-einer-menge-von-kandidaten",
    "href": "slides/07-anova.html#auswahl-eines-optimalen-modells-aus-einer-menge-von-kandidaten",
    "title": "07-ANOVA und ANCOVA",
    "section": "Auswahl eines optimalen Modells aus einer Menge von Kandidaten",
    "text": "Auswahl eines optimalen Modells aus einer Menge von Kandidaten\n\nProblem:\n\nBei komplexen ANOVA-Modellen hängen die p-Werte von der Anzahl (und manchmal von der Reihenfolge) der einbezogenen Faktoren und Wechselwirkungen ab.\nDer \\(H_0\\)-basierte Ansatz wird verwirrend, z.B. wegen widersprüchlicher p-Werte.\n\nAlternativer Ansatz:\n\nNutzt das Prinzip der Parsimonie\n\nAnstelle von p-Wert-basierten Tests werden verschiedene Modellkandidaten verglichen:\n\nModell mit allen potentiellen Effekten → vollständiges Modell\nWeglassen einzelner Faktoren → reduzierte Modelle (mehrere!)\nKeine Einflussfaktoren (nur Mittelwert) → Nullmodell\nWelches Modell ist das beste → minimales adäquates Modell?",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#wie-können-wir-messen-welches-modell-das-beste-ist",
    "href": "slides/07-anova.html#wie-können-wir-messen-welches-modell-das-beste-ist",
    "title": "07-ANOVA und ANCOVA",
    "section": "Wie können wir messen, welches Modell das beste ist?",
    "text": "Wie können wir messen, welches Modell das beste ist?\n\nKompromiss zwischen Modellanpassung und Modellkomplexität (Anzahl der Parameter, k).\n\nGüte der Anpassung: Likelihood L (misst, wie gut die Daten zu einem bestimmten Modell passen).\nLog Likelihood: macht das Kriterium additiv.\nAIC (Akaike Information Criterion):\n\n\\[AIC = −2 \\ln(L) + 2k\\]\n\nBIC ( Bayesian Information Criterion), berücksichtigt den Stichprobenumfang (\\(n\\)):\n\n\\[BIC = −2 \\ln(L) + k · \\ln(n)\\]\nDas Modell mit dem kleinsten AIC (oder BIC) ist das minimal adäquate (d.h. optimale) Modell.",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#modellauswahl-und-likelihood-ratio-tests",
    "href": "slides/07-anova.html#modellauswahl-und-likelihood-ratio-tests",
    "title": "07-ANOVA und ANCOVA",
    "section": "Modellauswahl und Likelihood-Ratio-Tests",
    "text": "Modellauswahl und Likelihood-Ratio-Tests\nAnsatz\n\nMehrere Modelle einzeln anpassen\nVergleiche die Modelle paarweise mit ANOVA (Likelihood Ratio Test)\n\nDaten und Beispiel\n\nplants &lt;- data.frame(No=1:12,\n                   growth=c(6.6, 7.2, 6.9, 8.3, 7.9, 9.2,\n                            8.3, 8.7, 8.1, 8.5, 9.1, 9.0),\n                   fert= rep(c(\"A\", \"B\", \"C\"), each=2),\n                   light= rep(c(\"low\", \"high\"), each=6)\n                   )\n\n\nm3 &lt;- lm(growth ~ fert * light, data=plants)  # f1 + f2 + f1:f2\nm2 &lt;- lm(growth ~ fert + light, data=plants)  # f1 + f2\nanova(m3, m2)\n\nAnalysis of Variance Table\n\nModel 1: growth ~ fert * light\nModel 2: growth ~ fert + light\n  Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)\n1      6 2.1700                           \n2      8 2.8567 -2  -0.68667 0.9493 0.4383\n\n\n\nLikelihood-Ratio-Test vergleicht zwei Modelle (anova mit &gt; 1 Modell)\nModell mit Interaktion (m3) nicht signifikant besser als Modell ohne Interaktion (m2).",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#aic-basierte-modellauswahl",
    "href": "slides/07-anova.html#aic-basierte-modellauswahl",
    "title": "07-ANOVA und ANCOVA",
    "section": "AIC-basierte Modellauswahl",
    "text": "AIC-basierte Modellauswahl\n\nDer paarweise Modellvergleich ist umständlich, insbesondere bei einer großen Anzahl von Modellen.\nLösung: Erstelle eine Menge von Kandidatenmodellen\nVerwende kleinstes AIC, um das minimal angemessene Modell auszuwählen.\n\n\nm3  &lt;- lm(growth ~ light * fert, data = plants) # Gesamtmodell\nm2  &lt;- lm(growth ~ light + fert, data = plants)\nm1a &lt;- lm(growth ~ fert, data = plants)\nm1b &lt;- lm(growth ~ light, data = plants)\nm0  &lt;- lm(growth ~ 1, data = plants)            # Nullmodell\n\nAIC(m0, m1a, m1b, m2, m3)\n\n    df      AIC\nm0   2 33.38238\nm1a  4 32.62699\nm1b  3 30.72893\nm2   5 26.83151\nm3   7 27.53237\n\n\nAnmerkung\n\nAIC-Werte sind bis zu einer additiven Konstante definiert\n\\(\\rightarrow\\) absolute Werte unterscheiden sich manchmal, abhängig von der angewandten Methode\n\\(\\Rightarrow\\) betrachtet den Bereich des AIC und die Unterschiede, ignoriert die absoluten Werte\nFaustregel: die „AIC-Einheit“ ist 2, Unterschiede \\(\\approx 2.0\\rightarrow\\) geringe Bedeutung",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#schrittweise-modellauswahl-automatisch",
    "href": "slides/07-anova.html#schrittweise-modellauswahl-automatisch",
    "title": "07-ANOVA und ANCOVA",
    "section": "Schrittweise Modellauswahl (automatisch)",
    "text": "Schrittweise Modellauswahl (automatisch)\n\nDas vollständige Modell wird an die Funktion step übergeben:\n\n\n\nm1 &lt;- lm(growth ~ fert * light, data=plants)\nopt &lt;- step(m1)\n\nStart:  AIC=-8.52\ngrowth ~ fert * light\n\n             Df Sum of Sq    RSS     AIC\n- fert:light  2   0.68667 2.8567 -9.2230\n&lt;none&gt;                    2.1700 -8.5222\n\nStep:  AIC=-9.22\ngrowth ~ fert + light\n\n        Df Sum of Sq    RSS     AIC\n&lt;none&gt;               2.8567 -9.2230\n- fert   2    2.6600 5.5167 -5.3256\n- light  1    2.6133 5.4700 -3.4275\n\n\n\nModell mit dem kleinsten AIC \\(\\rightarrow\\) optimales Modell.\n\n\n\nanova(opt)\n\nAnalysis of Variance Table\n\nResponse: growth\n          Df Sum Sq Mean Sq F value  Pr(&gt;F)  \nfert       2 2.6600 1.33000  3.7246 0.07190 .\nlight      1 2.6133 2.61333  7.3186 0.02685 *\nResiduals  8 2.8567 0.35708                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\np &lt; 0.05  \\(\\rightarrow\\) signifikant\n\nErgebnisse des Beispiels:\n\noptimales Modell (m2, opt), enthält beide Faktoren fert und light, aber keine Interaktion.\nDie Modellauswahl hat fert und light als notwendige erklärende Variablen identifiziert, im Gegensatz zur klassischen ANOVA-Tabelle, in der nur light signifikant ist.",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#signifikanztests",
    "href": "slides/07-anova.html#signifikanztests",
    "title": "07-ANOVA und ANCOVA",
    "section": "Signifikanztests?",
    "text": "Signifikanztests?\n\n\nDas Konzept der Modellauswahl überlagert die p-Wert-basierte Statistik.\nEinige Autoren raten generell davon ab, p-Werte in diesem Zusammenhang zu verwenden, andere empfehlen einen Kompromiss.\nWenn man einen p-Wert erhalten möchte, sollte man das optimale Modell mit weiteren reduzierten Modellen vergleichen, die p-Werte aber dennoch mit Vorsicht interpretieren:\n\n\nanova(m2, m1a) # fert\nanova(m2, m1b) # light\n\n\nIn jedem Fall gilt: Konzentriere dich auf die praktischen Implikationen und vergiss nicht, die Effektgrößen anzugeben!",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#zusammenfassung-des-kapitels-anova",
    "href": "slides/07-anova.html#zusammenfassung-des-kapitels-anova",
    "title": "07-ANOVA und ANCOVA",
    "section": "Zusammenfassung des Kapitels ANOVA",
    "text": "Zusammenfassung des Kapitels ANOVA\n\nLineare Modelle bilden die Grundlage für viele statistische Methoden.\n\nLineare Regression\nANOVA, ANCOVA, GLM, GAM, GLMM, . . .\nANOVA/ANCOVA anstelle von Mehrfachtests\n\nANOVA ist leistungsfähiger als Mehrfachtests:\n\nvermeidet \\(\\alpha\\)-Fehlerinflation\nein großes Experiment benötigt weniger n als viele kleine Experimente\nIdentifizierung von Interaktionseffekten\nEliminierung von Kovariaten\n\nModellauswahl vs. p-Wert-basierte Tests\n\nParadigmenwechsel in der Statistik: AIC anstelle des p-Wertes\nzuverlässiger, insbesondere bei unausgewogenen oder komplexen Designs\nerweiterbar auf generalisierte, additive und gemischte Modelle (GLM, GAM, LME, GLMM, …)\naber: p-Wert-basierte Tests sind manchmal leichter zu verstehen",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#vermeide-manipulation-von-p-werten",
    "href": "slides/07-anova.html#vermeide-manipulation-von-p-werten",
    "title": "07-ANOVA und ANCOVA",
    "section": "Vermeide Manipulation von p-Werten",
    "text": "Vermeide Manipulation von p-Werten\nExperimente NICHT wiederholen, bis ein signifikanter p-Wert gefunden wird.\nDie hochrangige Zeitschrift „… Nature hat einflussreiche Statistiker gebeten, eine Änderung zur Verbesserung der Wissenschaft zu empfehlen. Das gemeinsame Thema? Das Problem ist nicht unsere Mathematik, sondern wir selbst.“ (Leek et al. (2017)):\nFünf Wege, Statistiken zu verbessern. Kommentar zur Nature\n\nJeff Leek: Anpassung an die menschliche Kognition\nBlakeley B. McShane & Andrew Gelman: Verzicht auf statistische Signifikanz\nDavid Colquhoun: Auch falsch-positives Risiko angeben\nMichèle B. Nuijten: Analysepläne und Ergebnisse mitteilen\nSteven N. Goodman: Normen von innen heraus ändern\n\n\nSelbststudium\nLies das Paper von Johnson & Omland (2004) um mehr über das Paradigma der Modellauswahl zu erfahren.",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/07-anova.html#literaturverzeichnis",
    "href": "slides/07-anova.html#literaturverzeichnis",
    "title": "07-ANOVA und ANCOVA",
    "section": "Literaturverzeichnis",
    "text": "Literaturverzeichnis\n\n\n\n\nCrawley, M. J. (2002). Statistical computing. An introduction to data analysis using S-PLUS (pp. 1–761). Wiley. datasets: http://www.bio.ic.ac.uk/research/mjcraw/statcomp/data/\n\n\nDobson, A. J. (2013). Introduction to statistical modelling. Springer.\n\n\nDziallas, C., & Grossart, H.-P. (2011). Increasing Oxygen Radicals and Water Temperature Select for Toxic Microcystis sp. PLoS ONE, 6(9), e25569. https://doi.org/10.1371/journal.pone.0025569\n\n\nHolm, S. (1979). A simple sequentially rejective multiple test procedure. Scandinavian Journal of Statistics, 65–70. https://www.jstor.org/stable/4615733\n\n\nJähnichen, S., Ihle, T., Petzoldt, T., & Benndorf, J. (2007). Impact of Inorganic Carbon Availability on Microcystin Production by Microcystis aeruginosa PCC 7806. Applied and Environmental Microbiology, 73(21), 6994–7002. https://doi.org/10.1128/AEM.01253-07\n\n\nJähnichen, S., Long, B. M., & Petzoldt, T. (2011). Microcystin production by Microcystis aeruginosa: Direct regulation by multiple environmental factors. Harmful Algae, 12, 95–104. https://doi.org/10.1016/j.hal.2011.09.002\n\n\nJähnichen, S., Petzoldt, T., & Benndorf, J. (2001). Evidence for control of microcystin dynamics in Bautzen Reservoir (Germany) by cyanobacterial population growth rates and dissolved inorganic carbon. Fundamental and Applied Limnology, 150(2), 177–196. https://doi.org/10.1127/archiv-hydrobiol/150/2001/177\n\n\nJohnson, G., Jerald, & Omland, K. S. (2004). Model Selection in Ecology and Evolution. Trends in Ecology and Evolution, 19(2), 101–108. https://doi.org/10.1016/j.tree.2003.10.013\n\n\nZilliges, Y., Kehr, J.-C., Meissner, S., Ishida, K., Mikkat, S., Hagemann, M., Kaplan, A., Börner, T., & Dittmann, E. (2011). The Cyanobacterial Hepatotoxin Microcystin Binds to Proteins and Increases the Fitness of Microcystis under Oxidative Stress Conditions. PLoS ONE, 6(3), e17615. https://doi.org/10.1371/journal.pone.0017615",
    "crumbs": [
      "Statistische Grundlagen",
      "07-ANOVA und ANCOVA"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#statistische-tests",
    "href": "slides/05-classtests.html#statistische-tests",
    "title": "05-Klassische Tests",
    "section": "Statistische Tests",
    "text": "Statistische Tests\n\nEin statistischer Test hilft zu entscheiden, ob eine Hypothese wahrscheinlich richtig ist oder nicht, basierend auf vorliegenden Daten.\n\nBeispiel: Wir vergleichen zwei Stichproben oder eine Stichprobe mit einem statistischen Modell.\nDazu stellen zwei Hypothesen auf:\n\nAlternativhypothese (\\(H_a\\)): Das ist unsere eigentliche Hypothese, dass es einen Unterschied oder eine Beziehung gibt.\nNullhypothese (\\(H_0\\)): Wir nehmen an, dass es keinen Unterschied oder keine Beziehung gibt und testen, ob wir diese Hypothese ablehnen können.\n\nStatistisch signifikant bedeutet: Die Wahrscheinlichkeit, dass wir unsere Beobachtung nur durch puren Zufall gemacht haben, ist sehr gering. Wenn das so ist, sagen wir, dass unser Ergebnis signifikant ist und \\(H_a\\) unterstützt wird.\n\nsiehe dazu auch: https://de.wikipedia.org/wiki/Statistischer_Test",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#effektstärke-und-signifikanz",
    "href": "slides/05-classtests.html#effektstärke-und-signifikanz",
    "title": "05-Klassische Tests",
    "section": "Effektstärke und Signifikanz",
    "text": "Effektstärke und Signifikanz\n\nFür Mittelwertdifferenzen ist die relative Effektstärke:\n\n\\[\n  \\delta = \\frac{\\bar{\\mu}_1-\\bar{\\mu}_2}{\\sigma}=\\frac{\\Delta}{\\sigma}\n\\]\n\nmit:\n\nMittelwerte von zwei Grundgesamtheiten \\(\\mu_1, \\mu_2\\)\nabsolute Effektstärke \\(\\Delta\\)\nrelative Effektstärke \\(\\delta\\) (auch Cohen’s d genannt)\nSignifikanz bedeutet, dass es unwahrscheinlich ist, dass ein beobachteter Effekt das Ergebnis einer reinen Zufallsvariation ist.",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#nullhypothese-und-alternativhypothese",
    "href": "slides/05-classtests.html#nullhypothese-und-alternativhypothese",
    "title": "05-Klassische Tests",
    "section": "Nullhypothese und Alternativhypothese",
    "text": "Nullhypothese und Alternativhypothese\n\n\\(H_0\\) Nullhypothese: Zwei Grundgesamtheiten unterscheiden sich nicht in Bezug auf eine bestimmte Eigenschaft.\n\nAnnahme: Der beobachtete Effekt ist rein zufällig entstanden, der wahre Effekt ist Null.\n\n\\(H_a\\) Alternativhypothese (Versuchshypothese): Vorhandensein eines bestimmten Effekts.\n\nEine Alternativhypothese ist nie vollständig wahr oder „bewiesen“.\nDie Annahme von \\(H_A\\) bedeutet nur, dass \\(H_0\\) unwahrscheinlich ist.\n\n„Nicht signifikant“ bedeutet entweder kein Effekt oder Stichprobengröße zu klein!\n\nAnmerkung: Unterschiedliche Bedeutung von Signifikanz (\\(H_0\\) unwahrscheinlich) und Relevanz (Effekt groß genug, um in der Praxis eine Rolle zu spielen).",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#der-p-wert",
    "href": "slides/05-classtests.html#der-p-wert",
    "title": "05-Klassische Tests",
    "section": "Der p-Wert",
    "text": "Der p-Wert\n\nDie Interpretation des p-Wertes war in der Vergangenheit oft verwirrend, selbst in Statistik-Lehrbüchern, so dass es gut ist, sich auf eine klare Definition zu beziehen:\n\n\nDer p-Wert ist definiert als die Wahrscheinlichkeit, ein Ergebnis zu erhalten, das gleich oder „extremer“ ist als das, was tatsächlich beobachtet wurde, wenn die Nullhypothese wahr ist.\n\n\n\n\nhttps://en.wikipedia.org/wiki/P-value:\nHubbard (2004) Alphabet Soup: Blurring the Distinctions Between p’s and a’s in Psychological Research, Theory Psychology 14(3), 295-327. DOI: 10.1177/0959354304043638",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#alpha--und-beta-fehler",
    "href": "slides/05-classtests.html#alpha--und-beta-fehler",
    "title": "05-Klassische Tests",
    "section": "Alpha- und Beta-Fehler",
    "text": "Alpha- und Beta-Fehler\n\n\n\n\n\n\n\n\n\nRealität\nEntscheidung des Tests\nRichtig?\nWahrscheinlichkeit\n\n\n\n\n\\(H_0\\) = wahr\nsignifikant\nnein\n\\(\\alpha\\)-Fehler\n\n\n\\(H_0\\) = falsch\nnicht signifikant\nnein\n\\(\\beta\\)-Fehler\n\n\n\\(H_0\\) = wahr\nnicht signifikant\nja\n\\(1-\\alpha\\)\n\n\n\\(H_0\\) = falsch\nsignifikant\nja\n\\(1-\\beta\\) (Trennschärfe)\n\n\n\n\n\n\n\n\n\n1.\\(H_0\\) fälschlicherweise abgelehnt (Fehler erster Art oder \\(\\alpha\\)-Fehler)\n\nes wird ein Effekt behauptet, den es nicht gibt, z.B. ein Medikament, das keine Wirkung hat\n\n2.\\(H_0\\) fälschlicherweise beibehalten (Fehler zweiter Art oder \\(\\beta\\)-Fehler)\n\ntypischer Fall in kleinen Studien, bei denen die Wirkung nicht ausreicht, um vorhandene Effekte zu erkennen\n\nVerwendung in der Praxis\n\nübliche Konvention in den Umweltwissenschaften: \\(\\alpha=0.05\\), muss vorher festgelegt werden\n\\(\\beta=f(\\alpha, \\text{Effektstärke}, \\text{Stichprobengröße},\n\\text{Art des Tests})\\), sollte \\(\\le 0.2\\) sein",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#signifikanz-und-relevanz",
    "href": "slides/05-classtests.html#signifikanz-und-relevanz",
    "title": "05-Klassische Tests",
    "section": "Signifikanz und Relevanz",
    "text": "Signifikanz und Relevanz\n\n\nStatistische Signifikanz: die Nullhypothese \\(H_0\\) ist im statistischen Sinne unwahrscheinlich.\nPraktische Relevanz (manchmal auch „praktische Signifikanz“ genannt): die Effektstärke ist groß genug, um in der Praxis eine Rolle zu spielen.\n\nOb ein Effekt relevant sein kann oder nicht, hängt also von seiner Effektstärke und dem Anwendungsbereich ab.\nBetrachten wir zum Beispiel eine Impfung. Wenn ein Impfstoff in einem klinischen Test eine signifikante Wirkung hat, aber nur 10 von 1000 Menschen schützt, würde man diesen Effekt nicht als relevant ansehen und diesen Impfstoff nicht herstellen.\nAndererseits können auch kleine Wirkungen von Bedeutung sein. Wenn also eine toxische Substanz bei 1 von 1000 Personen Krebs auslösen würde, würden wir das als relevant betrachten. Um es auch als signifikant zu erkennen, ist eine epidemiologische Studie mit einer großen Anzahl von Menschen erforderlich. Da es sich aber um eine hochrelevante Wirkung handelt, lohnt sich der Aufwand.",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#take-home-messages",
    "href": "slides/05-classtests.html#take-home-messages",
    "title": "05-Klassische Tests",
    "section": "Take home messages",
    "text": "Take home messages\n\nEin p-Wert misst die Wahrscheinlichkeit, dass ein rein zufälliger Effekt gleich groß oder größer ist als ein beobachteter Effekt, wenn die Nullhypothese wahr ist.\nSignifikant, die Ergebnisse sind unwahrscheinlich, wenn es keinen echten Effekt gäbe.\nNicht signifikant bedeutet nicht „kein Effekt“.\nNicht signifikante Ergebnisse deuten auf die Notwendigkeit weiterer Untersuchungen hin:\n\nVergrößerung der Stichprobe\nErhöhung des experimentellen Effekts\nReduzierung des experimentellen Fehlers\nWahl eines leistungsfähigeren statistischen Verfahrens\n\nWichtig: Konzentriere Dich nicht nur auf p-Werte und Signifikanz!\nVergiss nie, Stichprobengröße, Effektstärke und Relevanz anzugeben.\nBei großen Datensätzen:\n\nStatistisch signifikante Ergebnisse können leicht auch für sehr kleine und praktisch irrelevante Effekte erzielt werden.\n\\(\\rightarrow\\) Effektstärke und Relevanz werden wichtiger als p-Werte.",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#einstichproben-t-test",
    "href": "slides/05-classtests.html#einstichproben-t-test",
    "title": "05-Klassische Tests",
    "section": "Einstichproben-t-Test",
    "text": "Einstichproben-t-Test\n\n\nprüft, ob eine Stichprobe aus einer Grundgesamtheit mit gegebenem Mittelwert \\(\\mu\\) stammt\nbasiert auf der Prüfung, ob der Mittelwert der Grundgesamtheit \\(\\mu\\) im Konfidenzintervall von \\(\\bar{x}\\) liegt\n\n\nAngenommen, wir haben eine Stichprobe mit dem Umfang \\(n=10, \\bar{x}=5.5, s=1\\) und \\(\\mu=5\\).\nNun schätzen wir das 95%-Konfidenzintervall von \\(\\bar{x}\\):\n\n\\[\nCI = \\bar{x} \\pm t_{1-\\alpha/2, n-1} \\cdot s_{\\bar{x}}\n\\] mit \\[\ns_{\\bar{x}} = \\frac{s}{\\sqrt{n}} \\qquad \\text{(Standardfehler)}\n\\]\nAuf den folgenden Folien werden unterschiedliche Berechnungsmethoden vorgestellt.",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#zur-erinnerung-standardabweichung-und-standardfehler",
    "href": "slides/05-classtests.html#zur-erinnerung-standardabweichung-und-standardfehler",
    "title": "05-Klassische Tests",
    "section": "Zur Erinnerung: Standardabweichung und Standardfehler",
    "text": "Zur Erinnerung: Standardabweichung und Standardfehler\n\n Visualisierung eines Einstichproben-t-Test. Links: ursprüngliche Verteilung der Daten, gemessen an der Standardabweichung, rechts: Verteilung der Mittelwerte, gemessen an ihrem Standardfehler. \n\\[\ns_{\\bar{x}} = \\frac{s}{\\sqrt{n}} \\qquad \\text{(Standardfehler)}\n\\]\n\nStandardfehler &lt; Standardabweichung\nmisst die Genauigkeit des Mittelwerts\nZGWS!\n\nWichtig: Der Test arbeitet mit der Verteilung der Mittelwerte, nicht mit der Verteilung der ursprünglichen Daten.",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#methode-1-liegt-mu-im-konfidenzintervall",
    "href": "slides/05-classtests.html#methode-1-liegt-mu-im-konfidenzintervall",
    "title": "05-Klassische Tests",
    "section": "Methode 1: Liegt \\(\\mu\\) im Konfidenzintervall?",
    "text": "Methode 1: Liegt \\(\\mu\\) im Konfidenzintervall?\n\n\nStichprobe: \\(n=10, \\bar{x}=5.5, s=1\\) und \\(\\mu=5\\)\nWenn \\(\\alpha = 0,05\\) ist, erhalten wir ein zweiseitiges 95%-Konfidenzintervall mit:\n\n\\[\\bar{x} \\pm t_{0,975, n-1} \\cdot \\frac{s}{\\sqrt{n}}\\]\n\n\n5.5 + c(-1, 1) * qt(0.975, 10-1) * 1/sqrt(10)\n\n[1] 4.784643 6.215357\n\n\n\n\n\nPrüfung, ob \\(\\mu=5.0\\) in diesem Intervall liegt?\nJa, es befindet sich innerhalb \\(\\Rightarrow\\) Unterschied nicht signifikant.",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#methode-2-vergleich-mit-einem-tabellierten-t-wert",
    "href": "slides/05-classtests.html#methode-2-vergleich-mit-einem-tabellierten-t-wert",
    "title": "05-Klassische Tests",
    "section": "Methode 2: Vergleich mit einem tabellierten t-Wert",
    "text": "Methode 2: Vergleich mit einem tabellierten t-Wert\n\nUmstellung der Gleichung des Konfidenzintervalls, Berechnung eines beobachteten \\(t\\)-Werts, \\(t_{obs}\\):\n\n\\[\nt_{obs} = |\\bar{x}-\\mu | \\cdot \\frac{1}{s_{\\bar{x}}} = \\frac{|\\bar{x}-\\mu |}{s} \\cdot \\sqrt{n} = \\frac{|5.5 -5.0|}{1.0} \\cdot \\sqrt{10}\n\\]\nBerechnung in R:\n\nt &lt;- abs(5.5 - 5.0) / 1.0 * sqrt(10)\nt\n\n[1] 1.581139\n\n\n\nVergleich von \\(t_{obs}\\) mit einem tabellierten Wert\n\n\n„Historische Methode“: Ablesen des kritischen t-Wertes für gegebenes \\(\\alpha\\) und Freiheitsgrade (\\(n-1\\)) aus einer Tabelle.\nFür \\(\\alpha=0.05\\) und zweiseitig ist das: \\(t_{1-\\alpha/2, n-1} = 2.26\\).\n\nVergleich: \\(1.58 &lt; 2.26\\) \\(\\Rightarrow\\) kein signifikanter Unterschied zwischen \\(\\bar{x}\\) und \\(\\mu\\).",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#methode-3-berechnung-des-p-wertes-aus-t_obs",
    "href": "slides/05-classtests.html#methode-3-berechnung-des-p-wertes-aus-t_obs",
    "title": "05-Klassische Tests",
    "section": "Methode 3: Berechnung des p-Wertes aus \\(t_{obs}\\)",
    "text": "Methode 3: Berechnung des p-Wertes aus \\(t_{obs}\\)\n\n\nVerwendung der computergestützten Wahrscheinlichkeitsfunktion der t-Verteilung (pt) anstelle des Tabellenvergleichs\nFür \\(t = t_{obs}\\) und Anzahl der Freiheitsgrade (\\(n-1\\)):\n\n\n\n2 * (1 - pt(t, df = 10 - 1)) # 2 * (1 - p) ist umgestellt von 1-alpha/2\n\n[1] 0.1483047\n\n\nDer p-Wert = 0.1483047 ist größer als \\(0,05\\), somit betrachten wir die Differenz als nicht signifikant.\n\nFAQ: kleiner oder größer als?\n\n\n\n\n\n\n\n\n\n\np-Wert\n\\(\\text{p-Wert} &lt; \\alpha\\)\nNullhypothese unwahrscheinlich\nsignifikant\n\n\nTest Statistik\n\\(t_{obs} &gt; t_{1-\\alpha/2, n-1}\\)\nEffekt übersteigt Grenze\nsignifikant",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#methode-4-integrierte-t-test-funktion-in-r",
    "href": "slides/05-classtests.html#methode-4-integrierte-t-test-funktion-in-r",
    "title": "05-Klassische Tests",
    "section": "Methode 4: Integrierte t-Test-Funktion in R",
    "text": "Methode 4: Integrierte t-Test-Funktion in R\n\nDas Gleiche kann man viel einfacher mit dem Computer in R machen.\nAngenommen, wir haben eine Stichprobe mit \\(\\bar{x}=5, s=1\\):\n\n## definiere Stichprobe\nx &lt;- c(5.5, 3.5, 5.4, 5.3, 6, 7.2, 5.4, 6.3, 4.5, 5.9)\n\n## führe Einstichproben-t-Test durch\nt.test(x, mu = 5)\n\n\n    One Sample t-test\n\ndata:  x\nt = 1.5811, df = 9, p-value = 0.1483\nalternative hypothesis: true mean is not equal to 5\n95 percent confidence interval:\n 4.784643 6.215357\nsample estimates:\nmean of x \n      5.5 \n\n\nDer Test liefert den beobachteten t-Wert, das 95%-Konfidenzintervall und den p-Wert.\nEin wichtiger Unterschied ist, dass diese Methode mit den Originaldaten arbeitet, während die anderen Methoden nur Mittelwert, Standardabweichung und Stichprobenumfang benötigen.",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#zweistichproben-t-test",
    "href": "slides/05-classtests.html#zweistichproben-t-test",
    "title": "05-Klassische Tests",
    "section": "Zweistichproben-t-Test",
    "text": "Zweistichproben-t-Test\n\nDer Zweistichproben-t-Test vergleicht zwei unabhängige Stichproben:\n\nx1 &lt;- c(5.3, 6.0, 7.1, 6.4, 5.7, 4.9, 5.0, 4.6, 5.7, 4.0, 4.5, 6.5)\nx2 &lt;- c(5.8, 7.1, 5.8, 7.0, 6.7, 7.7, 9.2, 6.0, 7.2, 7.8, 7.8, 5.7)\nt.test(x1, x2)\n\n\n    Welch Two Sample t-test\n\ndata:  x1 and x2\nt = -3.7185, df = 21.611, p-value = 0.001224\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -2.3504462 -0.6662205\nsample estimates:\nmean of x mean of y \n 5.475000  6.983333 \n\n\n\n\n\\(\\rightarrow\\) beide Stichproben unterscheiden sich signifikant (\\(p &lt; 0,05\\))\nAnmerkung: R hat hier nicht den „normalen“ t-Test durchgeführt, sondern den Welch-Test (= heteroskedastischer t-Test),\nbei dem die Varianzen der beiden Stichproben nicht gleich sein müssen.",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#hypothese-und-formel-für-den-zweistichproben-t-test",
    "href": "slides/05-classtests.html#hypothese-und-formel-für-den-zweistichproben-t-test",
    "title": "05-Klassische Tests",
    "section": "Hypothese und Formel für den Zweistichproben-t-Test",
    "text": "Hypothese und Formel für den Zweistichproben-t-Test\n\n\n\\(H_0\\) \\(\\mu_1 = \\mu_2\\)\n\\(H_a\\) die beiden Mittelwerte sind unterschiedlich\nTestkriterium\n\\[\nt_{obs} =\\frac{|\\bar{x}_1-\\bar{x}_2|}{s_{tot}} \\cdot \\sqrt{\\frac{n_1 n_2}{n_1+n_2}}\n\\]\n\n\n\n\n\n\n\n\n\n\ngepoolte Standardabweichung\n\\[\ns_{tot} = \\sqrt{{({n}_1 - 1)\\cdot s_1^2 + ({n}_2 - 1)\\cdot s_2^2\n\\over ({n}_1 + {n}_2 - 2)}}\n\\]\nAnnahmen: Unabhängigkeit, gleiche Varianzen, annähernde Normalverteilung",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#der-welch-test",
    "href": "slides/05-classtests.html#der-welch-test",
    "title": "05-Klassische Tests",
    "section": "Der Welch-Test",
    "text": "Der Welch-Test\n\nBekannt als t-Test für Stichproben mit ungleicher Varianz, funktioniert auch bei gleicher Varianz!\n\nTestkriterium:\n\\[\nt = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{s^2_{\\bar{x}_1} + s^2_{\\bar{x}_2}}}\n\\]\nStandardfehler der einzelnen Stichproben:\n\\[\ns_{\\bar{x}_i} = \\frac{s_i}{\\sqrt{n_i}}\n\\] Korrigierte Freiheitsgrade:\n\\[\n\\text{df} = \\frac{\\frac{s^2_1}{n_1} + \\frac{s^2_2}{n_2}}{\\frac{s^4_1}{n^2_1(n_1-1)} + \\frac{s^4_2}{n^2_2(n_2-1)}}\n\\]",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#welch-test-in-r",
    "href": "slides/05-classtests.html#welch-test-in-r",
    "title": "05-Klassische Tests",
    "section": "Welch-Test in R",
    "text": "Welch-Test in R\n\n\n\nt.test(x1, x2)\n\n\n    Welch Two Sample t-test\n\ndata:  x1 and x2\nt = -3.7185, df = 21.611, p-value = 0.001224\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -2.3504462 -0.6662205\nsample estimates:\nmean of x mean of y \n 5.475000  6.983333 \n\n\n\n… das ist die Standardmethode der t.test-Funktion.",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#test-auf-varianzgleichheit-f-test",
    "href": "slides/05-classtests.html#test-auf-varianzgleichheit-f-test",
    "title": "05-Klassische Tests",
    "section": "Test auf Varianzgleichheit: F-Test",
    "text": "Test auf Varianzgleichheit: F-Test\n\n\\(H_0\\): \\(\\sigma_1^2 = \\sigma_2^2\\)\n\\(H_a\\): Varianzen ungleich\nTestkriterium:\n\\[F = \\frac{s_1^2}{s_2^2} \\]\n\ngrößere der beiden Varianzen im Zähler \\((s^2_1 &gt; s^2_2)\\)\nFreiheitsgrade (\\(n-1\\)) für Zähler und Nenner können verschieden sein\n\n\n\n\n\n\n\n\n\n\n\nBeispiel:\n\n\\(s_1=1\\), \\(s_2 =2\\), \\(n_1=5, n_2=10, F=\\frac{2^2}{1^2}=4\\)\nFreiheitsgrad: \\(9 \\atop 4\\)\n\n\\(\\Rightarrow\\) \\(F_{9, 4, \\alpha=0.975} = 8.9 &gt; 4 \\quad\\rightarrow\\) nicht signifikant",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#homogenität-der-varianz-bei-2-stichproben",
    "href": "slides/05-classtests.html#homogenität-der-varianz-bei-2-stichproben",
    "title": "05-Klassische Tests",
    "section": "Homogenität der Varianz bei > 2 Stichproben",
    "text": "Homogenität der Varianz bei &gt; 2 Stichproben\n\n\nBartlett’s Test:\n\nbartlett.test(list(x1, x2, x3))\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  list(x1, x2, x3)\nBartlett's K-squared = 7.7136, df = 2, p-value = 0.02114\n\n\n Fligner-Killeen Test (empfohlen):\n\nfligner.test(list(x1, x2, x3))\n\n\n    Fligner-Killeen test of homogeneity of variances\n\ndata:  list(x1, x2, x3)\nFligner-Killeen:med chi-squared = 2.2486, df = 2, p-value = 0.3249\n\n\n\n\n\n\n\n\n\n\n\n\n\nTests werden häufig verwendet, um die Annahmen für eine ANOVA zu überprüfen.",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#empfehlung-für-zweistichproben-t-tests",
    "href": "slides/05-classtests.html#empfehlung-für-zweistichproben-t-tests",
    "title": "05-Klassische Tests",
    "section": "Empfehlung für Zweistichproben-t-Tests",
    "text": "Empfehlung für Zweistichproben-t-Tests\n\nTraditionelles Vorgehen:\n\nTest auf gleiche Varianzen mit Hilfe des F-Tests: var.test(x, y)\nWenn die Varianzen gleich sind: t.test(x, y, var.equal = TRUE)\nandernfalls: t.test(x, y) (= Welch-Test)\nPrüfe, ob beide Stichproben einer Normalverteilung folgen.\n\n\nModerne Empfehlung (bevorzugt):\n\nVerwende keine Vortests!\nVerwende immer den Welch-Test: t.test(x, y)\nÜberprüfe die ungefähre Normalverteilung mit Box- oder QQ-Plots. Das ist weniger wichtig, wenn \\(n\\) groß ist.\n\nsiehe Zimmerman (2004) oder Wikipedia.",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#gepaarter-t-test",
    "href": "slides/05-classtests.html#gepaarter-t-test",
    "title": "05-Klassische Tests",
    "section": "Gepaarter t-Test",
    "text": "Gepaarter t-Test\n\nmanchmal auch „t-Test für abhängige Stichproben“ genannt\n\nder Begriff „abhängig“ kann irreführend sein, „gepaart“ ist eindeutiger\ndie Werte innerhalb der Stichproben müssen immer noch unabhängig sein\n\nBeispiele: linker Arm / rechter Arm; vorher / nachher\nist im Wesentlichen ein Einstichproben-t-Test von paarweisen Unterschieden gegen \\(\\mu=0\\)\n\nReduziert den Einfluss individueller Unterschiede („Kovariate“) dank Fokussierung auf die paarweisen Unterschiede\n\n\n\nx1 &lt;- c(2, 3, 4, 5, 6)\nx2 &lt;- c(3, 4, 7, 6, 8)\nt.test(x1, x2, var.equal=TRUE)\n\n\n    Two Sample t-test\n\ndata:  x1 and x2\nt = -1.372, df = 8, p-value = 0.2073\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -4.28924  1.08924\nsample estimates:\nmean of x mean of y \n      4.0       5.6 \n\n\np=0.20, nicht signifikant\n\n\nx1 &lt;- c(2, 3, 4, 5, 6)\nx2 &lt;- c(3, 4, 7, 6, 8)\nt.test(x1, x2, paired=TRUE)\n\n\n    Paired t-test\n\ndata:  x1 and x2\nt = -4, df = 4, p-value = 0.01613\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -2.710578 -0.489422\nsample estimates:\nmean difference \n           -1.6 \n\n\np=0.016, signifikant\nDer gepaarte t-Test besitzt in diesem Fall eine größere Power (Trennschärfe).",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#mann-whitney--und-wilcoxon-test",
    "href": "slides/05-classtests.html#mann-whitney--und-wilcoxon-test",
    "title": "05-Klassische Tests",
    "section": "Mann-Whitney- und Wilcoxon-Test",
    "text": "Mann-Whitney- und Wilcoxon-Test\n\n\nNichtparametrische Tests:\n\nKeine Annahmen über Form und Parameter der Verteilung, aber\nVerteilungen sollten ähnlich sein, sonst kann der Test irreführend werden.\n\nBasierend auf Rängen: Die Tests vergleichen die Ränge der Daten.\nBezeichnung “Mann-Whitney” für unabhängige Stichproben, “Wilcoxon” für gepaarte Stichproben.\n\n Grundprinzip: Zählung der so genannten „Inversionen“ der Ränge, d.h. wie oft sich die Reihenfolge der Stichproben überschneidet\n\nStichprobe A: 1, 3, 4, 5, 7\nStichprobe B: 6, 8, 9, 10, 11\nBeide Stichproben gemeinsam geordnet: 1, 3, 4, 5, 6, 7, 8, 9, 10, 11\nInversionen: \\(\\rightarrow\\) \\(U = 1\\)",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#mann-whitney-test-in-der-praxis",
    "href": "slides/05-classtests.html#mann-whitney-test-in-der-praxis",
    "title": "05-Klassische Tests",
    "section": "Mann-Whitney-Test in der Praxis",
    "text": "Mann-Whitney-Test in der Praxis\n\n\nWeise den beiden Stichproben \\(A\\) und \\(B\\) mit dem Stichprobenumfang \\(m\\) und \\(n\\) die Ränge \\(R_A\\) und \\(R_B\\) zu.\nBerechne die Anzahl der Inversionen \\(U\\):\n\n\\[\\begin{align*}\n     U_A &= m \\cdot n + \\frac{m (m + 1)}{2} - \\sum_{i=1}^m R_A \\\\\n     U_B &= m \\cdot n + \\frac{n (n + 1)}{2} - \\sum_{i=1}^n R_B \\\\\n     U   &= \\min(U_A, U_B)\n\\end{align*}\\]\n\nKritische Werte von \\(U\\) finden sich in gängigen Statistik-Lehrbüchern.\nIn R nicht notwendig, p-Wert wird direkt ausgegeben.\nAnmerkung: Verwende spezielle Version wilcox.exact mit Korrektur, wenn mehrfach gleiche Werte (Bindungen) vorliegen.",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#mann-whitney---wilcoxon-test-in-r",
    "href": "slides/05-classtests.html#mann-whitney---wilcoxon-test-in-r",
    "title": "05-Klassische Tests",
    "section": "Mann-Whitney - Wilcoxon-Test in R",
    "text": "Mann-Whitney - Wilcoxon-Test in R\n\n\nA &lt;- c(1, 3, 4, 5, 7)\nB &lt;- c(6, 8, 9, 10, 11)\n\nwilcox.test(A, B) # für gepaarte Daten optionales Argument `paired = TRUE` verwenden\n\n\n    Wilcoxon rank sum exact test\n\ndata:  A and B\nW = 1, p-value = 0.01587\nalternative hypothesis: true location shift is not equal to 0\n\n\n\nMann-Whitney - Wilcoxon-Test mit Bindungskorrektur\n\nwird angewendet, wenn die Rangunterschiede doppelte Werte enthalten\n\n\nA &lt;- c(1, 3, 4, 5, 7)\nB &lt;- c(6, 8, 9, 10, 11)\n\n\nlibrary(\"exactRankTests\")\nwilcox.exact(A, B, paired=TRUE)\n\n\n    Exact Wilcoxon signed rank test\n\ndata:  A and B\nV = 0, p-value = 0.0625\nalternative hypothesis: true mu is not equal to 0",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#permutationsmethoden",
    "href": "slides/05-classtests.html#permutationsmethoden",
    "title": "05-Klassische Tests",
    "section": "Permutationsmethoden",
    "text": "Permutationsmethoden\n\nGrundprinzip: Schätzung einer Teststatistik \\(\\xi_{obs}\\) aus der Stichprobe,\nResampling: Simulieren vieler \\(\\xi_{i, sim}\\) aus zufällig permutiertem Datensatz (\\(n = 999\\) oder mehr)\nWie extrem ist \\(\\xi_{est}\\) innerhalb der geordneten Reihe der simulierten Werte \\(\\xi_{i, sim}\\)?\n\n\nSei \\(\\xi_{obs}\\) in unserem Beispiel \\(4.5\\), dann sei \\(\\Rightarrow\\) \\(p= 0.97\\).",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#bestimmung-der-power-von-statistischen-tests",
    "href": "slides/05-classtests.html#bestimmung-der-power-von-statistischen-tests",
    "title": "05-Klassische Tests",
    "section": "Bestimmung der Power von statistischen Tests",
    "text": "Bestimmung der Power von statistischen Tests\n\nWie viele Wiederholungen benötige ich?\n\nHängt ab von:\n\nder relativen Effektstärke \\(\\frac{\\mathrm{Effekt}}{\\mathrm{Standardabweichung}}\\)\n\n\\[\\delta=\\frac{(\\bar{x}_1-\\bar{x}_2)}{s}\\]\n\ndem Stichprobenumfang \\(n\\)\ndem vordefinierten Signifikanzniveau \\(\\alpha\\)\nund der angewandten statistischen Methode\n\nJe kleiner \\(\\alpha\\), \\(n\\) und \\(\\delta\\), desto größer ist der Fehler zweiter Art (\\(\\beta\\)).\nDer \\(\\beta\\)-Fehler ist die Wahrscheinlichkeit, Effekte zu übersehen, obwohl sie vorhanden sind.\nDie Trennschärfe (Power) (\\(1-\\beta\\)) ist die Wahrscheinlichkeit, dass ein Test signifikant ist, wenn ein Effekt vorhanden ist.",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#poweranalyse-1",
    "href": "slides/05-classtests.html#poweranalyse-1",
    "title": "05-Klassische Tests",
    "section": "Poweranalyse",
    "text": "Poweranalyse\n\nFormel für den Mindeststichprobenumfang im Einstichprobenfall:\n\\[\nn = \\bigg(\\frac{z_\\alpha + z_{1-\\beta}}{\\delta}\\bigg)^2\n\\]\n\n\\(z\\): die Quantile (qnorm) der Standardnormalverteilung für \\(\\alpha\\) und für \\(1-\\beta\\)\n\\(\\delta=\\Delta / s\\): relative Effektstärke.\n\nBeispiel\nZweiseitiger Test mit \\(\\alpha=0.025\\) und \\(\\beta=0.2\\)\n\\(\\rightarrow\\) \\(z_\\alpha = 1.96\\), \\(z_\\beta=0.84\\), dann:\n\\[\nn= (1.96 + 0.84)^2 \\cdot 1/\\delta^2 \\approx 8 /\\delta^2\n\\]\n\\(\\delta = 1.0\\cdot \\sigma\\) \\(\\qquad\\Rightarrow\\) n &gt; 8\n\\(\\delta = 0.5\\cdot \\sigma\\) \\(\\qquad\\Rightarrow\\) n &gt; 32",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#power-des-t-tests",
    "href": "slides/05-classtests.html#power-des-t-tests",
    "title": "05-Klassische Tests",
    "section": "Power des t-Tests",
    "text": "Power des t-Tests\nDie Trennschärfe eines t-Tests bzw. der Mindeststichprobenumfang kann mit der Funktion power.t.test() geschätzt werden:\n\npower.t.test(n=5, delta=0.5, sig.level=0.05)\n\n\n     Two-sample t test power calculation \n\n              n = 5\n          delta = 0.5\n             sd = 1\n      sig.level = 0.05\n          power = 0.1038399\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\n\\(\\rightarrow\\) ‘power’ = 0.10\n\nFür \\(n=5\\) wird ein vorhandener Effekt von \\(0.5 \\sigma\\) nur in 1 von 10 Fällen entdeckt.\nFür eine Power von 80% bei \\(n=5\\) wird Effektstärke von mindestens \\(2\\sigma\\) benötigt:\n\n\npower.t.test(n=5, power=0.8, sig.level=0.05)\n\nFür einen schwachen Effekt von \\(0.5\\sigma\\) wird \\(n\\ge 64\\) in jeder Gruppe benötig:\n\npower.t.test(delta=0.5,power=0.8,sig.level=0.05)\n\n\\(\\Rightarrow\\) Man braucht entweder einen großen Stichprobenumfang oder einen starken Effekt.",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#simulierte-power-eines-t-tests",
    "href": "slides/05-classtests.html#simulierte-power-eines-t-tests",
    "title": "05-Klassische Tests",
    "section": "Simulierte Power eines t-Tests",
    "text": "Simulierte Power eines t-Tests\n\n\n# Grundgesamtheitsparameter\nn      &lt;- 10\nxmean1 &lt;- 50; xmean2 &lt;- 55\nxsd1   &lt;- xsd2 &lt;- 10\nalpha  &lt;- 0.05\n\nnn &lt;- 1000   # Anzahl an Testläufen der Simulation\na &lt;- b &lt;- 0  # initialisiere Zähler\nfor (i in 1:nn) {\n  # erstelle Zufallszahlen\n  x1 &lt;- rnorm(n, xmean1, xsd1)\n  x2 &lt;- rnorm(n, xmean2, xsd2)\n  # Ergebnisse des t-Tests\n  p &lt;- t.test(x1,x2,var.equal = TRUE)$p.value \n  if (p &lt; alpha) {\n     a &lt;- a+1\n   } else {\n     b &lt;- b+1\n  }\n}\nprint(paste(\"a=\", a, \", b=\", b, \", a/n=\", a/nn, \", b/n=\", b/nn))\n\n\nallgemeingültiges Verfahren, auch für andere Tests geeignet.",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#testen-auf-verteilungen",
    "href": "slides/05-classtests.html#testen-auf-verteilungen",
    "title": "05-Klassische Tests",
    "section": "Testen auf Verteilungen",
    "text": "Testen auf Verteilungen\nNominale Variablen\n\n\\(\\chi^2\\)-Test\nExakter Test von Fisher\n\nOrdinale Variablen\n\nCramér-von-Mises-Test\n\\(\\rightarrow\\) stärker als \\(\\chi^2\\) oder KS-Test\n\nMetrische Skalen\n\nKolmogorov-Smirnov-Test (KS-Test)\nShapiro-Wilks-Test (für Normalverteilung)\nGrafische Prüfungen",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#mehrfeldertafeln-für-nominale-variablen",
    "href": "slides/05-classtests.html#mehrfeldertafeln-für-nominale-variablen",
    "title": "05-Klassische Tests",
    "section": "Mehrfeldertafeln für nominale Variablen",
    "text": "Mehrfeldertafeln für nominale Variablen\n\nWerden für nominale (d. h. kategoriale oder qualitative) Daten verwendet.\nBeispiele: Augen- und Haarfarbe, medizinische Behandlung und Anzahl der geheilten/nicht geheilten Personen\nWichtig: Verwende absolute Messwerte (echte Zahlen!), keine Prozentsätze oder andere berechnete Daten (also nicht etwa Biomasse pro Fläche)\n\nBeispiel: Verteilung von Daphnien (Wasserflöhen) in den Wasserschichten eines Sees:\n\n\n\nKlon\nObere Schicht\nTiefe Schicht\n\n\n\n\nA\n50\n87\n\n\nB\n37\n78\n\n\nC\n72\n45\n\n\n\n\nIn der oberen Schicht wurden die Futteralgen bereits aufgefressen. Sie finden sich nur noch im sauerstoffarmen Tiefenwasser.\ngenetisch angepasste Klone mit höherem Hämoglobingehalt können in sauerstoffreies Wasser tauchen",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#rechenschema-des-chi2-tests",
    "href": "slides/05-classtests.html#rechenschema-des-chi2-tests",
    "title": "05-Klassische Tests",
    "section": "Rechenschema des \\(\\chi^2\\)-Tests",
    "text": "Rechenschema des \\(\\chi^2\\)-Tests\n\nBeobachtete Häufigkeiten \\(O_{ij}\\)\n\n\n\n\n\nKlon A\nKlon B\nKlon C\nSumme \\(s_i\\)\n\n\n\n\nObere Schicht\n50\n37\n72\n159\n\n\nUntere Schicht\n87\n78\n45\n210\n\n\nSumme \\(s_j\\)\n137\n115\n117\n\\(n=369\\)\n\n\n\n\n\n\n\n\n\n\n\nErwartete Häufigkeiten \\(E_{ij} = s_i \\cdot s_j / n\\) (Gleichverteilung = Nullhypothese)\n\n\n\n\n\nKlon A\nKlon B\nKlon C\nSumme \\(s_i\\)\n\n\n\n\nObere Schicht\n59.0\n49.6\n50.4\n159\n\n\nUntere Schicht\n78.0\n65.4\n66.6\n210\n\n\nSumme \\(s_j\\)\n137\n115\n117\n\\(n=369\\)\n\n\n\n\n\n\n\n\n\n\n\nTeststatistik \\(\\hat{\\chi}^2 = \\sum_{i, j} \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\\)\nVergleich mit kritischem \\(\\chi^2\\) aus der Tabelle mit \\((n_{Zeile} - 1) \\cdot (n_{Spalte} - 1)\\) df.",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#der-chi2-test-in-r",
    "href": "slides/05-classtests.html#der-chi2-test-in-r",
    "title": "05-Klassische Tests",
    "section": "Der \\(\\chi^2\\)-Test in R",
    "text": "Der \\(\\chi^2\\)-Test in R\n\nOrganisiere die Daten in einer Matrix mit 3 Zeilen (für die Klone) und 2 Spalten (für die Tiefen):\n\n\nx &lt;- matrix(c(50, 37, 72, 87, 78, 45), ncol=2)\nx\n\n     [,1] [,2]\n[1,]   50   87\n[2,]   37   78\n[3,]   72   45\n\n\n\n\n\nchisq.test(x)\n\n\n    Pearson's Chi-squared test\n\ndata:  x\nX-squared = 24.255, df = 2, p-value = 5.408e-06\n\n\n\n\nAnmerkung: Die Ergebnisse sind nur zuverlässig, wenn alle beobachteten Häufigkeiten \\(\\geq 5\\) sind.\nFür kleinere Stichproben ist der exakte Test von Fisher zu verwenden.",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#exakter-test-nach-fisher",
    "href": "slides/05-classtests.html#exakter-test-nach-fisher",
    "title": "05-Klassische Tests",
    "section": "Exakter Test nach Fisher",
    "text": "Exakter Test nach Fisher\n\n\n\nx &lt;- matrix(c(50, 37, 72, 87, 78, 45), ncol=2)\nx\n\n     [,1] [,2]\n[1,]   50   87\n[2,]   37   78\n[3,]   72   45\n\n\n\nfisher.test(x)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  x\np-value = 5.807e-06\nalternative hypothesis: two.sided\n\n\n\n\n\\(\\rightarrow\\) signifikante Korrelation zwischen den Klonen und der vertikalen Verteilung im See.",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#lieblingszahlen-von-hse-studenten",
    "href": "slides/05-classtests.html#lieblingszahlen-von-hse-studenten",
    "title": "05-Klassische Tests",
    "section": "Lieblingszahlen von HSE-Studenten",
    "text": "Lieblingszahlen von HSE-Studenten\n\n\nZahlen von 1..9, \\(n=34\\)\n\\(H_0\\): gleiche Wahrscheinlichkeit für alle Zahlen \\(1/9\\) (diskrete Gleichverteilung)\n\\(H_A\\): einige Zahlen bevorzugt \\(\\rightarrow\\) weichen von diskreter Gleichverteilung ab",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#chi-quadrat-test",
    "href": "slides/05-classtests.html#chi-quadrat-test",
    "title": "05-Klassische Tests",
    "section": "Chi-Quadrat-Test",
    "text": "Chi-Quadrat-Test\n\n\n\nobsfreq &lt;- c(1, 1, 6, 2, 2, 5, 8, 6, 3)\nchisq.test(obsfreq)\n\n\n    Chi-squared test for given probabilities\n\ndata:  obsfreq\nX-squared = 13.647, df = 8, p-value = 0.09144\n\nchisq.test(obsfreq, simulate.p.value = TRUE, B = 1000)\n\n\n    Chi-squared test for given probabilities with simulated p-value (based\n    on 1000 replicates)\n\ndata:  obsfreq\nX-squared = 13.647, df = NA, p-value = 0.0969\n\n\n\n\n\nEinstichproben \\(\\chi^2\\)-Test. Er testet auf Gleichheit der Häufigkeit in allen Klassen.\nDie simulationsbasierte Version des Tests (mit 1000 Wiederholungen) ist etwas genauer als der Standard-\\(\\chi^2\\)-Test, aber beide sind nicht signifikant.",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#cramér-von-mises-test",
    "href": "slides/05-classtests.html#cramér-von-mises-test",
    "title": "05-Klassische Tests",
    "section": "Cramér-von-Mises-Test",
    "text": "Cramér-von-Mises-Test\n\n\\[\nT = n \\omega^2 = \\frac{1}{12n} + \\sum_{i=1}^n \\left[ \\frac{2i-1}{2n}-F(x_i) \\right]^2\n\\]",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#cramér-von-mises-test-in-r",
    "href": "slides/05-classtests.html#cramér-von-mises-test-in-r",
    "title": "05-Klassische Tests",
    "section": "Cramér-von-Mises-Test in R",
    "text": "Cramér-von-Mises-Test in R\n\nlibrary(dgof)\nobsfreq &lt;- c(1, 1, 6, 2, 2, 5, 8, 6, 3)\n\n## CvM-Test benötigt Einzelwerte, nicht Klassenhäufigkeiten\nx &lt;- rep(1:length(obsfreq), obsfreq)\nx\n\n [1] 1 2 3 3 3 3 3 3 4 4 5 5 6 6 6 6 6 7 7 7 7 7 7 7 7 8 8 8 8 8 8 9 9 9\n\n\n\n\n## erstelle kumulative Verteilung mit identischer Wahrscheinlichkeit für alle Fälle\ncdf &lt;- stepfun(1:9, cumsum(c(0, rep(1/9, 9))))\ncdf &lt;- ecdf(1:9)\n\n## führe den Test durch\ncvm.test(x, cdf)\n\n\n    Cramer-von Mises - W2\n\ndata:  x\nW2 = 0.51658, p-value = 0.03665\nalternative hypothesis: Two.sided\n\n\n\nDer Cramér-von-Mises-Test arbeitet mit den ursprünglichen, nicht in klassen eingeteilten Werten.\nVerwendung der kumulativen Verteilungsfunktion berücksichtigt die Reihenfolge der Klassen \\(\\rightarrow\\) leistungsfähiger als \\(\\chi^2\\)-Test.",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#testen-oder-prüfen",
    "href": "slides/05-classtests.html#testen-oder-prüfen",
    "title": "05-Klassische Tests",
    "section": "Testen oder Prüfen?",
    "text": "Testen oder Prüfen?\n\nPhilosophisches Problem: Wir wollen \\(H_0\\) behalten!\n\nGleichheit kann nicht getestet werden\nDeshalb: besser „Normalität prüfen“ sagen.\n\nVorab denken\n\nMacht die Normalverteilung für die Daten „Sinn“?\nSind die Daten metrisch (kontinuierlich)?\nWas ist der Prozess der Datenerzeugung \\(\\rightarrow\\) fachlicher Kontext?\n\nIntrinsische Nicht-Normalität\n\nEinige Datentypen, wie z. B. Zähldaten (z. B. Anzahl der Vorkommnisse) oder binäre Daten (z. B. Ja/Nein), sind von Natur aus nicht normalverteilt.\n\n\nBinäre Daten: Verwende Methoden für Binomialverteilung mit den Rohdaten anstelle von Prozentsätzen\nZähldaten: Nutze Methoden für die Poisson-Verteilung",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#shapiro-wilks-w-test",
    "href": "slides/05-classtests.html#shapiro-wilks-w-test",
    "title": "05-Klassische Tests",
    "section": "Shapiro-Wilks-W-Test ?",
    "text": "Shapiro-Wilks-W-Test ?\n\\(\\rightarrow\\) Ziel: prüft, ob eine Stichprobe aus einer Normalverteilung stammt\n\nx &lt;- rnorm(100)\nshapiro.test(x)\n\n\n    Shapiro-Wilk normality test\n\ndata:  x\nW = 0.99064, p-value = 0.7165\n\n\n\n\\(\\rightarrow\\) der \\(p\\)-Wert ist größer als 0.05, also würden wir \\(H_0\\) behalten und schlussfolgern, dass nichts gegen die Annahme der Normalität spricht\n\nDie Interpretation des Shapiro-Wilks-Tests ist mit Vorsicht zu betrachten:\n\nfür kleine \\(n\\) ist der Test nicht empfindlich genug\nbei großen \\(n\\) ist er überempfindlich\nDie Verwendung von Shapiro-Wilks zur Überprüfung der Normalität für t-Tests und ANOVA wird nicht mehr empfohlen\n\n\n\nAuch die \\(\\chi^2\\)- (Chi-Quadrat-) oder Kolmogorov-Smirnov-Tests werden für Normalitätstests nicht mehr empfohlen, sind aber für andere Testprobleme weiterhin wichtig.",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#alternative-verwendung-grafischer-methoden",
    "href": "slides/05-classtests.html#alternative-verwendung-grafischer-methoden",
    "title": "05-Klassische Tests",
    "section": "Alternative: Verwendung grafischer Methoden",
    "text": "Alternative: Verwendung grafischer Methoden\n\n\n\nHistogramm, Boxplot, QQ-Plot (=Quantil-Quantil-Plot)\nsiehe auch: Box-Cox-Methode",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#grafische-überprüfung-der-normalität",
    "href": "slides/05-classtests.html#grafische-überprüfung-der-normalität",
    "title": "05-Klassische Tests",
    "section": "Grafische Überprüfung der Normalität",
    "text": "Grafische Überprüfung der Normalität\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(x\\): theoretische Quantile, wo die Werte bei Vorliegen einer Normalverteilung gefunden werden sollten\n\\(y\\): normalisierte und geordnete Messwerte (\\(z\\)-Werte)\nskaliert in der Einheit der Standardabweichungen\nNormalverteilung liegt vor, wenn die Punkte einer Geraden folgen",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#prüfung-der-verteilung-für-deskriptive-zwecke",
    "href": "slides/05-classtests.html#prüfung-der-verteilung-für-deskriptive-zwecke",
    "title": "05-Klassische Tests",
    "section": "Prüfung der Verteilung für deskriptive Zwecke",
    "text": "Prüfung der Verteilung für deskriptive Zwecke\n\nIn manchen Disziplinen, z.B. in der Hydrologie, möchte man gelegentlich wissen, welcher Verteilungstyp einen Datensatz am besten beschreibt. Ein Beispiel ist die Extremwertanalyse (z.B. 100-jähriges Hochwasser), da hier das Central Limit Theorem (CLT) nicht greift.\nVorgehensweise\n\nVisuelle Prüfung (besonders auf die tails achten)\n\nHistogramm (erster Eindruck)\nQ-Q-Plots (genauere Passform)\n\nFormale Tests zur Ergänzung (Ausschlussprinzip)\n\nTests: Kolmogorov-Smirnov, Cramér-von Mises oder Anderson-Darling\nAblehnung des Verteilungstyps bei signifikantem \\(p &lt; 0.05\\).\n\nModellselektion\n\nNutzung von AIC/BIC zur Identifikation des optimalen Modells\nBerücksichtigung der physikalischen Plausibilität der Parameter",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#transformationen-1",
    "href": "slides/05-classtests.html#transformationen-1",
    "title": "05-Klassische Tests",
    "section": "Transformationen",
    "text": "Transformationen\n\nErmöglicht die Anwendung von Methoden, die für normalverteilte Daten entwickelt wurden, auf nicht-normalverteilte Fälle.\nEinige moderne Methoden (z. B. verallgemeinerte lineare Modelle, GLM) können bestimmte Verteilungen direkt verarbeiten, z.B. Binomial-, Gamma- oder Poisson-Verteilung.\n\nTransformationen für rechtsschiefe Daten\n\n\\(x'=\\log(x)\\)\n\\(x'=\\log(x + a)\\)\n\\(x'=(x+a)^c\\) (\\(a\\) zwischen 0,5 und 1)\n\\(x'=1/x\\) („sehr stark“, d.h. in den meisten Fällen zu extrem)\n\\(x'=a - 1/\\sqrt{x}\\) (um die Skalierung zu vereinfachen)\n\\(x'=1/\\sqrt{x}\\) (Kompromiss zwischen \\(\\ln\\) und \\(1/x\\))\n\\(x'=a+bx^c\\) (sehr allgemein, schließt Potenzen und Wurzeln ein)",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#transformationen-ii",
    "href": "slides/05-classtests.html#transformationen-ii",
    "title": "05-Klassische Tests",
    "section": "Transformationen II",
    "text": "Transformationen II\nTransformationen für Zähldaten\n\n\\(x'=\\sqrt{3/8+x}\\) (Zählungen: 1, 2, 3 \\(\\rightarrow\\) 0.61, 1.17, 1.54, 1.84, )\n\\(x'=\\lg(x+3/8)\\)\n\\(x'=\\log(\\log(x))\\) für riesige Zahlen\n\n\\(\\rightarrow\\) besser: ein GLM der Familien Poisson oder Quasi-Poisson in Betracht ziehen\nVerhältnisse und Prozentsätze\n\n\\(x'=\\arcsin \\sqrt{x/n}\\)\n\\(x'=\\arcsin \\sqrt{\\frac{x+3/8}{n+3/4}}\\)\n\n\\(\\rightarrow\\) besser: ein GLM mit Binomialverteilung in Betracht ziehen",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#wie-findet-man-die-beste-transformation",
    "href": "slides/05-classtests.html#wie-findet-man-die-beste-transformation",
    "title": "05-Klassische Tests",
    "section": "Wie findet man die beste Transformation?",
    "text": "Wie findet man die beste Transformation?\n\nBeispiel: Biovolumen von Kieselalgenzellen (Art Nitzschia acicularis).\n\n\n\n\ndat &lt;- read.csv(\"prk_nit.csv\")\n\nNit85 &lt;- dat$biovol[dat$group == \"nit85\"]\nNit90 &lt;- dat$biovol[dat$group == \"nit90\"]\n\nhist(Nit85, xlab=\"Biovolume (mm^3)\")\nhist(Nit90, xlab=\"Biovolume (mm^3)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRechtsschiefe Verteilung.\nBerechnungen des Biovolumens für Studien zum Nahrungsnetz und zur Vorhersage von Algenmassenentwicklungen.\n\n\n\nMehr über Nitzschia in Wikipedia\nDatensatz prk_nit.csv und Metadaten prk_nit_info.txt verfügbar unter https://github.com/tpetzoldt/datasets.",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#box-cox-methode",
    "href": "slides/05-classtests.html#box-cox-methode",
    "title": "05-Klassische Tests",
    "section": "Box-Cox Methode",
    "text": "Box-Cox Methode\nAbschätzung der optimalen Transformation aus der Klasse der Potenzen und Logarithmen:\n\\[\ny' = \\begin{cases} \\frac{y^\\lambda - 1}{\\lambda} & \\text{wenn } \\lambda \\neq 0 \\\\ \\ln(y) & \\text{wenn } \\lambda = 0 \\end{cases}\n\\]\nIn vielen praktischen Fällen kann man statt \\(\\frac{y^\\lambda - 1}{\\lambda}\\) vereinfacht \\(y^\\lambda\\) verwenden.\n\n\n\n\nlibrary(MASS)\n\nboxcox(Nit90 ~ 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArgument von boxcox ist eine sogenannte „Modellformel“ oder das Ergebnis eines linearen Modells (lm)\nDie einfachste Form ist das „Nullmodell“ ohne Erklärungsvariablen (~ 1).\nMehr über Modellformeln, siehe ANOVA Kapitel.",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#box-cox-methode-ergebnisse",
    "href": "slides/05-classtests.html#box-cox-methode-ergebnisse",
    "title": "05-Klassische Tests",
    "section": "Box-Cox Methode: Ergebnisse",
    "text": "Box-Cox Methode: Ergebnisse\n\n\nInterpretation\n\n\nDie gepunkteten vertikalen Linien und die horizontale 95%-Linie zeigen die Vertrauensgrenzen für mögliche Transformationen.\nDie Zahlen sind angenähert \\(\\rightarrow\\) eine Dezimalstelle genügt.\nHier können wir entweder eine log-Transformation (\\(\\lambda=0\\)) oder eine Potenz von \\(\\approx 0.5\\) verwenden.\n\n\n\n\nDirekte Ermittlung des Zahlenwerts:\n\nbc &lt;- boxcox(Nit90 ~ 1)\n\n\n\n\n\n\n\nstr(bc)\n\nList of 2\n $ x: num [1:100] -2 -1.96 -1.92 -1.88 -1.84 ...\n $ y: num [1:100] -237 -233 -230 -226 -223 ...\n\nbc$x[bc$y == max(bc$y)]\n\n[1] 0.1818182",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#test-von-gepoolten-stichproben-mit-unterschiedlichen-mittelwerten",
    "href": "slides/05-classtests.html#test-von-gepoolten-stichproben-mit-unterschiedlichen-mittelwerten",
    "title": "05-Klassische Tests",
    "section": "Test von gepoolten Stichproben mit unterschiedlichen Mittelwerten",
    "text": "Test von gepoolten Stichproben mit unterschiedlichen Mittelwerten\n\nboxcox(biovol ~ group, data = dat)\n\n\n\nUm die gemeinsame Verteilung aller Gruppen auf einmal zu testen, gibt man die Erklärungsvariablen auf der rechten Seite der Modellformel an: biovol ~ group\nDie optimale Transformation für beide Stichproben zusammen ist log.",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#korrelation",
    "href": "slides/05-classtests.html#korrelation",
    "title": "05-Klassische Tests",
    "section": "Korrelation",
    "text": "Korrelation\n\nHäufigkeiten von nominalen Variablen\n\n\\(\\chi^2\\)-Test\nExakter Test von Fisher\n\n⇒ Abhängigkeit zwischen Pflanzenart und Bodentyp\n(siehe oben)\nOrdinale Variablen\n\nSpearman-Korrelation\n\n\\(\\rightarrow\\) Rangzahlen\nMetrische Skalen\n\nPearson-Korrelation\nSpearman-Korrelation",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#varianz-und-kovarianz",
    "href": "slides/05-classtests.html#varianz-und-kovarianz",
    "title": "05-Klassische Tests",
    "section": "Varianz und Kovarianz",
    "text": "Varianz und Kovarianz\n\n\nVarianz\n\nmisst die Variation einer einzelnen Variablen\n\n\\[\n  s^2_x = \\frac{\\text{Quadratsumme}}{\\text{Freiheitsgrade}}=\\frac{\\sum_{i=1}^n (x_i-\\bar{x})^2}{n-1}\n\\]\nKovarianz\n\nmisst, wie sich zwei Variablen gemeinsam verändern\n\n\\[\n  q_{x,y} = \\frac{\\sum_{i=1}^n (x_i-\\bar{x})(y_i-\\bar{y})}{n-1}\n\\]\nKorrelation: skaliert auf \\((-1, +1)\\)\n\\[\n  r_{x,y} = \\frac{q_{x,y}}{s_x \\cdot s_y}\n\\]",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#korrelationskoeffizient-nach-pearson",
    "href": "slides/05-classtests.html#korrelationskoeffizient-nach-pearson",
    "title": "05-Klassische Tests",
    "section": "Korrelationskoeffizient nach Pearson",
    "text": "Korrelationskoeffizient nach Pearson\n\n\n\nder übliche Korrelationskoeffizient, den wir alle kennen\ntestet auf lineare Abhängigkeit\n\n\\[\nr_p=\\frac{\\sum{(x_i-\\bar{x})  (y_i-\\bar{y})}}\n       {\\sqrt{\\sum(x_i-\\bar{x})^2\\sum(y_i-\\bar{y})^2}}\n\\]\nOder:\n\\[\nr_p=\\frac {\\sum xy - \\sum y \\sum y / n}\n        {\\sqrt{(\\sum x^2-(\\sum x)^2/n)(\\sum y^2-(\\sum y)^2/n)}}\n\\] \nWertebereich: \\(-1 \\le r_p \\le +1\\)\n\n\n\n\\(0\\)\nkeine gegenseitige Abhängigkeit\n\n\n\\(+1 \\,\\text{or}\\,-1\\)\nstrikt positive bzw. negative Abhängigkeit\n\n\n\\(0 &lt; |r_p| &lt; 1\\)\npositive bzw. negative Abhängigkeit",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#welcher-korrelationskoeffizient-deutet-auf-eine-abhängigkeit-hin",
    "href": "slides/05-classtests.html#welcher-korrelationskoeffizient-deutet-auf-eine-abhängigkeit-hin",
    "title": "05-Klassische Tests",
    "section": "Welcher Korrelationskoeffizient deutet auf eine Abhängigkeit hin?",
    "text": "Welcher Korrelationskoeffizient deutet auf eine Abhängigkeit hin?\n\n\n\n\n\n\n\n\n\n\n\\(r=0.4, \\quad p=0.0039\\)\n\n\n\n\n\n\n\n\n\n\n\\(r=0.85, \\quad p=0.07\\)",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#signifikante-korrelation",
    "href": "slides/05-classtests.html#signifikante-korrelation",
    "title": "05-Klassische Tests",
    "section": "Signifikante Korrelation?",
    "text": "Signifikante Korrelation?\n\\[\n\\hat{t}_{\\alpha/2;n-2} =\\frac{|r_p|\\sqrt{n-2}}{\\sqrt{1-r^2_p}}\n\\]\n\\(t=0.829 \\cdot \\sqrt{1000-2}/\\sqrt{1-0.829^2}=46.86, df=998\\)\n Schnelltest: kritische Werte für \\(r_p\\)\n\n\n\n\\(n\\)\nd.f.\n\\(t\\)\n\\(r_{krit}\\)\n\n\n3\n1\n12.706\n0.997\n\n\n5\n3\n3.182\n0.878\n\n\n10\n8\n2.306\n0.633\n\n\n20\n18\n2.101\n0.445\n\n\n50\n48\n2.011\n0.280\n\n\n100\n98\n1.984\n0.197\n\n\n1000\n998\n1.962\n0.062",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#rangkorrelation-nach-spearman",
    "href": "slides/05-classtests.html#rangkorrelation-nach-spearman",
    "title": "05-Klassische Tests",
    "section": "Rangkorrelation nach Spearman",
    "text": "Rangkorrelation nach Spearman\n\n\nmisst monotone (und nicht unbedingt lineare) Abhängigkeiten\nSchätzung aus Rangunterschieden:\n\n\\[\nr_s=1-\\frac{6 \\sum d^2_i}{n(n^2-1)}\n\\]\n\nalternativ: Pearson-Korrelation der rang-transformierten Daten (notwendig bei Bindungen).\nTest: für \\(n &lt; 10\\) \\(\\rightarrow\\) Tabelle der kritischen Werte\n\nfür \\(10 \\leq n\\) \\(\\rightarrow\\) \\(t\\)-Verteilung\n\\[\n   \\hat{t}_{1-\\frac{\\alpha}{2};n-2}\n      =\\frac{|r_s|}{\\sqrt{1-r^2_S}} \\sqrt{n-2}\n\\]\n\n\nComputerstatistikpakete verwenden einen speziellen Algorithmus (Algorithmus AS 89 nach Best und Roberts, 1975).",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#beispiel",
    "href": "slides/05-classtests.html#beispiel",
    "title": "05-Klassische Tests",
    "section": "Beispiel",
    "text": "Beispiel\n\n\n\n\n\\(x\\)\n\\(y\\)\n\\(R_x\\)\n\\(R_y\\)\n\\(d\\)\n\\(d^2\\)\n\n\n\n\n1\n2.7\n1\n1\n0\n0\n\n\n2\n7.4\n2\n2\n0\n0\n\n\n3\n20.1\n3\n3\n0\n0\n\n\n4\n500.0\n4\n5\n-1\n1\n\n\n5\n148.4\n5\n4\n+1\n1\n\n\n\n\n\n\n\n2\n\n\n\n\n\n\n\n\n\n\n\n\\[\nr_s=1-\\frac{6 \\cdot 2}{5\\cdot (25-1)}=1-\\frac{12}{120}=0.9\n\\]\nZum Vergleich: \\(r_p=0.58\\)",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#anwendung-von-spearmans-r_s",
    "href": "slides/05-classtests.html#anwendung-von-spearmans-r_s",
    "title": "05-Klassische Tests",
    "section": "Anwendung von Spearman’s-\\(r_s\\)",
    "text": "Anwendung von Spearman’s-\\(r_s\\)\n\nVorteile\n\nverteilungsfrei (erfordert keine Normalverteilung),\nerkennt jegliche monotone Abhängigkeit,\nwird durch Ausreißer kaum beeinträchtigt.\n\nNachteile:\n\ngewisser Informationsverlust aufgrund der Rangbildung,\nkeine Informationen über die Art der Abhängigkeit,\nkeine direkte Beziehung zum Bestimmtheitsmaß.\n\nFazit: \\(r_s\\) ist dennoch sehr empfehlenswert!",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#korrelationskoeffizienten-in-r",
    "href": "slides/05-classtests.html#korrelationskoeffizienten-in-r",
    "title": "05-Klassische Tests",
    "section": "Korrelationskoeffizienten in R",
    "text": "Korrelationskoeffizienten in R\n\nPearson’s Produkt-Moment-Korrelationskoeffizient\nSpearman’s Rangkorrelationskoeffizient\n\n\nx &lt;- c(1, 2, 3, 5, 7,  9)\ny &lt;- c(3, 2, 5, 6, 8, 11)\ncor.test(x, y, method=\"pearson\")\n\n\n    Pearson's product-moment correlation\n\ndata:  x and y\nt = 7.969, df = 4, p-value = 0.001344\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.7439930 0.9968284\nsample estimates:\n      cor \n0.9699203 \n\n\nWenn Linearität oder Normalität der Residuen zweifelhaft sind, verwende eine Rangkorrelation\n\ncor.test(x, y, method=\"spearman\")\n\n\n    Spearman's rank correlation rho\n\ndata:  x and y\nS = 2, p-value = 0.01667\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.9428571",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#problemfälle",
    "href": "slides/05-classtests.html#problemfälle",
    "title": "05-Klassische Tests",
    "section": "Problemfälle",
    "text": "Problemfälle",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#ausblick-mehr-als-zwei-unabhängige-variablen",
    "href": "slides/05-classtests.html#ausblick-mehr-als-zwei-unabhängige-variablen",
    "title": "05-Klassische Tests",
    "section": "Ausblick: Mehr als zwei unabhängige Variablen",
    "text": "Ausblick: Mehr als zwei unabhängige Variablen\n\nMultiple Korrelation\n\nBeispiel: Chl-a=\\(f(x_1, x_2, x_3, \\dots)\\), wobei \\(x_i\\) = Biomasse der \\(i\\)-ten Phytoplanktonart.\nmultipler Korrelationskoeffizient\npartieller Korrelationskoeffizient\nAttraktive Methode \\(\\leftrightarrow\\), aber in der Praxis schwierig:\n\n„unabhängige“ Variablen können miteinander korrelieren (Multikollinearität) \\(\\Rightarrow\\) Verzerrung des Vielfachen \\(r\\).\nNichtlinearitäten sind noch schwieriger zu handhaben als im Fall von zwei Stichproben.\n\n\nEmpfehlung:\n\nVerwende multivariate Methoden (NMDS, PCA, …) für einen ersten Überblick,\nWende die multiple Regression mit Sorgfalt an und nutze Prozesswissen.",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/05-classtests.html#literatur",
    "href": "slides/05-classtests.html#literatur",
    "title": "05-Klassische Tests",
    "section": "Literatur",
    "text": "Literatur\n\n\n\n\n\nHubbard, R. (2004). Alphabet soup: Blurring the distinctions between p’s and a’s in psychological research. Theory & Psychology, 14(3), 295–327. https://doi.org/10.1177/0959354304043638\n\n\nZimmerman, D. W. (2004). A note on preliminary tests of equality of variances. British Journal of Mathematical and Statistical Psychology, 57(1), 173–181. https://doi.org/10.1348/000711004849222",
    "crumbs": [
      "Statistische Grundlagen",
      "05-Klassische Tests"
    ]
  },
  {
    "objectID": "slides/03-statparams.html#statistische-parameter",
    "href": "slides/03-statparams.html#statistische-parameter",
    "title": "03-Statistische Parameter",
    "section": "Statistische Parameter",
    "text": "Statistische Parameter\n\n\\(\\rightarrow\\) Zur Erinnerung: Die Berechnung statistischer Parameter wird als Schätzung bezeichnet.\nEigenschaften von statistischen Parametern\n\nErwartungstreue: die Schätzung konvergiert mit zunehmendem \\(n\\) gegen den wahren Wert\nEffizienz für eine gute Schätzung ist ein relativ kleines \\(n\\) ausreichend\nRobustheit die Schätzung wird durch Ausreißer oder gewisse Verletzungen statistischer Annahmen nur wenig beeinflusst\n\nJe nach Fragestellung gibt es verschiedene Arten von Parametern, insbesondere Maße der Lage (z.B. Mittelwert, Median), der Variation (z. B. Varianz, Standardabweichung) oder der Abhängigkeit (z. B. Korrelation).",
    "crumbs": [
      "Statistische Grundlagen",
      "03-Statistische Parameter"
    ]
  },
  {
    "objectID": "slides/03-statparams.html#lagemaße-i",
    "href": "slides/03-statparams.html#lagemaße-i",
    "title": "03-Statistische Parameter",
    "section": "Lagemaße I",
    "text": "Lagemaße I\n\nArithmetisches Mittel\n\\[\n  \\bar{x} = \\frac{1}{n} \\cdot {\\sum_{i=1}^n x_i}\n\\]\n\nGeometrisches Mittel\n\\[\n  G = \\sqrt[n]{\\prod_{i=1}^n x_i}\n\\]\nPraktischer: logarithmische Form:\n\\[\n  G =\\exp\\Bigg(\\frac{1}{n} \\cdot {\\sum_{i=1}^n \\ln{x_i}}\\Bigg)\n\\]\nvermeidet große Zahlen, die dem Computer numerische Probleme bereiten.",
    "crumbs": [
      "Statistische Grundlagen",
      "03-Statistische Parameter"
    ]
  },
  {
    "objectID": "slides/03-statparams.html#lagemaße-ii",
    "href": "slides/03-statparams.html#lagemaße-ii",
    "title": "03-Statistische Parameter",
    "section": "Lagemaße II",
    "text": "Lagemaße II\nHarmonisches Mittel\n\\[\n    \\frac{1}{H}=\\frac{1}{n}\\cdot \\sum_{i=1}^n \\frac{1}{x_i} \\quad; x_i&gt;0\n\\]\nBeispiel:\nMan fährt mit 50km/h zur Uni und mit 100km/h wieder nach Hause. Wie groß ist die mittlere Geschwindigkeit?\nErgebnis:\n1/((1/50 + 1/100)/2) = 1/((0.02 + 0.01)/2) = 1/0.015 = 66.67",
    "crumbs": [
      "Statistische Grundlagen",
      "03-Statistische Parameter"
    ]
  },
  {
    "objectID": "slides/03-statparams.html#median-zentralwert",
    "href": "slides/03-statparams.html#median-zentralwert",
    "title": "03-Statistische Parameter",
    "section": "Median (Zentralwert)",
    "text": "Median (Zentralwert)\n \\(n\\) ungerade: Daten sortieren, den mittleren Wert nehmen\n\\[\\tilde{x} = x_{(n+1)/2}\\] \\(n\\) gerade: Daten sortieren, Durchschnitt der beiden mittleren Werte bilden\n\\[\\tilde{x} = \\frac{x_{n/2}+x_{n/2+1}}{2}\\]\nBeispiel\n\n\n\n\n\n\n\nStichprobe mit 7 Werten\n2.9, 7.9, 4.1, 8.8, 9.4, 0.5, 5.3\n\n\nsortierte Stichprobe\n0.5, 2.9, 4.1, 5.3, 7.9, 8.8, 9.4\n\n\n\n\n\n\n\n\\(\\Rightarrow\\) Median: \\(\\tilde{x} = 5.3\\)\n\\(\\Rightarrow\\) Mittelwert: \\(\\bar{x} = 5.5571429\\)",
    "crumbs": [
      "Statistische Grundlagen",
      "03-Statistische Parameter"
    ]
  },
  {
    "objectID": "slides/03-statparams.html#getrimmter-mittelwert",
    "href": "slides/03-statparams.html#getrimmter-mittelwert",
    "title": "03-Statistische Parameter",
    "section": "Getrimmter Mittelwert",
    "text": "Getrimmter Mittelwert\n\n\nauch „gestutzter Mittelwert“ genannt\nKompromiss zwischen dem arithmetischen Mittel und dem Median\nEin bestimmter Prozentsatz der kleinsten und größten Werte wird ignoriert(z.B. 10% oder 25%), bevor das arithmetische Mittel berechnet wird\nwird auch im Sport verwendet\n\nBeispiel: Stichprobe mit 20 Werten, 10% auf beiden Seiten ausschließen\n0.4, 0.5, 1, 2.5, 2.9, 3.3, 4.1, 4.5, 4.6, 5.3, 5.5, 5.7, 6.8, 7.9, 8.8, 8.9, 9, 9.4, 9.6, 46\n\\(\\rightarrow\\) Arithmetisches Mittel: \\(\\bar{x}=7.335\\) \\(\\rightarrow\\) Getrimmter Mittelwert: \\(\\bar{x}_{t, 0.1}=5.6375\\)\n\nMedian und getrimmter Mittelwert werden weniger von Ausreißern und Schiefe der Verteilung beeinflusst \\(\\rightarrow\\) robuster\naber etwas weniger effizient",
    "crumbs": [
      "Statistische Grundlagen",
      "03-Statistische Parameter"
    ]
  },
  {
    "objectID": "slides/03-statparams.html#pseudomedian-hodges-lehmann-schätzer",
    "href": "slides/03-statparams.html#pseudomedian-hodges-lehmann-schätzer",
    "title": "03-Statistische Parameter",
    "section": "Pseudomedian (Hodges-Lehmann-Schätzer)",
    "text": "Pseudomedian (Hodges-Lehmann-Schätzer)\n\nDer Pseudomedian (\\(\\tilde{x}^*\\)) ist ein robuster und effizienter Schätzer für den Lageparameter. Er wird als Median aller möglichen Mittelwerte von je zwei Beobachtungen berechnet.\n\\[\\tilde{x}^* = \\text{median}\\left(M_{ij}\\right) \\text{ mit } M_{ij} = \\frac{x_i + x_j}{2} \\text{ für } 1 \\le i \\le j \\le n\\]\nBeispiel\n\nlibrary(Hmisc) \n\n# Verwenden der gleichen Stichprobe wie für den Median\nset.seed(123)\nx &lt;- round(runif(7, max = 10), 1)\n\n# Sortierung für bessere Lesbarkeit des Beispiels (nicht Teil der pMedian-Berechnung)\nsort(x) \n\n[1] 0.5 2.9 4.1 5.3 7.9 8.8 9.4\n\n# arithmetisches Mittel, Median, Pseudomedian\nc(mean(x), median(x), pMedian(x))\n\n[1] 5.557143 5.300000 5.625000\n\n\nBeachte: Strengenommen wird der Grundgesamtheitsparameter als “Pseudomedian” bezeichnet, der Stichprobenparameter als “Hodges-Lehmann-Schätzer”.",
    "crumbs": [
      "Statistische Grundlagen",
      "03-Statistische Parameter"
    ]
  },
  {
    "objectID": "slides/03-statparams.html#modus-modalwert",
    "href": "slides/03-statparams.html#modus-modalwert",
    "title": "03-Statistische Parameter",
    "section": "Modus (Modalwert)",
    "text": "Modus (Modalwert)\n\n\nhäufigster Wert einer Stichprobe\nStrenge Definition nur gültig für diskrete (binäre, nominale, ordinale) Skalen\nErweiterung auf kontinuierliche Skalen: Klassenbildung oder Dichteschätzung\n\nErste Näherung: Mitte der häufigsten Klasse.",
    "crumbs": [
      "Statistische Grundlagen",
      "03-Statistische Parameter"
    ]
  },
  {
    "objectID": "slides/03-statparams.html#modus-gewichtungsformel",
    "href": "slides/03-statparams.html#modus-gewichtungsformel",
    "title": "03-Statistische Parameter",
    "section": "Modus: Gewichtungsformel",
    "text": "Modus: Gewichtungsformel\n\n\\[\\begin{align}\n   D &= x_{lo}+\\frac{f_k-f_{k-1}}{2f_k-f_{k-1}-f_{k+1}}\\cdot w \\\\\n   D &= 18 + \\frac{29 - 15}{2 \\cdot 29 - 15 - 26} \\cdot 2 = 19.65\n\\end{align}\\]\n\\(f\\): Klassenhäufigkeit, \\(w\\): Klassenbreite\n\\(k\\): der Index der häufigsten Klasse, \\(x_{lo}\\) ihre Untergrenze.",
    "crumbs": [
      "Statistische Grundlagen",
      "03-Statistische Parameter"
    ]
  },
  {
    "objectID": "slides/03-statparams.html#modus-dichteschätzung",
    "href": "slides/03-statparams.html#modus-dichteschätzung",
    "title": "03-Statistische Parameter",
    "section": "Modus: Dichteschätzung",
    "text": "Modus: Dichteschätzung\n\nEtwas rechenintensiver, wobei der Modus das Maximum einer Kernel-Dichte-Schätzung ist.\nDer Modus aus der Dichteschätzung ist dann \\(D=19.42\\).",
    "crumbs": [
      "Statistische Grundlagen",
      "03-Statistische Parameter"
    ]
  },
  {
    "objectID": "slides/03-statparams.html#multimodale-verteilung",
    "href": "slides/03-statparams.html#multimodale-verteilung",
    "title": "03-Statistische Parameter",
    "section": "Multimodale Verteilung",
    "text": "Multimodale Verteilung\n\nBeispiel: Fischpopulation mit mehreren Altersklassen (Kohorten)",
    "crumbs": [
      "Statistische Grundlagen",
      "03-Statistische Parameter"
    ]
  },
  {
    "objectID": "slides/03-statparams.html#maßzahlen-der-streuung",
    "href": "slides/03-statparams.html#maßzahlen-der-streuung",
    "title": "03-Statistische Parameter",
    "section": "Maßzahlen der Streuung",
    "text": "Maßzahlen der Streuung\nVarianz\n\\[\n  s^2_x = \\frac{SQ}{df}=\\frac{\\sum_{i=1}^n (x_i-\\bar{x})^2}{n-1}\n\\]\n\n\\(SQ\\): Summe der quadrierten Differenzen vom Mittelwert \\(\\bar{x}\\)\n\\(df = n-1\\): Freiheitsgrade, \\(n\\): Stichprobenumfang\n\nStandardabweichung\n\\[s=\\sqrt{s^2}\\] \\(\\rightarrow\\) dieselbe Einheit wie der Mittelwert \\(\\bar{x}\\), so dass sie direkt verglichen werden können.\n\n\nIn der Praxis wird \\(s^2\\) oft mit folgender Formel berechnet:\n\\[\n  s^2_x = \\frac{\\sum{(x_i)^2}-(\\sum{x_i})^2/n}{n-1}\n\\]",
    "crumbs": [
      "Statistische Grundlagen",
      "03-Statistische Parameter"
    ]
  },
  {
    "objectID": "slides/03-statparams.html#variationskoeffizient-cv",
    "href": "slides/03-statparams.html#variationskoeffizient-cv",
    "title": "03-Statistische Parameter",
    "section": "Variationskoeffizient (\\(cv\\))",
    "text": "Variationskoeffizient (\\(cv\\))\nIst die relative Standardabweichung:\n\n\\[\n  cv=\\frac{s}{\\bar{x}}\n\\]\n\n\nVergleich der Streuung verschiedener Variablen, unabhängig von ihrer Maßeinheit\nNur für Daten mit Verhältnisskala, d.h. mit einem absoluten Nullpunkt (wie Meter)\nnicht für Variablen wie Celsius-Temperatur oder pH-Wert.\n\nBeispiel\nNehmen wir an, wir haben den Abfluss von zwei Flüssen, einer mit \\(cv=0.3\\), der andere mit \\(cv=0.8\\). Wir sehen, dass der 2. eine extremere Schwankung aufweist.",
    "crumbs": [
      "Statistische Grundlagen",
      "03-Statistische Parameter"
    ]
  },
  {
    "objectID": "slides/03-statparams.html#spannweite",
    "href": "slides/03-statparams.html#spannweite",
    "title": "03-Statistische Parameter",
    "section": "Spannweite",
    "text": "Spannweite\n\nDie Spannweite misst die Differenz zwischen Maximum und Minimum einer Stichprobe:\n\n\\[\n  r_x = x_{max}-x_{min}\n\\]\n\n\nNachteil: sehr empfindlich gegenüber Ausreißern.",
    "crumbs": [
      "Statistische Grundlagen",
      "03-Statistische Parameter"
    ]
  },
  {
    "objectID": "slides/03-statparams.html#interquartilsabstand",
    "href": "slides/03-statparams.html#interquartilsabstand",
    "title": "03-Statistische Parameter",
    "section": "Interquartilsabstand",
    "text": "Interquartilsabstand\n\n\nIQR oder \\(I_{50}\\) lässt die kleinsten und größten 25% aus.\nStichprobengröße von mindestens 12 Werten empfohlen\n\n\\[\n  I_{50}=Q_3-Q_1=P_{75}-P_{25}\n\\]\nGeordnete Stichprobe\n\n\\(Q_1\\), \\(Q_3\\): 1. und 3. Quartil\n\\(P_{25}, P_{75}\\): 25. und 75. Perzentil\ntypischerweise in Boxplots verwendet\n\n\n\n\n\n\n\n\n\n\n\n\n\nFür normalverteilte Stichproben, feste Beziehung zwischen \\(I_{50}\\) und \\(s\\):\n\\[\n  \\sigma = E(I_{50}/(2\\Phi^{-1}(3/4))) \\approx E(I_{50}/1.394) % 2*qnorm(3/4))\n\\]\nwobei \\(\\Phi^{-1}\\) die Quantilfunktion der Normalverteilung ist.",
    "crumbs": [
      "Statistische Grundlagen",
      "03-Statistische Parameter"
    ]
  },
  {
    "objectID": "slides/03-statparams.html#median-absolute-abweichung",
    "href": "slides/03-statparams.html#median-absolute-abweichung",
    "title": "03-Statistische Parameter",
    "section": "Median absolute Abweichung",
    "text": "Median absolute Abweichung\n\nDer Median der absoluten Differenzen zwischen dem Median und den Einzelwerten.\n\\[\n  MAD = \\text{median}(|\\tilde{x} - x_i|) \\quad\\text{wobei}\\quad \\tilde{x} = \\text{median}(x)\n\\]\n\nsehr robuster Schätzer\nin einigen Communities häufig verwendet, in unserem Bereich noch selten\nOft als praktisches Skalenmaß mit dem Hodges-Lehmann (HL)-Schätzer.\n\nAchtung: Skalierung\n\nDer “echte” MAD ist unskaliert (Konstante \\(1\\)).\nViele Programme (z.B. R) verwenden eine Skalierung mit dem Faktor \\(1.4826\\).\nDieser korrigierte Wert (cMAD) ist konsistent zur Standardabweichung \\(\\sigma\\) bei normalverteilten Daten.\n\n\\(\\longrightarrow\\) Sei vorsichtig und prüfe die Software-Dokumentation!\n\nUnskalierter MAD in R: mad(x, constant = 1)",
    "crumbs": [
      "Statistische Grundlagen",
      "03-Statistische Parameter"
    ]
  },
  {
    "objectID": "slides/03-statparams.html#anwendung-in-r",
    "href": "slides/03-statparams.html#anwendung-in-r",
    "title": "03-Statistische Parameter",
    "section": "Anwendung in R",
    "text": "Anwendung in R\n\nDie Maßzahlen der Streuung können wie folgt berechnet werden:\n\n\n x &lt;- rnorm(100, mean=50, sd=10)  # 100 Zufallszahlen\n\n var(x)                           # Varianz\n sd(x)                            # Standardabweichung\n range(x)                         # Spannweite\n quantile(x, c(0.25, 0.75))       # Quartile\n IQR(x)                           # Interquartilbereich\n diff(quantile(x, c(0.25, 0.75))) # ebenso, aus den Quartilen geschätzt\n mad(x)                           # Median absolute Abweichung, skaliert (cMAD)\n mad(x, constant = 1)             # MAD, unskaliert",
    "crumbs": [
      "Statistische Grundlagen",
      "03-Statistische Parameter"
    ]
  },
  {
    "objectID": "slides/03-statparams.html#standardfehler-des-mittelwerts",
    "href": "slides/03-statparams.html#standardfehler-des-mittelwerts",
    "title": "03-Statistische Parameter",
    "section": "Standardfehler des Mittelwerts",
    "text": "Standardfehler des Mittelwerts\n\n\\[\n  s_{\\bar{x}}=\\frac{s}{\\sqrt{n}}\n\\]\n\n\nmisst die Genauigkeit des Mittelwerts\nspielt eine zentrale Rolle bei der Schätzung von Konfidenzintervallen und statistischen Tests\n\nFaustregel für einen Stichprobenumfang von etwa \\(n &gt; 30\\):\n\n„Zwei-Sigma-Regel“: der wahre Mittelwert liegt mit 95% im Bereich von \\(\\bar{x} \\pm 2 s_\\bar{x}\\)",
    "crumbs": [
      "Statistische Grundlagen",
      "03-Statistische Parameter"
    ]
  },
  {
    "objectID": "slides/01-introduction.html#ziele-des-kurses",
    "href": "slides/01-introduction.html#ziele-des-kurses",
    "title": "01-Einführung",
    "section": "Ziele des Kurses",
    "text": "Ziele des Kurses\n\n\nEinführung in die „Datenwissenschaft“\nStatistische Konzepte und ausgewählte Methoden\n\nStatistische Parameter\nVerteilungen und Wahrscheinlichkeiten\nStatistische Tests\nAuswahl von Modellen\n\nPraktische Erfahrungen\n\nDaten-Strukturen\nGrundlagen der Sprache R\nAnwendungen mit realen und simulierten Datensätzen\n\n\n\\(\\Rightarrow\\) Praktisches Verständnis und „statistisches Gefühl“,\n\\(\\rightarrow\\) Wichtiger als auswendig gelernte Fakten.",
    "crumbs": [
      "Statistische Grundlagen",
      "01-Einführung"
    ]
  },
  {
    "objectID": "slides/01-introduction.html#themen",
    "href": "slides/01-introduction.html#themen",
    "title": "01-Einführung",
    "section": "Themen",
    "text": "Themen\n\n\nGrundlegende Konzepte der Statistik\nEine Einführung in R\nStatistische Parameter und Verteilungen\nAusgewählte Klassische Tests\nLineare Modelle\nVarianzanalyse\nNichtlineare Regression\ngrundlagen der Zeitreihenanalyse (optional)\nMultivariate Statistik",
    "crumbs": [
      "Statistische Grundlagen",
      "01-Einführung"
    ]
  },
  {
    "objectID": "slides/01-introduction.html#material",
    "href": "slides/01-introduction.html#material",
    "title": "01-Einführung",
    "section": "Material",
    "text": "Material\n\n\nFolien, Tutorien: tpetzoldt.github.io/elements-de\nÜbungen: tpetzoldt.github.io/element-labs\nDaten: tpetzoldt.github.io/datasets\n\n\n\\(\\rightarrow\\) Folien und Übungen werden regelmäßig aktualisiert, je nach Fortschritt des Kurses. Kommentare sind willkommen.\n\nPrüfung\n\nVorlesungsbegleitende Präsentationen zu den Übungen\n\nSchriftliche Klausur am Ende des Semesters\n\n\n\nFragen?",
    "crumbs": [
      "Statistische Grundlagen",
      "01-Einführung"
    ]
  },
  {
    "objectID": "slides/01-introduction.html#ein-einführendes-beispiel",
    "href": "slides/01-introduction.html#ein-einführendes-beispiel",
    "title": "01-Einführung",
    "section": "Ein einführendes Beispiel",
    "text": "Ein einführendes Beispiel\nTäglicher mittlerer Abfluss der Elbe, Pegel Dresden, Flusskilometer 55,6\ndate,       discharge\n1806-01-01,  472\n1806-01-02, 1050\n1806-01-03, 1310\n1806-01-04, 1020\n1806-01-05,  767\n1806-01-06,  616\n...\n2020-10-11,  216\n2020-10-12,  204\n2020-10-13,  217\n2020-10-14,  288\n2020-10-15,  440\n2020-10-16,  601\n2020-10-17,  570\n2020-10-18,  516\n2020-10-19,  450\n2020-10-20,  422\n2020-10-21,  396\n2020-10-22,  372\n2020-10-23,  356\n2020-10-24,  357\n2020-10-25,  332\n2020-10-26,  303\n2020-10-27,  302\n2020-10-28,  316\n2020-10-29,  321\n2020-10-30,  331\n2020-10-31,  353\n2020-11-01,  395\n\\(&gt;\\) 70.000 Messungen. Wie können wir das analysieren und was bedeutet das?\nDatenquelle: Bundesanstalt für Gewässerkunde",
    "crumbs": [
      "Statistische Grundlagen",
      "01-Einführung"
    ]
  },
  {
    "objectID": "slides/01-introduction.html#grafik-über-20-jahre",
    "href": "slides/01-introduction.html#grafik-über-20-jahre",
    "title": "01-Einführung",
    "section": "Grafik über 20 Jahre",
    "text": "Grafik über 20 Jahre\n\nAbfluss der Elbe, Pegel Dresden, Datenquelle BfG",
    "crumbs": [
      "Statistische Grundlagen",
      "01-Einführung"
    ]
  },
  {
    "objectID": "slides/01-introduction.html#was-sagen-uns-diese-daten",
    "href": "slides/01-introduction.html#was-sagen-uns-diese-daten",
    "title": "01-Einführung",
    "section": "Was sagen uns diese Daten?",
    "text": "Was sagen uns diese Daten?\n\n\nWie hoch ist der mittlere Abfluss? → Mittelwerte\nWie groß ist die Variation in den Daten? → Varianz\nWie wahrscheinlich sind Dürren oder Überschwemmungen? → Verteilung\nWie präzise sind unsere Vorhersagen? → Konfidenzintervalle\nWelche Faktoren beeinflussen den Abfluss? → Korrelationen",
    "crumbs": [
      "Statistische Grundlagen",
      "01-Einführung"
    ]
  },
  {
    "objectID": "slides/01-introduction.html#wie-soll-man-anfangen",
    "href": "slides/01-introduction.html#wie-soll-man-anfangen",
    "title": "01-Einführung",
    "section": "Wie soll man anfangen?",
    "text": "Wie soll man anfangen?\n\n\nMittelwert: 224\nMedian: 224\nStandardabweichung: 253\nSpannweite: 2, 4500\n\nWelche dieser Parameter sind am besten geeignet?",
    "crumbs": [
      "Statistische Grundlagen",
      "01-Einführung"
    ]
  },
  {
    "objectID": "slides/01-introduction.html#grafiken",
    "href": "slides/01-introduction.html#grafiken",
    "title": "01-Einführung",
    "section": "Grafiken",
    "text": "Grafiken",
    "crumbs": [
      "Statistische Grundlagen",
      "01-Einführung"
    ]
  },
  {
    "objectID": "slides/01-introduction.html#boxplots",
    "href": "slides/01-introduction.html#boxplots",
    "title": "01-Einführung",
    "section": "Boxplots",
    "text": "Boxplots\n\n\nBeachte die logarithmische Skala von y!\nIn der rechten Version reichen die Whisker bis zum einem Datenpunkt, der nicht weiter als das 1,5-fache des Interquartilabstandes der Box entfernt ist.",
    "crumbs": [
      "Statistische Grundlagen",
      "01-Einführung"
    ]
  },
  {
    "objectID": "slides/01-introduction.html#drei-wege-mit-der-statistik-zu-arbeiten",
    "href": "slides/01-introduction.html#drei-wege-mit-der-statistik-zu-arbeiten",
    "title": "01-Einführung",
    "section": "Drei Wege mit der Statistik zu arbeiten",
    "text": "Drei Wege mit der Statistik zu arbeiten\n\nDeskriptive Statistiken und Grafiken\n\nDiagramme, wie in den Beispielen\nMittelwerte, Standardabweichungen, …\nRohdaten interpretieren\n\nHypothesentests\n\nUnterscheidung zwischen Effekten und zufälligen Schwankungen\nErgebnisse überzeugender machen\n\nStatistische Modellierung\n\nMessung der Größe von Effekten (z. B. Klimatrends)\nModelle erstellen, die Abhängigkeiten zusammenfassen\nMaschinelles Lernen",
    "crumbs": [
      "Statistische Grundlagen",
      "01-Einführung"
    ]
  },
  {
    "objectID": "slides/01-introduction.html#statistische-hypothesentests",
    "href": "slides/01-introduction.html#statistische-hypothesentests",
    "title": "01-Einführung",
    "section": "Statistische Hypothesentests",
    "text": "Statistische Hypothesentests\n\nWie wahrscheinlich ist es, dass unsere Hypothese untersützt wird?\n\n\nUmwandlung einer wissenschaftlichen in eine statistische Hypothese\nSchätzung der Irrtumswahrscheinlichkeit (p-Wert) einer Hypothese\n\nBeispiele\n\nIst eine medizinische Behandlung erfolgreich oder nicht? → \\(\\chi^2\\)-Test\nErhöht eine spezielle Nahrung den Ertrag einer Fischzucht? → t-Test\nWelche Faktoren (z. B. Futter, Temperatur, pH-Wert) einer kombinierten Behandlung beeinflussen das Wachstum von Wasserorganismen? → ANOVA\n(Wie) hängt die beobachtete Algenbiomasse vom Phosphor ab? → Korrelation und Regression",
    "crumbs": [
      "Statistische Grundlagen",
      "01-Einführung"
    ]
  },
  {
    "objectID": "slides/01-introduction.html#statistische-modellierung",
    "href": "slides/01-introduction.html#statistische-modellierung",
    "title": "01-Einführung",
    "section": "Statistische Modellierung",
    "text": "Statistische Modellierung\n\nAnpassung eines statistischen Modells an beobachtete Daten\n\nWahl einer geeigneten Modellierungsstrategie\nSpezifizierung statistischer Modelle\nMessung der Effektgrößen\nAuswahl eines optimalen Modells aus verschiedenen Modellkandidaten\n\nBeispiele\n\nAnpassung einer Verteilung an jährliche Abflussdaten, um das 100-jährige Hochwasser zu schätzen.\nAnpassen eines ANOVA-Modells an experimentelle Daten → welcher Faktor beeinflusst das Ergebnis am stärksten?\nAnpassen eines multiplen linearen Modells an Klimadaten → wie stark unterscheiden sich Klimatrends zwischen geografischen Standorten?",
    "crumbs": [
      "Statistische Grundlagen",
      "01-Einführung"
    ]
  },
  {
    "objectID": "slides/01-introduction.html#beispiel-vergleich-zweier-mittelwerte",
    "href": "slides/01-introduction.html#beispiel-vergleich-zweier-mittelwerte",
    "title": "01-Einführung",
    "section": "Beispiel: Vergleich zweier Mittelwerte",
    "text": "Beispiel: Vergleich zweier Mittelwerte\n\n\nEin gegebener Datensatz (Dobson, 1983) enthält das Geburtsgewicht (in g) von 12 Jungen und 12 Mädchen.\nHat der Unterschied etwas mit dem Geschlecht der Babys zu tun oder handelt es sich um Zufall?",
    "crumbs": [
      "Statistische Grundlagen",
      "01-Einführung"
    ]
  },
  {
    "objectID": "slides/01-introduction.html#beispiel-korrelation-und-regression",
    "href": "slides/01-introduction.html#beispiel-korrelation-und-regression",
    "title": "01-Einführung",
    "section": "Beispiel: Korrelation und Regression",
    "text": "Beispiel: Korrelation und Regression\n\n\n\n\n\n\n\n\n\n\n\nAbhängigkeit der Chlorophyllkonzentration in Seen vom Phosphor\n\nlinks ein regionaler Datensatz (Koschel und Scheffler 1985)\nrechts ein internationaler Datensatz (Vollenweider und Kerekes 1980).\n\nWelche der Abbildungen hat eine größere Aussagekraft? Warum?\n\n\n\nDer Parameter \\(r\\) ist der Korrelationskoeffizient nach Pearson.",
    "crumbs": [
      "Statistische Grundlagen",
      "01-Einführung"
    ]
  },
  {
    "objectID": "slides/01-introduction.html#welche-datenstruktur-ist-besser",
    "href": "slides/01-introduction.html#welche-datenstruktur-ist-besser",
    "title": "01-Einführung",
    "section": "Welche Datenstruktur ist besser?",
    "text": "Welche Datenstruktur ist besser?\n\n\nWide-Format\n\n\n\n\n\n\nstation\n2021\n2022\n2023\n\n\n\n\nA\n10\n13\n18\n\n\nB\n8\n1\n17\n\n\nC\n13\n14\n9\n\n\nD\n2\n5\n19\n\n\nE\n17\n2\n10\n\n\n\n\n\n\nLong-Format\n\n\n\n\n\n\nyear\nstation\nvalue\n\n\n\n\n2021\nA\n10\n\n\n2021\nB\n8\n\n\n2021\nC\n13\n\n\n2021\nD\n2\n\n\n2021\nE\n17\n\n\n2022\nA\n13\n\n\n2022\nB\n1\n\n\n2022\nC\n14\n\n\n2022\nD\n5\n\n\n2022\nE\n2\n\n\n2023\nA\n18\n\n\n2023\nB\n17\n\n\n2023\nC\n9\n\n\n2023\nD\n19\n\n\n2023\nE\n10",
    "crumbs": [
      "Statistische Grundlagen",
      "01-Einführung"
    ]
  },
  {
    "objectID": "slides/01-introduction.html#beispiel-ein-experiment-zum-algenwachstum",
    "href": "slides/01-introduction.html#beispiel-ein-experiment-zum-algenwachstum",
    "title": "01-Einführung",
    "section": "Beispiel: Ein Experiment zum Algenwachstum",
    "text": "Beispiel: Ein Experiment zum Algenwachstum\n\nWide-Format\n\n\n\n\nTable 1: Vermehrung einer Algenpopulation innerhalb von 4 Tagen (relative Einheiten)\n\n\n\n\n\n\ntreat\nreplicate 1\nreplicate 2\nreplicate 3\n\n\n\n\nFertilizer\n0.020\n-0.217\n-0.273\n\n\nF. open\n0.940\n0.780\n0.555\n\n\nF.+sugar\n0.188\n-0.100\n0.020\n\n\nF.+CaCO3\n0.245\n0.236\n0.456\n\n\nBas.med.\n0.699\n0.727\n0.656\n\n\nA.dest\n-0.010\n0.000\n-0.010\n\n\nTap water\n0.030\n-0.070\nNA\n\n\n\n\n\n\n\n\n\n\n\nNA bedeutet „nicht verfügbar“ (not available), d.h. ein fehlender Wert",
    "crumbs": [
      "Statistische Grundlagen",
      "01-Einführung"
    ]
  },
  {
    "objectID": "slides/01-introduction.html#daten-im-long-format",
    "href": "slides/01-introduction.html#daten-im-long-format",
    "title": "01-Einführung",
    "section": "Daten im Long-Format",
    "text": "Daten im Long-Format\n\n\nVorteile\n\nsieht „dumm“ aus, ist aber besser für die Datenanalyse\nabhängige Variable growth und Erklärungsvariable treat deutlich sichtbar\nModellformel: growth ~ treat\nleicht erweiterbar auf \\(&gt;1\\) Erklärungsvariable\n\n\n\n\n\n\n\ntreat\nrep\ngrowth\n\n\n\n\nFertilizer\n1\n0.020\n\n\nFertilizer\n2\n-0.217\n\n\nFertilizer\n3\n-0.273\n\n\nF. open\n1\n0.940\n\n\nF. open\n2\n0.780\n\n\nF. open\n3\n0.555\n\n\nF.+sugar\n1\n0.188\n\n\nF.+sugar\n2\n-0.100\n\n\nF.+sugar\n3\n0.020\n\n\nF.+CaCO3\n1\n0.245\n\n\nF.+CaCO3\n2\n0.236\n\n\nF.+CaCO3\n3\n0.456",
    "crumbs": [
      "Statistische Grundlagen",
      "01-Einführung"
    ]
  },
  {
    "objectID": "slides/01-introduction.html#warum-das-long-format",
    "href": "slides/01-introduction.html#warum-das-long-format",
    "title": "01-Einführung",
    "section": "Warum das Long-Format?",
    "text": "Warum das Long-Format?\n\n\nKlar und konsistent:\n\nvermeidet Duplikate\nDatenstruktur einfacher zu verstehen\n\nFlexibel:\n\nfür verschiedene statistische Analysen, z.B. ANOVA, multiple Regression, Zeitreihen\nbei Bedarf leicht in breite Formate zu transformieren\n\nKompatibel:\n\nmoderne Datenanalysetools wie R und Python bevorzugen das long-Format\nkompatibel mit Datenbanksystemen\n\n\nDeshalb:\n\nVersuche das wide-Format zu vermeiden! Es führt zu Inkonsistenz und Verkomplizierung der Analyse.\nBereinige die Daten vor der Analyse und konvertiere Tabellen aus dem wide-Format in das long-Format.\n\n\n\\(\\rightarrow\\) Übung mit Zeitreihen der Elbe.",
    "crumbs": [
      "Statistische Grundlagen",
      "01-Einführung"
    ]
  },
  {
    "objectID": "slides/01-introduction.html#mathematik",
    "href": "slides/01-introduction.html#mathematik",
    "title": "01-Einführung",
    "section": "Mathematik",
    "text": "Mathematik\n\n\nLineare Algebra: Die Grundlage für viele statistische Methoden, insbesondere Matrizen und Vektoren.\nCalculus: Optimierungsprobleme, Ableitung statistischer Formeln, Verständnis des Verhaltens von Funktionen.\nNumerische Analysis: Implementierung von statistischen Methoden auf Computern, insbesondere bei großen oder komplexen Datensätzen.\nWahrscheinlichkeitstheorie: Stichprobenziehung und Modellierung von Daten, Verständnis statistischer Schlussfolgerungen, Entwicklung von Algorithmen.\nStatistische Modellierung: Regressionsanalyse, Zeitreihenanalyse, bayesianische Modellierung, maschinelles Lernen.\n\n\n\\(\\rightarrow\\) Die richtige Verwendung fertiger Software erfordert grundlegendes Verständnis.",
    "crumbs": [
      "Statistische Grundlagen",
      "01-Einführung"
    ]
  },
  {
    "objectID": "slides/01-introduction.html#datenverarbeitung",
    "href": "slides/01-introduction.html#datenverarbeitung",
    "title": "01-Einführung",
    "section": "Datenverarbeitung",
    "text": "Datenverarbeitung\nBenötigte Software\n\nEin Tabellenkalkulationsprogramm, Excel oder LibreOffice https://www.libreoffice.org/\nDas R-System für Datenanalyse und Grafiken https://www.r-project.org\nRStudio zum benutzerfreundlichen Arbeiten mit R https://posit.co/download/rstudio-desktop/",
    "crumbs": [
      "Statistische Grundlagen",
      "01-Einführung"
    ]
  },
  {
    "objectID": "slides/01-introduction.html#warum-r",
    "href": "slides/01-introduction.html#warum-r",
    "title": "01-Einführung",
    "section": "Warum R?",
    "text": "Warum R?\n\n\n“lingua franca of computational statistics”.\n\nÄußerst leistungsfähig\nKein anderes System verfügt über so viele statistische Methoden\nWird in der statistischen Forschung verwendet\n\nFrei (OpenSource)\n\nFrei zu benutzen\nFrei zu modifizieren\nFrei, etwas beizutragen\n\nWeniger kompliziert als man denkt:\n\nJa, man braucht Kommandozeilenprogrammierung\naber: schon eine einzige Zeile kann viel bewirken\ngroße Anzahl Bücher und Online-Skripte\n\n\n\n\nIm Gegensatz zu anderen Systemen ist Copy & Paste erlaubt – aber bitte zitieren.",
    "crumbs": [
      "Statistische Grundlagen",
      "01-Einführung"
    ]
  },
  {
    "objectID": "slides/01-introduction.html#bücher",
    "href": "slides/01-introduction.html#bücher",
    "title": "01-Einführung",
    "section": "Bücher",
    "text": "Bücher\nStatistische Methoden\n\nSehr gut lesbare Einführungen\n\nDalgaard, P., 2008: Introductory Statistics with R. Springer, New York, 2nd edition. (Volltext der 1. Auflage frei verfügbar)\nVerzani, J. (2019). Using R for introductory statistics. CRC press.\n\nSehr gut verständlich, insbesondere für Regressions- und Zeitreihenanalyse:\n\nKleiber, C. and Zeileis, A., 2008: Applied Econometrics with R, Springer Verlag, New York. https://link.springer.com/book/10.1007/978-0-387-77318-6\n\n\nR Programmierung\n\nEinführung in die Datenwissenschaft mit dem modernen „Tidyverse“-Ansatz:\n\nWickham, H., Çetinkaya-Rundel, M and Grolemund, G, 2023: R for Data Science. Free ebook: https://r4ds.hadley.nz/\n\n\n\n\n\n\nUnd jede Menge frei verfügbares Material im Internet …",
    "crumbs": [
      "Statistische Grundlagen",
      "01-Einführung"
    ]
  },
  {
    "objectID": "slides/02-terminology.html#grundlagen-und-terminologie",
    "href": "slides/02-terminology.html#grundlagen-und-terminologie",
    "title": "02-Grundbegriffe",
    "section": "Grundlagen und Terminologie",
    "text": "Grundlagen und Terminologie\n\n\nZiele von statistischen Analysen\nDeskriptive und experimentelle Forschung\nDas Sparsamkeitsprinzip\nSkalen von Variablen\nWahrscheinlichkeit\nStichprobe und Grundgesamtheit\nZufällige und systematische Fehler\nParameter der Grundgesamtheit und der Stichprobe",
    "crumbs": [
      "Statistische Grundlagen",
      "02-Grundbegriffe"
    ]
  },
  {
    "objectID": "slides/02-terminology.html#ziele-von-statistischen-analysen",
    "href": "slides/02-terminology.html#ziele-von-statistischen-analysen",
    "title": "02-Grundbegriffe",
    "section": "Ziele von statistischen Analysen",
    "text": "Ziele von statistischen Analysen\n\nDaten zusammenfassen, komprimieren und beschreiben (deskriptive Statistik)\n\nEffizientes Arbeiten mit großen Datensätzen\nStatistische Parameter, Mittelwerte, Streuung, Korrelation abschätzen\n\nErstellen von Hypothesen aus Daten (explorative Statistik)\n\nData Mining und explorative Statistik\nGrafische Methoden, multivariate Statistik\n\nHypothesen testen (statistische Inferenz)\n\nklassische Tests, ANOVA, Korrelation, . . .\nModellauswahl\n\nForschung planen (Versuchsplanung)\n\nEffektstärke im Vergleich zum Zufallsfehler\nVersuchsaufbau und erforderliche Stichprobengröße\n\nStatistische Modellierung\n\nEffektstärke messen, beste Erklärung für ein Problem finden\nMustererkennung, Vorhersage, maschinelles Lernen",
    "crumbs": [
      "Statistische Grundlagen",
      "02-Grundbegriffe"
    ]
  },
  {
    "objectID": "slides/02-terminology.html#deskriptive-oder-experimentelle-forschung",
    "href": "slides/02-terminology.html#deskriptive-oder-experimentelle-forschung",
    "title": "02-Grundbegriffe",
    "section": "Deskriptive oder experimentelle Forschung",
    "text": "Deskriptive oder experimentelle Forschung\nDeskriptive Forschung\n\nAufdecken von Unterschieden und von Wechselbeziehungen in Datensätzen.\n\nBeobachtung, Überwachung, Korrelationen\ndas Forschungsthema wird nicht manipuliert\n\n\nExperimentelle Forschung\n\nKann ein erwarteter Effekt reproduziert werden?\n\nManipulation von einzelnen Bedingungen\nEliminierung von Störungen (kontrollierte Randbedingungen)\nmöglichst einfacher Versuchsaufbau\n\n\nStarke Inferenz erfordert eine klare Hypothese und experimentelle Forschung.\nSchwache Inferenz aus Beobachtungen und Daten abgeleitet.\n\\(\\rightarrow\\) deskriptive Forschung liefert die Daten für die Hypothesenbildung.",
    "crumbs": [
      "Statistische Grundlagen",
      "02-Grundbegriffe"
    ]
  },
  {
    "objectID": "slides/02-terminology.html#das-sparsamkeitsprinzip-parsimonieprinzip",
    "href": "slides/02-terminology.html#das-sparsamkeitsprinzip-parsimonieprinzip",
    "title": "02-Grundbegriffe",
    "section": "Das Sparsamkeitsprinzip (Parsimonieprinzip)",
    "text": "Das Sparsamkeitsprinzip (Parsimonieprinzip)\nWird einem englischen Philosophen aus dem 14. Jahrhundert zugeschrieben („Ockhams Rasiermesser“)\n\nWenn man zwei konkurrierende Theorien hat, die genau die gleichen Vorhersagen machen, ist die einfachere die bessere.\n\nIm Zusammenhang mit der statistischen Analyse und Modellierung:\n\nModelle sollten so wenig Parameter wie möglich haben\nlineare Modelle sollten gegenüber nichtlinearen Modellen bevorzugt werden\nExperimente sollten auf nur wenigen Annahmen beruhen\nModelle sollten vereinfacht werden, bis sie minimal angemessen sind\neinfache Erklärungen sind komplexen Erklärungen vorzuziehen\n\nEiner der wichtigsten wissenschaftlichen Grundsätze\n\\(\\rightarrow\\) Aber die Natur ist komplex, eine zu starke Vereinfachung muss vermieden werden.\n\nmuss kritisch reflektiert und diskutiert werden",
    "crumbs": [
      "Statistische Grundlagen",
      "02-Grundbegriffe"
    ]
  },
  {
    "objectID": "slides/02-terminology.html#variablen-und-parameter",
    "href": "slides/02-terminology.html#variablen-und-parameter",
    "title": "02-Grundbegriffe",
    "section": "Variablen und Parameter",
    "text": "Variablen und Parameter\n\n\ny = a + b \\(\\cdot\\) x\n\n\n\nVariablen: alles, was gemessen oder experimentell manipuliert wird, z. B. die Phosphorkonzentration in einem See, die Lufttemperatur oder die Abundanz von Tieren\nParameter: Werte, die durch ein statistisches Modell geschätzt werden, z. B. Mittelwert, Standardabweichung, Steigung eines linearen Modells.\n\nUnabhängige Variablen Erklärungsvariablen, Prädiktoren)\n\nwerden absichtlich eingestellt oder als Ergebnis nicht kontrollierbarer Faktoren angenommen\n\nAbhängige Variablen (Zielgröße, Zielvariablen, vorhergesagte Variablen)\n\ndie Variablen von Interesse, die wir zu verstehen versuchen.",
    "crumbs": [
      "Statistische Grundlagen",
      "02-Grundbegriffe"
    ]
  },
  {
    "objectID": "slides/02-terminology.html#skalen-von-variablen",
    "href": "slides/02-terminology.html#skalen-von-variablen",
    "title": "02-Grundbegriffe",
    "section": "Skalen von Variablen",
    "text": "Skalen von Variablen\n\n\nBinär (boolesche Variable): genau zwei Zustände: wahr/falsch, 1/0, vorhanden oder nicht vorhanden.\nNominal (benannte Entitäten): ohne Ordnung, {rot, gelb, grün}, Liste von Arten.\nOrdinale Variablen (Ränge, geordnete Faktoren): Werte oder Begriffe mit einer Ordnung {1., 2., 3., …}; {oligotroph, mesotroph, eutroph, polytroph, hypertroph}, aber nicht „dystroph“\nMetrisch: kontinuierlich (idealerweise ohne Stufen). Zwei Untertypen:\n\nIntervallskala: ermöglicht Vergleiche und Differenzen, aber Verhältnisse machen keinen Sinn. (20°C ist 10 Grad wärmer als 10°C, aber nicht das Doppelte)\nVerhältnisskala: Daten mit einem absoluten Nullpunkt, Verhältnisse machen Sinn. Ein Baum mit 2m ist doppelt so hoch wie ein Baum mit 1m.\n\n\nDas Niveau der Variablen steigt von der binären zur Verhältnis-Skala. Es ist immer möglich, ein höheres in ein niedrigeres Niveau umzuwandeln.",
    "crumbs": [
      "Statistische Grundlagen",
      "02-Grundbegriffe"
    ]
  },
  {
    "objectID": "slides/02-terminology.html#umwandlung-von-skalen",
    "href": "slides/02-terminology.html#umwandlung-von-skalen",
    "title": "02-Grundbegriffe",
    "section": "Umwandlung von Skalen",
    "text": "Umwandlung von Skalen\n\nDas Niveau der Variablen steigt von der binären zur Verhältnis-Skala. Es ist immer möglich, ein höheres in ein niedrigeres Niveau umzuwandeln:\n\nmetrisch \\(\\rightarrow\\) ordinal: Rangbildung\nmetrisch oder ordinal \\(\\rightarrow\\) binär: Vergleich mit Schwellenwert\nnominal \\(\\rightarrow\\) binär: Zuordnung zu zwei Gruppen\n\nDie Umwandlung in eine niedrigere Skala führt zu einem gewissen Informationsverlust, ermöglicht aber die Verwendung zusätzlicher Methoden aus der untergeordneten Skala.\nErklärung: Wenn wir die Rangkorrelation auf metrische Daten anwenden, wenden wir im Wesentlichen eine Methode für die Ordinalskala auf metrische Daten an. In diesem Fall verlieren wir Informationen über die Unterschiede zwischen den Werten, verringern aber auch den Einfluss von Extremwerten und Ausreißern.\nDie Umwandlung von metrischen in binäre Daten kann sinnvoll sein, wenn die metrischen Daten nicht genau genug sind. So kann beispielsweise die Zählung von Tieren (z. B. Wölfen) in einem bestimmten Gebiet von zu vielen Faktoren abhängen (Struktur der Landschaft, Erfahrung der Menschen, Jahreszeit usw.), so dass die genauen Zahlen (Häufigkeiten) fraglich sind. In solchen Fällen ist eine Umwandlung in eine binäre Skala (vorhanden/abwesend) und die Anwendung eines entsprechenden Tests (z. B. logistische Regression oder Fisher’s exakter Test) zuverlässiger.",
    "crumbs": [
      "Statistische Grundlagen",
      "02-Grundbegriffe"
    ]
  },
  {
    "objectID": "slides/02-terminology.html#wahrscheinlichkeit",
    "href": "slides/02-terminology.html#wahrscheinlichkeit",
    "title": "02-Grundbegriffe",
    "section": "Wahrscheinlichkeit",
    "text": "Wahrscheinlichkeit\n\nKlassische Definition\n\nDie Wahrscheinlichkeit \\(p\\) ist die Chance eines bestimmten Ereignisses:\n\n\\[\np = \\frac{\\text{Anzahl der ausgewählten Fälle}}{\\text{Anzahl aller möglichen Fälle}}\n\\]\n\n1 oder 6 bei einem Würfel \\(p=2/6\\)\nProblem, wenn der Nenner unendlich wird\n\nAxiomatische Definition\n\nAxiom I: \\(0 \\le p \\le 1\\)\nAxiom II: unmögliche Ereignisse haben \\(p=0\\), sichere Ereignisse haben \\(p=1\\)\nAxiom III: für sich gegenseitig ausschließende Ereignisse \\(A\\) und \\(B\\), d.h. in der Mengenlehre gilt \\(A \\bigcap B = \\emptyset\\): \\(p(A \\bigcup B)= p(A) + p(B)\\)",
    "crumbs": [
      "Statistische Grundlagen",
      "02-Grundbegriffe"
    ]
  },
  {
    "objectID": "slides/02-terminology.html#stichprobe-und-grundgesamtheit",
    "href": "slides/02-terminology.html#stichprobe-und-grundgesamtheit",
    "title": "02-Grundbegriffe",
    "section": "Stichprobe und Grundgesamtheit",
    "text": "Stichprobe und Grundgesamtheit\n\nStichprobe\nObjekte, von denen wir Messungen oder Beobachtungen haben\n\nGrundgesamtheit\nMenge aller Probanden, die die gleiche Chance hatten, Teil der Stichprobe zu werden.\n\\(\\Rightarrow\\) Die Grundgesamtheit wird durch die Art der Strichprobengewinnung definiert\n\\(\\Rightarrow\\) Die Stichproben sollten repräsentativ für unser beabsichtigtes Beobachtungsobjekt sein.",
    "crumbs": [
      "Statistische Grundlagen",
      "02-Grundbegriffe"
    ]
  },
  {
    "objectID": "slides/02-terminology.html#stichproben-strategien",
    "href": "slides/02-terminology.html#stichproben-strategien",
    "title": "02-Grundbegriffe",
    "section": "Stichproben-Strategien",
    "text": "Stichproben-Strategien\n\nZufallsstichprobe\n\nIndividuen werden nach dem Zufallsprinzip aus einer Grundgesamtheit ausgewählt.\nBeispiele:\n\nZufällige Auswahl von Probenahmestellen auf einem Raster.\nZufällige Platzierung von Versuchseinheiten in einem Regal.\n\n\n\nGeschichtete Stichprobe\n\nDie Grundgesamtheit wird in Klassen ähnlicher Objekte (Schichten oder Strata) unterteilt.\nDie Schichten werden getrennt analysiert, danach werden die Informationen gewichtet und kombiniert, um Rückschlüsse auf die Grundgesamtheit zu ziehen.\nDie geschichtete Stichprobe erfordert Informationen über die Größe und Repräsentativität der Schichten.\nBeispiele: Wahlprognosen, Tiefenschichten in einem See, Altersklassen von Tieren.",
    "crumbs": [
      "Statistische Grundlagen",
      "02-Grundbegriffe"
    ]
  },
  {
    "objectID": "slides/02-terminology.html#zufällige-und-systematische-fehler",
    "href": "slides/02-terminology.html#zufällige-und-systematische-fehler",
    "title": "02-Grundbegriffe",
    "section": "Zufällige und systematische Fehler",
    "text": "Zufällige und systematische Fehler\n\nZufallsfehler\n\nkönnen mit statistischen Methoden geschätzt werden\nwerden eliminiert, wenn der Stichprobenumfang groß ist\nbei großen Stichproben gleichen sich große und kleine Fehler aus\n\nSystematische Fehler auch Bias genannt\n\nkönnen in der Regel nicht allein mit statistischen Methoden geschätzt werden\nerfordern Kenntnisse über das betrachtete System\nEliminierung erfordert Kalibrierung mittels Standards, Blindwerten oder Paarbildung",
    "crumbs": [
      "Statistische Grundlagen",
      "02-Grundbegriffe"
    ]
  },
  {
    "objectID": "slides/02-terminology.html#grundgesamtheits--und-stichprobenparameter",
    "href": "slides/02-terminology.html#grundgesamtheits--und-stichprobenparameter",
    "title": "02-Grundbegriffe",
    "section": "Grundgesamtheits- und Stichprobenparameter",
    "text": "Grundgesamtheits- und Stichprobenparameter\n\n„Wahre“ Parameter der Grundgesamtheit\n\nsymbolisiert durch griechische Buchstaben, (\\(\\mu, \\sigma, \\gamma\\, \\alpha, \\beta\\))\nin der Regel unbekannt\nwerden anhand einer Stichprobe geschätzt\n\n„Berechnete“ Parameter aus einer Probe\n\nsymbolisiert mit lateinischen Buchstaben (\\(\\bar{x}\\), \\(s\\), \\(r^2\\), …)\ndie Berechnung erfolgt anhand einer Stichprobe\nStatistiker sagen „Schätzung“ statt „Berechnung“.\nDie geschätzten Parameter können auch wieder als Zufallsvariable behandelt werden",
    "crumbs": [
      "Statistische Grundlagen",
      "02-Grundbegriffe"
    ]
  },
  {
    "objectID": "slides/02-terminology.html#erwartungswert",
    "href": "slides/02-terminology.html#erwartungswert",
    "title": "02-Grundbegriffe",
    "section": "Erwartungswert",
    "text": "Erwartungswert\n\nEine einzelne Messung \\(x_i\\) einer Zufallsvariablen \\(X\\) kann als Summe des Erwartungswertes \\(\\mathbf{E}(X)\\) der Zufallsvariablen und eines Zufallsfehlers \\(\\varepsilon_i\\) formuliert werden.\n\\[\\begin{align}\n  x_i &= \\mathbf{E}(X) + \\varepsilon_i\\\\\n  \\mathbf{E}(\\varepsilon)&=0\n\\end{align}\\]\nBeispiel:\n\nfür einen fairen Würfel mit 6 Augen sollte der wahre Mittelwert \\(\\mu =3.5\\) sein\nIn Wirklichkeit ist nicht genau bekannt, ob ein realer Würfel perfekt symmetrisch ist.\n\nBeispiel: 3 Personen mit 5 Versuchen:\n\n\n\nsample 1:  3 3 2 4 1  mean: 2.6\n\n\nsample 2:  6 1 1 6 1  mean: 3\n\n\nsample 3:  6 5 6 6 5  mean: 5.6\n\n\n\nGesamtmittelwert: \\(\\bar{x} = 3.73\\) liegt nahe an \\(\\mu = 3.5\\).",
    "crumbs": [
      "Statistische Grundlagen",
      "02-Grundbegriffe"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#wahrscheinlichkeitsverteilungen",
    "href": "slides/04-distributions.html#wahrscheinlichkeitsverteilungen",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Wahrscheinlichkeitsverteilungen",
    "text": "Wahrscheinlichkeitsverteilungen\n\nDefinition\n\neine mathematische Funktion\nWahrscheinlichkeit des Auftretens verschiedener möglicher Ergebnisse für ein Experiment\n\n\\(\\rightarrow\\) https://en.wikipedia.org/wiki/Probability_distribution\n\nEigenschaften\n\nEine bestimmte Form (Verteilungstyp, eine mathematische Formel)\nKann durch ihre Parameter beschrieben werden (z. B. Mittelwert \\(\\mu\\) und Standardabweichung \\(\\sigma\\)).\n\nWahrscheinlichkeitsverteilungen sind eines der Kernkonzepte der Statistik und viele Statistikkurse beginnen mit dem Werfen von Münzen1 oder Würfeln. Wir beginnen mit einem kleinen Experiment im Klassenzimmer.\nWir gehen davon aus, dass die Chancen 50:50 sind. Forscher fanden heraus, dass es eine sehr geringe Abweichung gibt, siehe \\(\\rightarrow\\) youtube video",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#was-ist-deine-lieblingszahl",
    "href": "slides/04-distributions.html#was-ist-deine-lieblingszahl",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Was ist deine Lieblingszahl?",
    "text": "Was ist deine Lieblingszahl?\nIn einem Experiment im Hörsaal wurden die Studierenden eines internationalen Kurses nach ihrer Lieblingszahl von 1 bis 9 gefragt.\n\n\n\n\n\nZahl\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nHäufigkeit\n0\n1\n5\n5\n6\n4\n12\n3\n3\n\n\n\n\n\n\nDie resultierende Verteilung ist:\n\nempirisch: Daten aus einem Experiment\ndiskret: nur diskrete Zahlen (1, 2, 3 …, 9) möglich, keine Brüche",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#computersimulationen",
    "href": "slides/04-distributions.html#computersimulationen",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Computersimulationen",
    "text": "Computersimulationen\n\nAnstelle von realen Experimenten können wir auch simulierte Zufallszahlen verwenden.\n\nVorteil: wir können Daten aus Verteilungen mit bekannten Eigenschaften simulieren.\nHerausforderung: etwas abstrakt\n\nZweck\n\nein Gefühl für den Zufall zu bekommen, wie eine Stichprobe nach einer bestimmten „Theorie“ aussehen kann\nstatistische Methoden erforschen und testen und das Verständnis schulen\nein Werkzeug für die Versuchsplanung\nAnwendung und Aussagekraft einer Analyse im Vorfeld testen\n\n\n\\(\\rightarrow\\) Simulation: ein wichtiges Instrument für die Entwicklung und das Verständnis statistischer Methoden!",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#kontinuierliche-gleichverteilung-mathbfu0-1",
    "href": "slides/04-distributions.html#kontinuierliche-gleichverteilung-mathbfu0-1",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Kontinuierliche Gleichverteilung \\(\\mathbf{U}(0, 1)\\)",
    "text": "Kontinuierliche Gleichverteilung \\(\\mathbf{U}(0, 1)\\)\n\n\ngleiche Wahrscheinlichkeit des Auftretens in einem bestimmten Intervall\nz.B. \\([0, 1]\\)\nin R: runif, random, uniform\n\n\nrunif(10)\n\n [1] 0.50776341 0.84530023 0.11758184 0.17743664 0.65554698 0.86826580\n [7] 0.84999413 0.04312942 0.58220316 0.15802466\n\n\n \n\nKlassenbildung (Binning): Einteilung der Werte in Klassen",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#dichtefunktion-von-mathbfux_min-x_max",
    "href": "slides/04-distributions.html#dichtefunktion-von-mathbfux_min-x_max",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Dichtefunktion von \\(\\mathbf{U}(x_{min}, x_{max})\\)",
    "text": "Dichtefunktion von \\(\\mathbf{U}(x_{min}, x_{max})\\)\n\n\nDichte \\(f(X)\\), manchmal abgekürzt als „pdf“ (probability density function):\n\n\\[\nf(x) = \\begin{cases}\n         \\frac{1}{x_{max}-x_{min}} & \\text{für } x \\in [x_{min},x_{max}] \\\\\n         0                     & \\text{sonst}\n       \\end{cases}\n\\]\n\nFläche unter der Kurve (d. h. das Integral) = 1,0\n100% der Ereignisse liegen zwischen \\(-\\infty\\) und \\(+\\infty\\) und für \\(\\mathbf{U}(x_{min}, x_{max})\\) im Intervall \\([x_{min}, y_{max}]\\)",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#kumulative-verteilungsfunktion-von-mathbfux_min-x_max",
    "href": "slides/04-distributions.html#kumulative-verteilungsfunktion-von-mathbfux_min-x_max",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Kumulative Verteilungsfunktion von \\(\\mathbf{U}(x_{min}, x_{max})\\)",
    "text": "Kumulative Verteilungsfunktion von \\(\\mathbf{U}(x_{min}, x_{max})\\)\n\n\nDie cdf (cumulative distribution function) ist das Integral der Dichtefunktion:\n\\[\nF(x) =\\int_{-\\infty}^{x} f(x) dx\n\\] Die Gesamtfläche (Gesamtwahrscheinlichkeit) ist \\(1.0\\):\n\\[\nF(x) =\\int_{-\\infty}^{+\\infty} f(x) dx = 1\n\\]\nFür die Verteilungsfunktion der Gleichverteilung gilt somit:\n\\[\nF(x) = \\begin{cases}\n         0                     & \\text{für } x &lt; x_{min} \\\\\n         \\frac{x-x_{min}}{x_{max}-x_{min}} & \\text{für } x \\in [x_{min},x_{max}] \\\\\n         1                     & \\text{für } x &gt; x_{max}\n       \\end{cases}\n\\]",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#quantilfunktion",
    "href": "slides/04-distributions.html#quantilfunktion",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Quantilfunktion",
    "text": "Quantilfunktion\n\n… die Umkehrung der kumulativen Verteilungsfunktion.\n\n\n\n\n\n\n\n\n\n\nKumulative Verteilungsfunktion\n\n\n\n\n\n\n\n\n\n\nQuantilsfunktion\nBeispiel: In welchem Bereich kann man 95% einer Gleichverteilung \\(\\mathbf{U}(40,60)\\) finden?",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#zusammenfassung-gleichverteilung",
    "href": "slides/04-distributions.html#zusammenfassung-gleichverteilung",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Zusammenfassung: Gleichverteilung",
    "text": "Zusammenfassung: Gleichverteilung",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#die-normalverteilung-mathbfnmu-sigma",
    "href": "slides/04-distributions.html#die-normalverteilung-mathbfnmu-sigma",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Die Normalverteilung \\(\\mathbf{N}(\\mu, \\sigma)\\)",
    "text": "Die Normalverteilung \\(\\mathbf{N}(\\mu, \\sigma)\\)\n\nvon großer theoretischer Bedeutung aufgrund des zentralen Grenzwertsatzes (ZGWS / central limit theorem CLT)\nergibt sich aus der Addition einer großen Anzahl von Zufallswerten gleicher Größenordnung.\n\nDie Dichtefunktion der Normalverteilung ist eine mathematische Schönheit.\n\\[\nf(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\, \\mathrm{e}^{-\\frac{(x-\\mu)^2}{2 \\sigma^2}}\n\\]\n\nC.F. Gauß, Gauß-Kurve und Formel auf einer deutschen DM-Banknote von 1991–2001 (Wikipedia, CC0)",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#der-zentrale-grenzwertsatz-clt",
    "href": "slides/04-distributions.html#der-zentrale-grenzwertsatz-clt",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Der zentrale Grenzwertsatz (CLT)",
    "text": "Der zentrale Grenzwertsatz (CLT)\n\n\nDie Summe einer großen Anzahl \\(n\\) unabhängiger und identisch verteilter Zufallswerte konvergiert gegen eine Normalverteilung, unabhängig vom Typ der ursprünglichen Verteilung.",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#ein-simulationsexperiment",
    "href": "slides/04-distributions.html#ein-simulationsexperiment",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Ein Simulationsexperiment",
    "text": "Ein Simulationsexperiment\n\n\n\nErstelle eine Matrix mit 100 Zeilen und 25 Spalten von gleichverteilten Zufallszahlen\nBerechne die Zeilensummen\n\n\npar(mfrow=c(2, 1), las=1)\nset.seed(42)\nx  &lt;- matrix(runif(25 * 100), ncol = 25)\n\n# View(x) # uncomment this to show the matrix\n\nx_sums &lt;- rowSums(x)\nhist(x)\nhist(x_sums)\n\n\\(\\rightarrow\\) Zeilensummen sind annähernd normalverteilt",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#zufallszahlen-und-dichtefunktion",
    "href": "slides/04-distributions.html#zufallszahlen-und-dichtefunktion",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Zufallszahlen und Dichtefunktion",
    "text": "Zufallszahlen und Dichtefunktion",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#dichte-und-quantile-der-standardnormalverteilung",
    "href": "slides/04-distributions.html#dichte-und-quantile-der-standardnormalverteilung",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Dichte und Quantile der Standardnormalverteilung",
    "text": "Dichte und Quantile der Standardnormalverteilung\n\n\nTheoretisch liegen 50% der Werte unter und 50% über dem Mittelwert\n95% liegen ungefähr zwischen \\(\\pm 2 \\sigma\\)",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#dichte-und-quantile-der-standardnormalverteilung-1",
    "href": "slides/04-distributions.html#dichte-und-quantile-der-standardnormalverteilung-1",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Dichte und Quantile der Standardnormalverteilung",
    "text": "Dichte und Quantile der Standardnormalverteilung",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#kumulative-verteilungsfunktion-und-quantilfunktion",
    "href": "slides/04-distributions.html#kumulative-verteilungsfunktion-und-quantilfunktion",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Kumulative Verteilungsfunktion und Quantilfunktion",
    "text": "Kumulative Verteilungsfunktion und Quantilfunktion\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuantil\n1\n1.64\n1.96\n2.0\n2.33\n2.57\n3\n\\(\\mu \\pm z\\cdot \\sigma\\)\n\n\n\n\neinseitig\n\n0.95\n0.975\n0.977\n0.99\n0.995\n0.9986\n\\(1-\\alpha\\)\n\n\nzweiseitig\n0.68\n0.90\n0.95\n0.955\n0.98\n0.99\n0.997\n\\(1-\\alpha/2\\)",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#standardnormalverteilung-skalierung-und-verschiebung",
    "href": "slides/04-distributions.html#standardnormalverteilung-skalierung-und-verschiebung",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Standardnormalverteilung, Skalierung und Verschiebung",
    "text": "Standardnormalverteilung, Skalierung und Verschiebung\n\n\n\\(\\mu\\) ist der Verschiebungsparameter, der die gesamte glockenförmige Kurve entlang der \\(x\\)-Achse verschiebt.\n\\(\\sigma\\) ist der Skalierungsparameter, der die Kurve in Richtung \\(x\\) streckt oder staucht.",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#standardisierung-z-transformation",
    "href": "slides/04-distributions.html#standardisierung-z-transformation",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Standardisierung (\\(z\\)-Transformation)",
    "text": "Standardisierung (\\(z\\)-Transformation)\n\nJede Normalverteilung kann skaliert und verschoben werden, um eine Standardnormalverteilung mit \\(\\mu=0, \\sigma=1\\) zu bilden.\n\n\nNormalverteilung\n\n\n\n\n\n\n\n\n\n\\[\nf(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\, \\mathrm{e}^{-\\frac{(x-\\mu)^2}{2 \\sigma^2}}\n\\]\n\n \\[\nz = \\frac{x-\\mu}{\\sigma}\n\\] \\(\\longrightarrow\\) \\(\\longrightarrow\\) \\(\\longrightarrow\\)\n\nStandardnormalverteilung\n\n\n\n\n\n\n\n\n\n\\[\nf(x) = \\frac{1}{\\sqrt{2\\pi}} \\, \\mathrm{e}^{-\\frac{1}{2}x^2}\n\\]",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#t-verteilung-mathbftx-df",
    "href": "slides/04-distributions.html#t-verteilung-mathbftx-df",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "t-Verteilung \\(\\mathbf{t}(x, df)\\)",
    "text": "t-Verteilung \\(\\mathbf{t}(x, df)\\)\n\n\nzusätzlicher Parameter „Freiheitsgrade“ (df)\nwird für Konfidenzintervalle und statistische Tests verwendet\nkonvergiert gegen Normalverteilung für \\(df \\rightarrow \\infty\\)",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#abhängigkeit-des-t-wertes-von-der-anzahl-der-df",
    "href": "slides/04-distributions.html#abhängigkeit-des-t-wertes-von-der-anzahl-der-df",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Abhängigkeit des t-Wertes von der Anzahl der df",
    "text": "Abhängigkeit des t-Wertes von der Anzahl der df\n\n\n\n\n\n\ndf\n1.00\n4.00\n9.00\n19.00\n29.00\n99.00\n999.00\n\n\nt\n12.71\n2.78\n2.26\n2.09\n2.05\n1.98\n1.96",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#logarithmische-normalverteilung-lognormal",
    "href": "slides/04-distributions.html#logarithmische-normalverteilung-lognormal",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Logarithmische Normalverteilung (Lognormal)",
    "text": "Logarithmische Normalverteilung (Lognormal)\n\n\nViele Prozesse in der Natur folgen nicht einer Normalverteilung.\nbegrenzt durch Null auf der linken Seite\ngroße Extremwerte auf der rechten Seite\n\nBeispiele: Abfluss von Flüssen, Nährstoffkonzentrationen, Algenbiomasse in einem See",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#elternverteilung-der-lognormalverteilung",
    "href": "slides/04-distributions.html#elternverteilung-der-lognormalverteilung",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Elternverteilung der Lognormalverteilung",
    "text": "Elternverteilung der Lognormalverteilung\n\n\nLogarithmus von Werten einer Lognormalverteilung \\(\\rightarrow\\) Eltern-Normalverteilung.\nDie Lognormalverteilung wird durch die Parameter der log-transformierten Daten \\(\\bar{x}_L\\) und \\(s_L\\) beschrieben\nder Antilog von \\(\\bar{x}_L\\) ist das geometrische Mittel",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#binomialverteilung",
    "href": "slides/04-distributions.html#binomialverteilung",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Binomialverteilung",
    "text": "Binomialverteilung\n\n\nAnzahl der erfolgreichen Versuche aus \\(n\\) Gesamtversuchen mit Erfolgswahrscheinlichkeit \\(p\\).\nWie viele 6en mit Wahrscheinlichkeit \\(1/6\\) in 3 Versuchen?\nMedizin, Toxikologie, Vergleich von Prozentzahlen\nÄhnlich, aber ohne zurücklegen: Hypergeometrische Verteilung im Lotto",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#poisson-verteilung",
    "href": "slides/04-distributions.html#poisson-verteilung",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Poisson-Verteilung",
    "text": "Poisson-Verteilung\n\n\nVerteilung von seltenen Ereignissen, eine diskrete Verteilung\nMittelwert und Varianz sind gleich (\\(\\mu = \\sigma^2\\)), daraus ergibt sich der Parameter „lambda“ (\\(\\lambda\\))\nBeispiele: Bakterienzählung auf einem Raster, Warteschlangen, Ausfallmodelle\n\nQuasi-Poisson, wenn \\(\\mu \\neq \\sigma^2\\)\n\nWenn \\(s^2 &gt; \\bar{x}\\): Überdispersion\nwenn \\(s^2 &lt; \\bar{x}\\): Unterdispersion",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#konfidenzintervall",
    "href": "slides/04-distributions.html#konfidenzintervall",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Konfidenzintervall",
    "text": "Konfidenzintervall\n– hängt nur von \\(\\lambda\\) bzw. der Anzahl der gezählten Einheiten (\\(k\\)) ab\n\nTypischer Fehler bei einer Zellzählung: 95% Konfidenzintervall\n\n\n\n\n\nAnzahl\n2\n3\n5\n10\n50\n100\n200\n400\n1000\n\n\nvon\n0\n1\n2\n5\n37\n81\n173\n362\n939\n\n\nbis\n7\n9\n12\n18\n66\n122\n230\n441\n1064",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#zur-erinnerung-der-zentrale-grenzwertsatz-zgws",
    "href": "slides/04-distributions.html#zur-erinnerung-der-zentrale-grenzwertsatz-zgws",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Zur Erinnerung: Der zentrale Grenzwertsatz (ZGWS)",
    "text": "Zur Erinnerung: Der zentrale Grenzwertsatz (ZGWS)\n\nDie Summen einer großen Anzahl \\(n\\) unabhängiger und identisch verteilter Zufallswerte konvergieren gegen eine Normalverteilung, unabhängig vom Typ der ursprünglichen Verteilung.\n\n\nWir können Methoden für eine Normalverteilung auch bei Abweichungen von der NV anwenden:\n\nwenn wir einen großen Datensatz haben\nwenn die ursprüngliche Verteilung nicht „zu schief“ ist\n\nDie erforderliche Zahl \\(n\\) hängt von der Schiefe der ursprünglichen Verteilung ab.\n\n\n\nGrund: Methoden wie t-Test oder ANOVA basieren auf Mittelwerten.",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#konfidenzintervalle-des-mittelwerts",
    "href": "slides/04-distributions.html#konfidenzintervalle-des-mittelwerts",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Konfidenzintervalle des Mittelwerts",
    "text": "Konfidenzintervalle des Mittelwerts\n\nStandardfehler\n\\[\ns_{\\bar{x}} = \\frac{s}{\\sqrt{n}}\n\\]\n\nDie Variabilität des Mittelwerts halbiert sich, wenn wir den Stichprobenumfang vervierfachen (\\(2^2\\)).\n\nSchätzung des 95%-Konfidenzintervalls:\n\\[\nCI_{95\\%} = \\bigg(\\bar{x} - z_{0.975} \\cdot \\frac{s}{\\sqrt{n}},\n                 \\bar{x} + z_{0.975} \\cdot \\frac{s}{\\sqrt{n}}\\bigg)\n\\]\nmit \\(z_{1-\\alpha/2} = z_{0.975} =\\) \\(1.96\\).\n\n\\(\\rightarrow\\) \\(2\\sigma\\) Regel\n\n\nIntervall, in dem der wahre Mittelwert mit 95%iger Wahrscheinlichkeit gefunden wird",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#unterschied-zwischen-stichprobe-und-konfidenzintervall",
    "href": "slides/04-distributions.html#unterschied-zwischen-stichprobe-und-konfidenzintervall",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Unterschied zwischen Stichprobe und Konfidenzintervall",
    "text": "Unterschied zwischen Stichprobe und Konfidenzintervall\n\n\nVorhersageintervall: Charakterisiert die Verteilung der Daten anhand der Parameter der Stichprobe (z. B. Mittelwert, Standardabweichung). Es schätzt den Bereich, in den eine einzelne zukünftige Beobachtung wahrscheinlich fallen wird.\nStandardabweichung \\(s_x\\) misst die Variabilität der ursprünglichen Daten\nrekonstruiert die ursprüngliche Verteilung, wenn ihr Typ bekannt ist (z. B. normal, lognormal)\n\n\n\nKonfidenzintervall: charakterisiert die Genauigkeit eines statistischen Parameters, basierend auf seinem Standardfehler\nSchätzt anhand von \\(\\bar{x}\\) und \\(s_\\bar{x}\\) das Intervall, in dem \\(\\mu\\) mit einer bestimmten Wahrscheinlichkeit gefunden wird\nweniger abhängig von der ursprünglichen Verteilung der Daten aufgrund des ZGWS",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#verwendung-der-t-verteilung-für-kleine-stichproben",
    "href": "slides/04-distributions.html#verwendung-der-t-verteilung-für-kleine-stichproben",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Verwendung der t-Verteilung für kleine Stichproben",
    "text": "Verwendung der t-Verteilung für kleine Stichproben\n\\[\nCI_{95\\%} = \\bigg(\\bar{x} - t_{0.975, n-1} \\cdot \\frac{s}{\\sqrt{n}},\n                 \\bar{x} + t_{0.975, n-1} \\cdot \\frac{s}{\\sqrt{n}}\\bigg)\n\\]\n\nnotwendig für kleine Stichproben: \\(n\\lessapprox 30\\), \\(n-1\\) Freiheitsgrade\nkann selbstverständlich auch für \\(n &gt; 30\\) verwendet werden\n\\(t\\)-Quantil kann in Tabellen gefunden oder mit der Funktion qt() in R berechnet werden.\n\nBeispiel mit \\(\\mu=50\\) und \\(\\sigma=10\\):\n\nset.seed(123)\nn &lt;- 10\nx &lt;- rnorm(n, 50, 10)\nm &lt;- mean(x); s &lt;- sd(x)\nse &lt;- s/sqrt(n)\n# lower and upper confidence limits\nm + qt(c(0.025, 0.975), n-1) * se\n\n[1] 43.92330 57.56922\n\n\n\\(\\rightarrow\\) der wahre Mittelwert (\\(\\mu\\)=50) ist im Intervall CI = (43.9, 57.6).",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#ausreißer",
    "href": "slides/04-distributions.html#ausreißer",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Ausreißer",
    "text": "Ausreißer\n\nExtrem große oder extrem kleine Werte werden oft als „Ausreißer“ bezeichnet.\nPotenzielle Ausreißer können aber auch „Extremwerte“ aus einer schiefen Verteilung sein. Sie auszuschließen, kann wissenschaftliches Fehlverhalten sein.\nEin „echter“ Ausreißer ist ein Wert, der nicht aus der zu analysierenden Population stammt, z. B. ein schwerwiegender Messfehler, wenn jemand vergessen hat, eine Chemikalie in einer Analyse hinzuzufügen.\nEr kann aber auch etwas Interessantes sein, z. B. das Ergebnis eines neuen Phänomens.\n\n\\(\\Rightarrow\\) Es kann falsch sein, Werte auszuschließen, nur weil sie „zu groß“ oder „zu klein“ sind.\n\\(\\rightarrow\\) Versuche, den Grund zu finden, warum Werte extrem sind!\n\n\\(4 \\sigma\\)-Regel\n\nprüft, ob ein Wert mehr als 4 Standardabweichungen vom Mittelwert entfernt ist.\nStichprobengröße sollte \\(n \\ge 10\\) sein, \\(\\bar{x}\\) und \\(s\\) werden ohne den potentiellen Ausreißer berechnet.\nÄhnliche „Faustregeln“ sind in Statistik-Lehrbüchern zu finden.",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#ausreißertest-für-lineare-modelle-mit-bonferroni-korrektur",
    "href": "slides/04-distributions.html#ausreißertest-für-lineare-modelle-mit-bonferroni-korrektur",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Ausreißertest für lineare Modelle mit Bonferroni-Korrektur",
    "text": "Ausreißertest für lineare Modelle mit Bonferroni-Korrektur\n\nFür lineare Modelle und GLMs können wir den Bonferroni-Ausreißertest aus dem Paket car verwenden.\n\n\nlibrary(car)\nx &lt;- c(rnorm(20), 12)   # der 21. Wert (=12) ist ein Ausreißer\noutlierTest(lm(x ~ 1))  # x ~ 1 ist das \"Nullmodell\"\n\n   rstudent unadjusted p-value Bonferroni p\n21 11.66351         4.1822e-10   8.7826e-09\n\n\n\\(\\rightarrow\\) Der 21. Wert wird als Ausreißer identifiziert.\n Alternative zu Ausreißertests\n\nVerwendung robuster Parameter und Methoden,\n\nz.B. Median oder getrimmter Mittelwert anstelle des arithmetischen Mittels,\nrobuste lineare Regression „rlm“ anstelle von „lm”\nRangbasierte Methoden wie die Spearman-Korrelation\n\nWichtig Ausreißer können in einer Analyse weggelassen werden, aber die Anzahl und das Ausmaß der Ausreißer müssen erwähnt werden!",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#extremwerte-in-boxplots",
    "href": "slides/04-distributions.html#extremwerte-in-boxplots",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Extremwerte in Boxplots",
    "text": "Extremwerte in Boxplots\n\n\nExtremwerte außerhalb der Whiskers, wenn sie mehr als das 1,5-fache der Breite der Interquartilsbox von den Boxgrenzen entfernt sind.\n\nManchmal auch „Ausreißer“ genannt.\nIch bevorzuge den Begriff „Extremwert“, da es sich um regelmäßige Beobachtungen aus einer schiefen oder einer ‘heavy tailed’ Verteilung handeln kann.",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#beispiel",
    "href": "slides/04-distributions.html#beispiel",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Beispiel",
    "text": "Beispiel\n\npar(mfrow=c(1, 3), las=1)\nelbe &lt;- read.csv(\"https://tpetzoldt.github.io/datasets/data/elbe.csv\")\ndischarge &lt;- elbe$discharge\nboxplot(discharge, main=\"Boxplot des Abflusses\")\nhist(discharge)\nhist(log(discharge - 70))\n\n\nAbflussdaten der Elbe in Dresden in \\(\\mathrm m^3 s^{-1}\\), Datenquelle: Bundesanstalt für Gewässerkunde (BFG), siehe Nutzungshinweise.\n\nLinks: große Anzahl von Extremwerten, sind das Ausreißer?\nMitte: Verteilung ist rechtsschief.\nRechts: Transformation (3-parametrische Lognormalverteilung)  \\(\\rightarrow\\) symmetrische Verteilung, keine Ausreißer!",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/04-distributions.html#mehr-in-den-übungen",
    "href": "slides/04-distributions.html#mehr-in-den-übungen",
    "title": "04-Wahrscheinlichkeitsverteilungen",
    "section": "Mehr in den Übungen …",
    "text": "Mehr in den Übungen …\n\nhttps://tpetzoldt.github.io/element-labs/",
    "crumbs": [
      "Statistische Grundlagen",
      "04-Wahrscheinlichkeitsverteilungen"
    ]
  },
  {
    "objectID": "slides/06-linear.html#das-lineare-modell",
    "href": "slides/06-linear.html#das-lineare-modell",
    "title": "06-Lineare Regression",
    "section": "Das lineare Modell",
    "text": "Das lineare Modell\n\\[\ny_i = \\alpha + \\beta_1 x_{i,1} + \\beta_2 x_{i,2} + \\cdots + \\beta_p x_{i,p} + \\varepsilon_i\n\\]\n\nGrundlegend für viele statistische Methoden\n\nLineare Regression einschließlich einiger (auf den ersten Blick) „nichtlinearer“ Funktionen\nANOVA, ANCOVA, GLM (gleichzeitiges Testen von mehreren Stichproben oder mehreren Faktoren)\nMultivariate Statistik (z. B. PCA)\nZeitreihenanalyse (z. B. ARIMA)\nImputation (Schätzung von fehlenden Werten)",
    "crumbs": [
      "Statistische Grundlagen",
      "06-Lineare Regression"
    ]
  },
  {
    "objectID": "slides/06-linear.html#method-of-least-squares",
    "href": "slides/06-linear.html#method-of-least-squares",
    "title": "06-Lineare Regression",
    "section": "Method of least squares",
    "text": "Method of least squares\n\\[\nRSS = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 = \\sum_{i=1}^n  \\varepsilon^2 \\qquad \\text{(residual sum of squares)}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\\begin{align}\n  \\text{Gesamtvarianz} &= \\text{Varianzaufklärung} &+& \\text{Restvarianz}\\\\\n                    s^2_y &= s^2_{y|x}               &+& s^2_{\\varepsilon}\n\\end{align}\\]",
    "crumbs": [
      "Statistische Grundlagen",
      "06-Lineare Regression"
    ]
  },
  {
    "objectID": "slides/06-linear.html#das-bestimmtheitsmaß",
    "href": "slides/06-linear.html#das-bestimmtheitsmaß",
    "title": "06-Lineare Regression",
    "section": "Das Bestimmtheitsmaß",
    "text": "Das Bestimmtheitsmaß\n\\[\\begin{align}\n     r^2 & = \\frac{\\text{Varianzaufklärung}}{\\text{Gesamtvarianz}}\\\\\n         & = \\frac{s^2_{y|x}}{s^2_y}\\\\\n\\end{align}\\]\nSie kann auch als Verhältnis zwischen der Summe der Quadrate der Residuen (RSS) und der Gesamtsumme (TSS = total sum of squares) ausgedrückt werden:\n\\[\n    r^2 = 1-\\frac{s^2_{\\varepsilon}}{s^2_{y}} = 1-\\frac{RSS}{TSS} =  1- \\frac{\\sum(y_i -\\hat{y}_i)^2}{\\sum(y_i - \\bar{y})^2}\n\\]\n\nabgeleitet von der „Summe der Quadrate“, skaliert als relative Varianz\nidentisch mit der quadrierten Pearson-Korrelation \\(r^2\\) (im linearen Fall)\nSehr nützliche Interpretation: Prozentsatz der Varianz der Rohdaten, der durch das Modell erklärt wird.\n\nZum Beispiel: \\(r^2= 1-\\) 15.3 \\(/\\) 40.8 \\(=\\) 0.625",
    "crumbs": [
      "Statistische Grundlagen",
      "06-Lineare Regression"
    ]
  },
  {
    "objectID": "slides/06-linear.html#minimierung-der-rss",
    "href": "slides/06-linear.html#minimierung-der-rss",
    "title": "06-Lineare Regression",
    "section": "Minimierung der RSS",
    "text": "Minimierung der RSS\n\nAnalytische Lösung: Minimierung der Summe der Quadrate (\\(\\sum \\varepsilon^2\\))\nLineares Gleichungssystem\nMinimale RSS \\(\\longleftarrow\\) partielle 1. Ableitungen (\\(\\partial\\))\n\nFür \\(y=a \\cdot x + b\\) mit 2 Parametern: \\(\\frac{\\partial\\sum \\varepsilon^2}{\\partial{a}}=0\\), \\(\\frac{\\partial\\sum \\varepsilon^2}{\\partial{b}}=0\\):\n\n\\[\\begin{align}\n  \\frac{\\partial \\sum(\\hat{y_i} - y_i)^2}{\\partial a}     &= \\frac{\\partial \\sum(a + b \\cdot x_i - y_i)^2}{\\partial a} = 0\\\\\n      \\frac{\\partial \\sum(\\hat{y_i} - y_i)^2}{\\partial b} &= \\frac{\\partial \\sum(a + b \\cdot x_i - y_i)^2}{\\partial b} = 0\n\\end{align}\\]\nLösung des linearen Gleichungssystems:\n\\[\\begin{align}\nb &=\\frac {\\sum x_iy_i - \\frac{1}{n}(\\sum x_i \\sum y_i)} {\\sum x_i^2 - \\frac{1}{n}(\\sum x_i)^2}\\\\\na &=\\frac {\\sum y_i - b \\sum x_i}{n}\n\\end{align}\\]\n\nLösung für eine beliebige Anzahl von Parametern mit Matrixalgebra",
    "crumbs": [
      "Statistische Grundlagen",
      "06-Lineare Regression"
    ]
  },
  {
    "objectID": "slides/06-linear.html#signifikanz-der-regression",
    "href": "slides/06-linear.html#signifikanz-der-regression",
    "title": "06-Lineare Regression",
    "section": "Signifikanz der Regression",
    "text": "Signifikanz der Regression\n\n\\[\n\\hat{F}_{1;n-2;\\alpha}= \\frac{s^2_{explained}}{s^2_{residual}}\n                         = \\frac{r^2(n-2)}{1-r^2}\n\\] \nAnnahmen\n\nGültigkeit: die Daten entsprechen der Forschungsfrage\nAdditivität und Linearität: \\(y = \\alpha + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots\\)\nUnabhängigkeit der Fehler: Residuen um die Regressionslinie sind unabhängig\nGleiche Varianz der Fehler: Residuen sind homogen um die Regressionsgerade verteilt\nNormalität der Fehler: die „Annahme, die im Allgemeinen am wenigsten wichtig ist“\n\nSiehe: Gelman & Hill (2007) : Data analysis using regression …",
    "crumbs": [
      "Statistische Grundlagen",
      "06-Lineare Regression"
    ]
  },
  {
    "objectID": "slides/06-linear.html#diagnostik",
    "href": "slides/06-linear.html#diagnostik",
    "title": "06-Lineare Regression",
    "section": "Diagnostik",
    "text": "Diagnostik\n\n\n\nKeine Regressionsanalyse ohne grafische Diagnostik!\n\nx-y-Plot mit Regressionsgerade: ist die Varianz homogen?\nPlot der Residuen vs. gefittet: gibt es noch irgendwelche Restmuster?\nQ-Q- Plot, Histogramm: Ist die Verteilung der Residuen näherungsweise normal?\n\nVerwende grafische Methoden für die Normalität, vertraue in diesem Fall nicht auf Shapiro-Wilks.",
    "crumbs": [
      "Statistische Grundlagen",
      "06-Lineare Regression"
    ]
  },
  {
    "objectID": "slides/06-linear.html#konfidenzintervalle-der-parameter",
    "href": "slides/06-linear.html#konfidenzintervalle-der-parameter",
    "title": "06-Lineare Regression",
    "section": "Konfidenzintervalle der Parameter",
    "text": "Konfidenzintervalle der Parameter\n\nBasierend auf Standardfehlern und der t-Verteilung, ähnlich wie beim KI des Mittelwerts\n\n\\[\\begin{align}\na & \\pm t_{1-\\alpha/2, n-2} \\cdot s_a\\\\\nb & \\pm t_{1-\\alpha/2, n-2} \\cdot s_b\n\\end{align}\\]\n\nsummary(m)\n\n\nCall:\nlm(formula = y ~ x)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.4451 -1.0894 -0.4784  1.5065  3.1933 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.50740    0.87338   2.871   0.0102 *  \nx            2.04890    0.07427  27.589 3.51e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.885 on 18 degrees of freedom\nMultiple R-squared:  0.9769,    Adjusted R-squared:  0.9756 \nF-statistic: 761.1 on 1 and 18 DF,  p-value: 3.514e-16\n\n\n Beispiel: KI von a: \\(a \\pm t_{1-\\alpha/2, n-2} \\cdot s_a = 2.5074 \\pm\n2.09 \\cdot 0.87338\\)",
    "crumbs": [
      "Statistische Grundlagen",
      "06-Lineare Regression"
    ]
  },
  {
    "objectID": "slides/06-linear.html#konfidenzintervall-und-vorhersageintervall",
    "href": "slides/06-linear.html#konfidenzintervall-und-vorhersageintervall",
    "title": "06-Lineare Regression",
    "section": "Konfidenzintervall und Vorhersageintervall",
    "text": "Konfidenzintervall und Vorhersageintervall\n\n\nKonfidenzintervall:\n\nZeigt den Bereich, in dem die „wahre Regressionslinie“ zu 95 % erwartet wird.\nDie Breite dieses Bereichs nimmt mit zunehmendem \\(n\\) ab\nanalog zum Standardfehler\n\nVorhersageintervall:\n\nZeigt den Bereich an, in dem die Vorhersage für einen einzelnen Wert (zu 95%) erwartet wird.\nDie Breite ist unabhängig vom Stichprobenumfang \\(n\\)\nanalog zur Standardabweichung",
    "crumbs": [
      "Statistische Grundlagen",
      "06-Lineare Regression"
    ]
  },
  {
    "objectID": "slides/06-linear.html#konfidenzintervalle-für-die-lineare-regression-code",
    "href": "slides/06-linear.html#konfidenzintervalle-für-die-lineare-regression-code",
    "title": "06-Lineare Regression",
    "section": "Konfidenzintervalle für die lineare Regression: Code",
    "text": "Konfidenzintervalle für die lineare Regression: Code\n\n## generiere Beispiel Daten\nx &lt;- 1:10\ny &lt;- 2 + 0.5 * x + 0.5 * rnorm(x)\n\n## fitte Modell\nreg &lt;- lm(y ~ x)\nsummary(reg)\n\n## Daten und Regressionslinie plotten\nplot(x,y, xlim = c(0, 10), ylim = c(0, 10), pch = 16)\nabline(reg, lwd = 2)\n\n## Intervalle berechnen und plotten\nnewdata &lt;- data.frame(x=seq(-1, 11, length=100))\nconflim &lt;- predict(reg, newdata=newdata, interval = \"confidence\")\npredlim &lt;- predict(reg, newdata=newdata, interval = \"prediction\")\n\nlines(newdata$x, conflim[,2], col = \"blue\")\nlines(newdata$x, conflim[,3], col = \"blue\")\nlines(newdata$x, predlim[,2], col = \"red\")\nlines(newdata$x, predlim[,3], col = \"red\")\n\n\nDie Variable newdata:\n\nüberspannt den Bereich der x-Werte in kleinen Schritten, um eine glatte Kurve zu erhalten\neine einzige Spalte mit genau demselben Namen x wie in der Modellformel\nbei multipler Regression: eine Spalte pro Erklärungsvariable",
    "crumbs": [
      "Statistische Grundlagen",
      "06-Lineare Regression"
    ]
  },
  {
    "objectID": "slides/06-linear.html#problemfälle",
    "href": "slides/06-linear.html#problemfälle",
    "title": "06-Lineare Regression",
    "section": "Problemfälle",
    "text": "Problemfälle",
    "crumbs": [
      "Statistische Grundlagen",
      "06-Lineare Regression"
    ]
  },
  {
    "objectID": "slides/06-linear.html#identifizierung-und-behandlung-von-problemfällen",
    "href": "slides/06-linear.html#identifizierung-und-behandlung-von-problemfällen",
    "title": "06-Lineare Regression",
    "section": "Identifizierung und Behandlung von Problemfällen",
    "text": "Identifizierung und Behandlung von Problemfällen\n\nRainbow-Test (Linearität)\n\n## generiere Test-Daten\nx &lt;- 1:10\ny &lt;- 2 + 0.5 * x + 0.5 * rnorm(x)\n\nlibrary(lmtest)\nraintest(y~x)\n\n\n    Rainbow test\n\ndata:  y ~ x\nRain = 0.79952, df1 = 5, df2 = 3, p-value = 0.6153\n\n\n\nBreusch-Pagan-Test (Homogenität der Varianz)\n\nbptest(y~x)\n\n\n    studentized Breusch-Pagan test\n\ndata:  y ~ x\nBP = 3.3989, df = 1, p-value = 0.06524",
    "crumbs": [
      "Statistische Grundlagen",
      "06-Lineare Regression"
    ]
  },
  {
    "objectID": "slides/06-linear.html#nicht-normalität-und-ausreißer",
    "href": "slides/06-linear.html#nicht-normalität-und-ausreißer",
    "title": "06-Lineare Regression",
    "section": "Nicht-Normalität und Ausreißer",
    "text": "Nicht-Normalität und Ausreißer\n\n\nNicht-Normalität\n\nweniger wichtig, als viele Leute denken ( aufgrund des CLTs)\nTransformationen (z. B. Box-Cox), Polynome, periodische Funktionen\nVerwendung von GLM’s (generalized linear models)\n\n\n\n\nAusreißer (abhängig vom Muster)\n\nVerwendung von Transformationen (z.B. Doppellog)\nVerwendung von Ausreißer-Tests, z.B. outlierTest aus Paket car\nrobuste Regression mit IWLS (iteratively re-weighted least squares) aus dem Paket MASS",
    "crumbs": [
      "Statistische Grundlagen",
      "06-Lineare Regression"
    ]
  },
  {
    "objectID": "slides/06-linear.html#robuste-regression-mit-iwls",
    "href": "slides/06-linear.html#robuste-regression-mit-iwls",
    "title": "06-Lineare Regression",
    "section": "Robuste Regression mit IWLS",
    "text": "Robuste Regression mit IWLS\n\n\nIWLS: iterierte, neu gewichtete kleinste Quadrate (engl. iterated re-weighted least squares)\nOLS (gewöhnliche kleinste Quadrate, engl. ordinary least squares) ist eine „normale“ lineare Regression.\nM-Schätzung und MM-Schätzung sind zwei verschiedene Ansätze, Details in Venables & Ripley (2013)\nrobuste Regression ist dem Ausschluss von Ausreißern vorzuziehen",
    "crumbs": [
      "Statistische Grundlagen",
      "06-Lineare Regression"
    ]
  },
  {
    "objectID": "slides/06-linear.html#code-der-iwls-regression",
    "href": "slides/06-linear.html#code-der-iwls-regression",
    "title": "06-Lineare Regression",
    "section": "Code der IWLS-Regression",
    "text": "Code der IWLS-Regression\n\nlibrary(\"MASS\")\n\n## Testdaten mit 2 „Ausreißern“\nx &lt;- c(1, 2, 3, 3, 4, 5, 7, 7, 7, 8, 8, 9, 10, 14, 15, 15, 16, 17, 18, 18)\ny &lt;- c(8.1, 20, 10.9, 8.4, 9.6, 16.1, 17.3, 15.3, 16, 15.9, 19.3, \n       21.3, 24.8, 31.3, 4, 31.9, 33.7, 36.5, 42.4, 38.5)\n\n## Fitten der Modelle\nssq    &lt;- lm(y ~ x)\niwls   &lt;- rlm(y ~ x)\niwlsmm &lt;- rlm(y ~ x, method = \"MM\")\n\n## Plotten der Modelle\nplot(x, y, pch = 16, las = 1)\nabline(ssq, col = \"blue\", lty = \"dashed\")\nabline(iwls, col = \"red\")\nabline(iwlsmm, col = \"green\")\nlegend(\"topleft\", c(\"OLS\", \"IWLS-M\", \"IWLS-MM\"),\n       col = c(\"blue\", \"red\", \"green\"),\n       lty = c(\"dashed\", \"solid\", \"solid\"))",
    "crumbs": [
      "Statistische Grundlagen",
      "06-Lineare Regression"
    ]
  },
  {
    "objectID": "slides/06-linear.html#referenzen",
    "href": "slides/06-linear.html#referenzen",
    "title": "06-Lineare Regression",
    "section": "Referenzen",
    "text": "Referenzen\n\n\n\n\n\nFox, J., & Weisberg, S. (2018). An R companion to applied regression. Sage publications.\n\n\nGelman, A., & Hill, J. (2007). Data analysis using regression and multilevelhierarchical models (Vol. 1). Cambridge University Press New York, NY, USA.\n\n\nKleiber, C., & Zeileis, A. (2008). Applied econometrics with R. Springer.\n\n\nVenables, W. N., & Ripley, B. D. (2013). Modern applied statistics with S-PLUS (3rd ed.). Springer Science; Business Media.",
    "crumbs": [
      "Statistische Grundlagen",
      "06-Lineare Regression"
    ]
  },
  {
    "objectID": "slides/08-nonlinear-regression.html#nichtlineare-regression",
    "href": "slides/08-nonlinear-regression.html#nichtlineare-regression",
    "title": "08-Nichtlineare Regression",
    "section": "Nichtlineare Regression",
    "text": "Nichtlineare Regression\nViele Phänomene in der Natur sind nichtlinear!\nLinear oder nichtlinear?\n\nEinige nichtlineare Probleme können mit linearen Methoden gelöst werden\nz.B. Polynome oder periodische (Sinus- und Cosinus-) Funktionen\nandere können durch Transformationen angepasst werden\n\nBeispiel\n\\[y = a \\cdot x^b\\] kann umgewandelt werden in:\n\\[\\ln(y) = \\ln(a) + b \\cdot \\ln(x)\\]\n\naber: Linearisierung transformiert auch die Residuen\ndie Transformation ist manchmal richtig und manchmal falsch\nHomogenität der Varianzen",
    "crumbs": [
      "Statistische Grundlagen",
      "08-Nichtlineare Regression"
    ]
  },
  {
    "objectID": "slides/08-nonlinear-regression.html#linearisierung-oder-direkte-nichtlineare-anpassung",
    "href": "slides/08-nonlinear-regression.html#linearisierung-oder-direkte-nichtlineare-anpassung",
    "title": "08-Nichtlineare Regression",
    "section": "Linearisierung oder direkte nichtlineare Anpassung?",
    "text": "Linearisierung oder direkte nichtlineare Anpassung?\n\nLinearisierende Transformationen\n\nLogarithmus, Quadratwurzel, Kehrwerte …\nkönnen angewandt werden, wenn die Restvarianz homogen bleibt (oder wird).\naber in einigen Fällen führen die Transformationen zu Heteroskedastizität \\(\\Rightarrow\\) verfälschte Regressionsparameter.\n\nNichtlineare Regression\n\nsehr flexible, benutzerdefinierte Funktionen\nkeine Transformation erforderlich\naber: erfordert iterative Optimierungsmethoden\ntheoretisch können nur lokale Optima gefunden werden\nParameter sind nicht in allen Fällen identifizierbar",
    "crumbs": [
      "Statistische Grundlagen",
      "08-Nichtlineare Regression"
    ]
  },
  {
    "objectID": "slides/08-nonlinear-regression.html#nichtlineare-regression-1",
    "href": "slides/08-nonlinear-regression.html#nichtlineare-regression-1",
    "title": "08-Nichtlineare Regression",
    "section": "Nichtlineare Regression",
    "text": "Nichtlineare Regression\n\nIterative Suche nach dem Minimum der Summe der Quadrate",
    "crumbs": [
      "Statistische Grundlagen",
      "08-Nichtlineare Regression"
    ]
  },
  {
    "objectID": "slides/08-nonlinear-regression.html#wie-lässt-sich-das-globale-minimum-finden",
    "href": "slides/08-nonlinear-regression.html#wie-lässt-sich-das-globale-minimum-finden",
    "title": "08-Nichtlineare Regression",
    "section": "Wie lässt sich das globale Minimum finden?",
    "text": "Wie lässt sich das globale Minimum finden?\n\nAnpassungsgüte: Residuensumme der quadrierten Differenzen \\(RSS\\):\n\\[\nRSS = \\sum_{i=1}^n\\left(y_i- f(\\mathbf x_i, \\mathbf p)\\right)^2 = \\min !\n\\]\nmit \\(y\\): abhängige Variable, \\(\\mathbf x\\): Matrix der unabhängigen Variablen,\\(\\mathbf p\\): Parametervektor, \\(n\\): Stichprobenumfang\nVerwendung eines iterativen Lösers \\(\\rightarrow\\) siehe nächste Folien\nNichtlinearer Bestimmungskoeffizient \\(R^2\\)\n\nsteht in keinem Zusammenhang mit dem (linearen) Korrelationskoeffizienten\nkann aus den Rest- und Gesamtvarianzen berechnet werden\n\n\\[\nR^2 = 1 - \\frac{\\text{Varianz der Residuen}}{\\text{Varianz der y-Daten}} = 1- \\frac{s^2_\\varepsilon}{s^2_y}\n\\]\n\nnichtlinear \\(r^2\\) misst den Anteil der erklärten Varianz\n… andere Indizes können zusätzlich verwendet werden, z.B. MSE, RMSE, NSE, …",
    "crumbs": [
      "Statistische Grundlagen",
      "08-Nichtlineare Regression"
    ]
  },
  {
    "objectID": "slides/08-nonlinear-regression.html#allgemeines-prinzip-von-optimierungsalgorithmen",
    "href": "slides/08-nonlinear-regression.html#allgemeines-prinzip-von-optimierungsalgorithmen",
    "title": "08-Nichtlineare Regression",
    "section": "Allgemeines Prinzip von Optimierungsalgorithmen",
    "text": "Allgemeines Prinzip von Optimierungsalgorithmen\n\nDas Minimum der quadrierten Residuen (RSS) wird durch Iteration gesucht.:\n\n\nBeginne mit einer Anfangsschätzung für den Parametersatz.\nVersuche, einen Parametersatz mit niedrigerer RSS zu finden.\nIst der neue Parametersatz besser?\n\nNein: Verwerfe die neuen Parameter und gehe zu 2\nJa: Akzeptiere die neuen Parameter und springe zu 4\n\nIst der neue Parametersatz gut genug?\n\nNein: Springe zu 2\nJa: Springe zu 5\n\nParametersatz gefunden.",
    "crumbs": [
      "Statistische Grundlagen",
      "08-Nichtlineare Regression"
    ]
  },
  {
    "objectID": "slides/08-nonlinear-regression.html#deterministische-methoden",
    "href": "slides/08-nonlinear-regression.html#deterministische-methoden",
    "title": "08-Nichtlineare Regression",
    "section": "Deterministische Methoden",
    "text": "Deterministische Methoden\n\n\nGradient Descent\n\neinen Schritt in die Richtung des steilsten Abstiegs gehen\n\\(\\rightarrow\\) relativ einfach\n\\(\\rightarrow\\) relativ robust für „kompliziertere“ Probleme\n\nNewton-Methode\n\nquadratische Approximation der RSS-Funktion\nVersuche, das Minimum zu schätzen\n\\(\\rightarrow\\) berücksichtigt die Krümmung\n\\(\\rightarrow\\) ist schneller für „gut funktionierende“ Probleme\nmehrere Versionen: quasi-Newton, Gauss-Newton, L-BFGS, …\n\nLevenberg-Marquardt\n\ninterpoliert zwischen Gauß-Newton und Gradient Descent.\n\n\n  Die Newton-Methode (rot) nutzt Krümmungsinformationen, um schneller zu konvergieren als der Gradient Descent (grün). Quelle: Wikipedia.",
    "crumbs": [
      "Statistische Grundlagen",
      "08-Nichtlineare Regression"
    ]
  },
  {
    "objectID": "slides/08-nonlinear-regression.html#stochastische-methoden",
    "href": "slides/08-nonlinear-regression.html#stochastische-methoden",
    "title": "08-Nichtlineare Regression",
    "section": "Stochastische Methoden",
    "text": "Stochastische Methoden\n\nAnwendung statistischer Prinzipien (Zufallssuche)\nKlassische Methoden\n\nSimuliertes Glühen: simuliert die Erwärmung und Abkühlung von Materie \\(\\rightarrow\\) „Kristallisationsprozess“.\nKontrollierte Zufallssuche Price (1983)\n\nEvolutionäre Algorithmen\n\nAnalogie zur Genetik: Mutation und Selektion\nverfolgt eine „Population“ von mehreren Parametersätzen parallel\nInformationsaustausch („Crossover“) zwischen Parametersätzen\n\\(\\rightarrow\\) für komplizierte Probleme mit einer großen Anzahl von Parametern\nheutzutage in Microsoft Excel und LibreOffice Calc eingebaut\n\n… und vieles mehr.",
    "crumbs": [
      "Statistische Grundlagen",
      "08-Nichtlineare Regression"
    ]
  },
  {
    "objectID": "slides/08-nonlinear-regression.html#enzymkinetik",
    "href": "slides/08-nonlinear-regression.html#enzymkinetik",
    "title": "08-Nichtlineare Regression",
    "section": "Enzymkinetik",
    "text": "Enzymkinetik\n\n… kann mit der bekannten Michaelis-Menten-Funktion beschrieben werden:\n\\[\nv = v_{max} \\frac{S}{k_m + S}\n\\]",
    "crumbs": [
      "Statistische Grundlagen",
      "08-Nichtlineare Regression"
    ]
  },
  {
    "objectID": "slides/08-nonlinear-regression.html#linearisierung-vs.-echte-nichtlineare-regression",
    "href": "slides/08-nonlinear-regression.html#linearisierung-vs.-echte-nichtlineare-regression",
    "title": "08-Nichtlineare Regression",
    "section": "Linearisierung vs. (echte) nichtlineare Regression",
    "text": "Linearisierung vs. (echte) nichtlineare Regression\n\nLinearisierende Transformation\n[&gt;] Angemessen, wenn die Transformation die Homogenität der Varianzen verbessert. [+] Schnell, einfach und leicht. [+] Analytische Lösung liefert das globale Optimum. [-] Nur eine begrenzte Anzahl von Funktionen kann angepasst werden. [-] Kann zu einer falsch transformierten Fehlerstruktur und verzerrten Ergebnissen führen.\nNichtlineare Regression\n[&gt;] Geeignet, wenn die Fehlerstruktur bereits homogen ist und/oder keine analytische Lösung existiert. [+] Kann zur Anpassung beliebiger Funktionen verwendet werden, sofern die Parameter identifizierbar sind. [-] Benötigt Startwerte und beträchtliche Berechnungszeit. [-] Beste Lösung (globales Optimum) ist nicht garantiert.",
    "crumbs": [
      "Statistische Grundlagen",
      "08-Nichtlineare Regression"
    ]
  },
  {
    "objectID": "slides/08-nonlinear-regression.html#nichtlineare-regression-in-r-einfache-exponentielle-regression",
    "href": "slides/08-nonlinear-regression.html#nichtlineare-regression-in-r-einfache-exponentielle-regression",
    "title": "08-Nichtlineare Regression",
    "section": "Nichtlineare Regression in R: einfache exponentielle Regression",
    "text": "Nichtlineare Regression in R: einfache exponentielle Regression\n\nModell anpassen\n\n# Beispieldaten\nx &lt;- 1:10\ny &lt;- c(1.6, 1.8, 2.1, 2.8, 3.5, \n       4.1, 5.1, 5.8, 7.1, 9.0)\n\n# Anfangsparameter für den Optimierer\npstart &lt;- c(a = 1, b = 1)\n\n# nichtlineare kleinste Quadrate\nfit &lt;- nls(y ~ a * exp(b * x), start = pstart)\nsummary(fit)\n\n\nFormula: y ~ a * exp(b * x)\n\nParameters:\n  Estimate Std. Error t value Pr(&gt;|t|)    \na 1.263586   0.049902   25.32 6.34e-09 ***\nb 0.194659   0.004716   41.27 1.31e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1525 on 8 degrees of freedom\n\nNumber of iterations to convergence: 13 \nAchieved convergence tolerance: 5.956e-08\n\n\n\nPlotte Ergebnisse\n\n# zusätzliche x-Werte, für eine geglättete Kurve\nx1 &lt;- seq(1, 10, 0.1)\ny1 &lt;- predict(fit, data.frame(x = x1))\nplot(x, y)\nlines(x1, y1, col = \"red\")",
    "crumbs": [
      "Statistische Grundlagen",
      "08-Nichtlineare Regression"
    ]
  },
  {
    "objectID": "slides/08-nonlinear-regression.html#angepasste-parameter",
    "href": "slides/08-nonlinear-regression.html#angepasste-parameter",
    "title": "08-Nichtlineare Regression",
    "section": "Angepasste Parameter",
    "text": "Angepasste Parameter\n\n\n\n\nFormula: y ~ a * exp(b * x)\n\nParameters:\n  Estimate Std. Error t value Pr(&gt;|t|)    \na 1.263586   0.049902   25.32 6.34e-09 ***\nb 0.194659   0.004716   41.27 1.31e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1525 on 8 degrees of freedom\n\nNumber of iterations to convergence: 13 \nAchieved convergence tolerance: 5.956e-08\n\n\n\nEstimate: die angepassten Parameter\nStd. Error: \\(s_{\\bar{x}}\\): zeigt die Zuverlässigkeit der Schätzung an\nt- und p-Werte: keine Überinterpretation!\nIn der nichtlinearen Welt können „nicht-signifikante“ Parameter strukturell notwendig sein.\n\nBestimmungskoeffizient \\(r^2 = 1-\\frac{s^2_\\varepsilon}{s^2_y}\\)\n\n(Rsquared &lt;- 1 - var(residuals(fit))/var(y))\n\n[1] 0.9965644",
    "crumbs": [
      "Statistische Grundlagen",
      "08-Nichtlineare Regression"
    ]
  },
  {
    "objectID": "slides/08-nonlinear-regression.html#michaelis-menten-kinetik",
    "href": "slides/08-nonlinear-regression.html#michaelis-menten-kinetik",
    "title": "08-Nichtlineare Regression",
    "section": "Michaelis-Menten-Kinetik",
    "text": "Michaelis-Menten-Kinetik\n\n\nCode\n\n\nS &lt;-c(25, 25, 10, 10, 5, 5, 2.5, 2.5, 1.25, 1.25)\nV &lt;-c(0.0998, 0.0948, 0.076, 0.0724, 0.0557,\n      0.0575, 0.0399, 0.0381, 0.017, 0.0253)\n\n## Michaelis-Menten-Kinetik\nf &lt;- function(S, Vm, K) { Vm * S/(K + S) }\n\npstart &lt;- c(Vm = 0.1, K = 5)\nmodel_fit &lt;- nls(V ~ f(S, Vm, K), start = pstart)\nsummary(model_fit)\n\nplot(S, V, xlim = c(0, max(S)), ylim = c(0, max(V)))\nx1 &lt;-seq(0, 25, length = 100)\nlines(x1, predict(model_fit, data.frame(S = x1)), col = \"red\")\n\n\n Bestimmungskoeffizient\n\n(1 - var(residuals(model_fit))/var(V))\n\n[1] 0.9895147\n\n\n\nErgebnisse\n\n\n\nFormula: V ~ f(S, Vm, K)\n\nParameters:\n   Estimate Std. Error t value Pr(&gt;|t|)    \nVm  0.11713    0.00381   30.74 1.36e-09 ***\nK   5.38277    0.46780   11.51 2.95e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.003053 on 8 degrees of freedom\n\nNumber of iterations to convergence: 3 \nAchieved convergence tolerance: 6.678e-06",
    "crumbs": [
      "Statistische Grundlagen",
      "08-Nichtlineare Regression"
    ]
  },
  {
    "objectID": "slides/08-nonlinear-regression.html#michaelis-menten-kinetik-mit-selbststart",
    "href": "slides/08-nonlinear-regression.html#michaelis-menten-kinetik-mit-selbststart",
    "title": "08-Nichtlineare Regression",
    "section": "Michaelis-Menten-Kinetik mit Selbststart",
    "text": "Michaelis-Menten-Kinetik mit Selbststart\n\nFunktion SSmicmen bestimmt Startparameter automatisch.\nNur wenige Selbststartfunktionen in R verfügbar.\n\n\nCode\n\n\nS &lt;- c(25, 25, 10, 10, 5, 5, 2.5, 2.5, 1.25, 1.25)\nV &lt;- c(0.0998, 0.0948, 0.076, 0.0724, 0.0557,\n       0.0575, 0.0399, 0.0381, 0.017, 0.0253)\n\nmodel_fit &lt;- nls(V ~ SSmicmen(S, Vm, K))\n\nplot(S, V, xlim = c(0, max(S)), ylim = c(0, max(V)))\nx1 &lt;-seq(0, 25, length = 100)\nlines(x1, predict(model_fit, data.frame(S = x1)), col=\"red\")\n\n\nErgebnisse\n\n\nsummary(model_fit, correlation=TRUE)\n\n\nFormula: V ~ f(S, Vm, K)\n\nParameters:\n   Estimate Std. Error t value Pr(&gt;|t|)    \nVm  0.11713    0.00381   30.74 1.36e-09 ***\nK   5.38277    0.46780   11.51 2.95e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.003053 on 8 degrees of freedom\n\nCorrelation of Parameter Estimates:\n  Vm  \nK 0.88\n\nNumber of iterations to convergence: 3 \nAchieved convergence tolerance: 6.678e-06\n\n\n\n\n\n\nPlot\n\n\n\n\n\n\n\n\n\n\nAnmerkung: Korrelation der Parameter\n\nHohe absolute Korrelationswerte deuten auf die Nichtidentifizierbarkeit von Parametern hin.\nkritischer Wert hängt von den Daten ab\nmanchmal können bessere Startwerte oder ein anderer Optimierungsalgorithmus helfen",
    "crumbs": [
      "Statistische Grundlagen",
      "08-Nichtlineare Regression"
    ]
  },
  {
    "objectID": "slides/08-nonlinear-regression.html#praktische-hinweise",
    "href": "slides/08-nonlinear-regression.html#praktische-hinweise",
    "title": "08-Nichtlineare Regression",
    "section": "Praktische Hinweise",
    "text": "Praktische Hinweise\n\n\nDaten plotten\nFinde gute Ausgangswerte durch Nachdenken oder durch Trial and Error\nVermeide sehr kleine und/oder sehr große Zahlen \\(\\longrightarrow\\) skaliere das Problem auf Werte zwischen etwa 0,001 und 1000 um\nBeginne mit einer einfachen Funktion und füge nach und nach Terme und Parameter hinzu\nNimm die Signifikanz von Parametern nicht zu ernst. Ein nicht signifikanter Parameter kann für die Struktur des Modells notwendig sein, sein Wegfall macht das gesamte Modell ungültig.",
    "crumbs": [
      "Statistische Grundlagen",
      "08-Nichtlineare Regression"
    ]
  },
  {
    "objectID": "slides/08-nonlinear-regression.html#weiterführende-literatur",
    "href": "slides/08-nonlinear-regression.html#weiterführende-literatur",
    "title": "08-Nichtlineare Regression",
    "section": "Weiterführende Literatur",
    "text": "Weiterführende Literatur\n\n\nPaket growthrates für Wachstumskurven: https://cran.r-project.org/package=growthrates\nPaket FME für komplexere Modellanpassungsaufgaben (Identifizierbarkeitsanalyse, eingeschränkte Optimierung, mehrere abhängige Variablen und MCMC): (Soetaert & Petzoldt, 2010), https://cran.r-project.org/package=FME\nMehr über Optimierung in R: https://cran.r-project.org/web/views/Optimization.html",
    "crumbs": [
      "Statistische Grundlagen",
      "08-Nichtlineare Regression"
    ]
  },
  {
    "objectID": "slides/08-nonlinear-regression.html#lineweaver-burk-transformation-vs.-nichtlineare-anpassung",
    "href": "slides/08-nonlinear-regression.html#lineweaver-burk-transformation-vs.-nichtlineare-anpassung",
    "title": "08-Nichtlineare Regression",
    "section": "Lineweaver-Burk-Transformation vs. nichtlineare Anpassung",
    "text": "Lineweaver-Burk-Transformation vs. nichtlineare Anpassung\n\nCode der Methodenvergleichsfolie\n\n\nS &lt;-c(25, 25, 10, 10, 5, 5, 2.5, 2.5, 1.25, 1.25)\nV &lt;-c(0.0998, 0.0948, 0.076, 0.0724, 0.0557, \n      0.0575, 0.0399, 0.0381, 0.017, 0.0253)\nmodel_fit&lt;-nls(V ~ SSmicmen(S, Vm, K))\n\npar(mfrow=c(1,2), las=1, lwd=2)\n## Lineweaver-Burk\nx &lt;- 1/S; y &lt;- 1/V\n\nplot(x, y, xlab=\"1/S\", ylab=\"1/V\", xlim=c(-0.2,1), ylim=c(0, 80), pch=16,\n  main=\"Linearisation\\n(Lineweaver-Burk)\")\nabline(h=0, lwd=1, col=\"grey\")\nabline(v=0, lwd=1, col=\"grey\")\nm &lt;- lm(y ~ x)\nabline(m, col = \"red\")\nVm_l &lt;- 1/coef(m)[1]\nKm_l &lt;- coef(m)[2] * Vm_l\n#legend(\"topleft\", c(\"vmax = 1/intercept\", \"km = slope * vmax\"), \n#        box.lwd=1, bg=\"white\")\ntext(0.35, 75, \"1/V = 1/vmax + km / vmax * S\")\n\n## retransformed, both together\nplot(S, V, xlim = c(0, max(S)),ylim=c(0, max(V)), pch=16, main=\"No Transformation\")\nx1 &lt;-seq(0, 25, length=100)\nlines(x1, Vm_l * x1 / (Km_l + x1), col=\"red\")\nlines(x1, predict(model_fit, data.frame(S=x1)), col=\"blue\")\nlegend(\"bottomright\", legend=c(\"linearisation\", \"nonlinear\"), \n       box.lwd=1, lwd=2, col=c(\"red\", \"blue\"))\ntext(15, 0.04, \"V = S * vmax / (km + S)\")\n\n\nSiehe: https://en.wikipedia.org/wiki/Lineweaver-Burk_plot",
    "crumbs": [
      "Statistische Grundlagen",
      "08-Nichtlineare Regression"
    ]
  },
  {
    "objectID": "slides/08-nonlinear-regression.html#referenzen",
    "href": "slides/08-nonlinear-regression.html#referenzen",
    "title": "08-Nichtlineare Regression",
    "section": "Referenzen",
    "text": "Referenzen\n\n\n\n\n\nPrice, W. L. (1977). A controlled random search procedure for global optimization. The Computer Journal, 20(4), 367–370.\n\n\nPrice, W. L. (1983). Global optimization by controlled random search. Journal of Optimization Theory and Applications, 40(3), 333–348.\n\n\nSoetaert, K., & Petzoldt, T. (2010). Inverse modelling, sensitivity and monte carlo analysis in R using package FME. Journal of Statistical Software, 33(3), 1–28. https://doi.org/10.18637/jss.v033.i03",
    "crumbs": [
      "Statistische Grundlagen",
      "08-Nichtlineare Regression"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#table-of-contents",
    "href": "slides/x2-r-graphics.html#table-of-contents",
    "title": "x2-Graphics with R",
    "section": "Table of Contents",
    "text": "Table of Contents\n\n\nThe easy way\nCustomizing graphics\nMultiple grapics on one page\nSaving and exporting graphics\nLattice\ngrid and gridbase\nggplot2",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#the-easy-way",
    "href": "slides/x2-r-graphics.html#the-easy-way",
    "title": "x2-Graphics with R",
    "section": "The Easy Way",
    "text": "The Easy Way\n\n\nplot(iris)\n\n\n\nR contains many graphics functions with convenient defaults.\niris is a built-in data set in R (see next slide)\nplot is a so-called generic function that automatically decides how to plot.",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#the-iris-data-set",
    "href": "slides/x2-r-graphics.html#the-iris-data-set",
    "title": "x2-Graphics with R",
    "section": "The iris data set",
    "text": "The iris data set\n\nThe famous (Fisher’s or Anderson’s) iris data set contains measurements (in centimeter) of the variables sepal length, sepal width, petal length and petal width of 50 flowers from each of 3 species of iris, Iris setosa, I. versicolor, and I. virginica.\n\nsee ?iris in R’s online help.\nor: https://en.wikipedia.org/wiki/Iris_flower_data_set",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#plotting-colums-of-a-data-frame",
    "href": "slides/x2-r-graphics.html#plotting-colums-of-a-data-frame",
    "title": "x2-Graphics with R",
    "section": "Plotting colums of a data frame",
    "text": "Plotting colums of a data frame\n\n\nplot(iris$Sepal.Length, iris$Petal.Length)\n\n\n\n\n\n\n\n\n\n\nplot(iris$Sepal.Length, iris$Petal.Length,\n     col=iris$Species)\n\n\n\n\n\n\n\n\nA column of a data.frame is accessed with $.",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#the-use-of-with-saves-dollars",
    "href": "slides/x2-r-graphics.html#the-use-of-with-saves-dollars",
    "title": "x2-Graphics with R",
    "section": "The use of with() saves dollars",
    "text": "The use of with() saves dollars\n\n\n\nplot(iris$Sepal.Length, iris$Petal.Length, \n     col=iris$Species)\n\n\n\n\n\n\n\n\n\n\nwith(iris, plot(Sepal.Length, Petal.Length, \n                col=Species))",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#colors-and-plotting-symbols-in-r",
    "href": "slides/x2-r-graphics.html#colors-and-plotting-symbols-in-r",
    "title": "x2-Graphics with R",
    "section": "Colors and plotting symbols in R",
    "text": "Colors and plotting symbols in R\nR allows to change style and color of plotting symbols:\n\ncol: color, can be one of 8 default colors or a user-defined color\npch: plotting character, can be one of 25 symbols or a quoted letter\ncex: character extension: size of a plotting character\n\n\nplot(1:25, col=1:25, pch=1:15, cex=2)",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#special-plotting-symbols",
    "href": "slides/x2-r-graphics.html#special-plotting-symbols",
    "title": "x2-Graphics with R",
    "section": "Special plotting symbols",
    "text": "Special plotting symbols\n\nsymbols 21..25 have an optional background color\nlwd: border width of the symbol\n\n\nplot(21:25, col=\"darkred\", pch=21:25, cex=2, bg=\"green\", lwd=2)",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#r-as-function-plotter",
    "href": "slides/x2-r-graphics.html#r-as-function-plotter",
    "title": "x2-Graphics with R",
    "section": "R as function plotter",
    "text": "R as function plotter\n\nx &lt;- seq(0, 20, length.out=100)\ny1 &lt;- sin(x)\ny2 &lt;- cos(x)\nplot(x, y1, type=\"l\", col=\"red\")\nlines(x, y2, col=\"blue\")\n\n\n\ntype: “p”: points, “l”: lines, “b”: both, points and lines, “c”: empty points joined by lines, “o”: overplotted points and lines, “s” and “S”: stair steps, “h” histogram-like vertical lines, “n”: no points or lines.",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#line-styles",
    "href": "slides/x2-r-graphics.html#line-styles",
    "title": "x2-Graphics with R",
    "section": "Line styles",
    "text": "Line styles\n\nx &lt;- seq(0, 20, length.out=100)\nplot(x, sin(x), type=\"l\", col=\"red\", lwd=3, lty=\"dotted\")\nlines(x, cos(x), col=\"blue\", lwd=2, lty=\"dashed\")\n\n\n\nlty: line type (“blank”, “solid”, “dashed”, “dotted”, “dotdash”, “longdash”, “twodash”) or a number from 1…7, or a string with up to 8 numbers for drawing and skipping (e.g. “4224”).\nlwd: line width (a number, defaults to 1)",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#coordinate-axes-and-annotations",
    "href": "slides/x2-r-graphics.html#coordinate-axes-and-annotations",
    "title": "x2-Graphics with R",
    "section": "Coordinate axes and annotations",
    "text": "Coordinate axes and annotations\n\nplot(iris$Sepal.Length, iris$Petal.Length, xlim=c(0, 8), ylim=c(2,8),\n     col=iris$Species, pch=16,\n     xlab=\"Sepal Length (cm)\", ylab=\"Petal Length (cm)\", main=\"Iris Data\",\n     las = 1)\n\n\n\ncol=iris$Species: works because Species is a factor\nlas=1: numbers on y-axis upright (try: 0, 1, 2 or 3)\nlog: may be used to transform axes (e.g. log=“x”, log=“y”, log=“xy”)",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#adding-a-legend",
    "href": "slides/x2-r-graphics.html#adding-a-legend",
    "title": "x2-Graphics with R",
    "section": "Adding a legend",
    "text": "Adding a legend\n\nmycolors &lt;- c(\"blue\", \"red\", \"cyan\")\nplot(iris$Sepal.Length, iris$Petal.Length, xlim=c(0, 8), ylim=c(2,8),\n     col=mycolors[iris$Species], pch = 16,\n     xlab=\"Sepal Length (cm)\", ylab=\"Petal Length (cm)\", main=\"Iris Data\",\n     las = 1)\nlegend(\"topleft\", legend=c(\"Iris setosa\", \"Iris versicolor\", \"Iris virginica\"),\n  col=mycolors, pch=16)\n\n\n\nsee ?legend for more options (e.g. line styles, position of the legend)",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#global-parameters-font-size-margins",
    "href": "slides/x2-r-graphics.html#global-parameters-font-size-margins",
    "title": "x2-Graphics with R",
    "section": "Global parameters, font size, margins, …",
    "text": "Global parameters, font size, margins, …\n\n\nMany figure options can be specified globally with par()\npar(lwd=2) all lines have double width\npar(mfrow=c(2,2)) subdivides the graphics area in 2 x 2 fields\npar(las=1) numbers at y axis upright\npar(mar=c(5, 5, 0.5, 0.5)) changes figure margins (bottom, left, top, right)\npar(cex=2) increase font size\n\\(\\rightarrow\\) sometimes it is better to leave font size as is and change size of the figure instead\n\n\n\nRead the ?par help page!",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#example",
    "href": "slides/x2-r-graphics.html#example",
    "title": "x2-Graphics with R",
    "section": "Example",
    "text": "Example\n\n\n#\nplot(iris$Sepal.Length, iris$Petal.Length, \n     col=iris$Species)\n#\n\n\n\n\n\n\n\n\n\n\n\n\nopar &lt;- par(cex=2, mar=c(4,4,1,1), las=1)\nplot(iris$Sepal.Length, iris$Petal.Length, \n     col=iris$Species)\npar(opar)\n\n\n\n\n\n\n\n\n\n\n\nchange font size (cex), margins (mar) and axis label orientation (las)\nopar stores previuos parameter and allows resetting",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#saving-and-exporting-figures",
    "href": "slides/x2-r-graphics.html#saving-and-exporting-figures",
    "title": "x2-Graphics with R",
    "section": "Saving and exporting figures",
    "text": "Saving and exporting figures\n\nEasiest way ist to use the RStudio’s Export –&gt; Save as Image (or copy to clipboard)\nImportant: Select correct image format and image size!\n\n\n\n\n\n\n\n\n\n\nFormat\nType\nUsage\nNotes\n\n\n\n\nPNG\nbitmap\ngeneral purpose\nfixed size, use at least 300 pixels per inch\n\n\nJPEG\nbitmap\nphotographs\nnot good for R images\n\n\nTIFF\nbitmap\nPNG is easier\noutdated, required by some journals\n\n\nBMP\nbitmap\nnot recommended\noutdated, needs huge memory\n\n\nMetafile\nvector\nWindows standard format\neasy to use, quality varies\n\n\nSVG\nvector\ncan be edited\nallows editing with Inkscape\n\n\nEPS\nvector\nPDF is easier\nrequired by some journals\n\n\nPDF\nvector\nbest quality\nperfect for LaTex, RMarkdown and Quarto, MS Office requires conversion",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#vector-vs.-bitmap-graphics",
    "href": "slides/x2-r-graphics.html#vector-vs.-bitmap-graphics",
    "title": "x2-Graphics with R",
    "section": "Vector vs. Bitmap Graphics",
    "text": "Vector vs. Bitmap Graphics\nBitmap formats\n\njpg, png, tiff\nfixed resolution, cannot be magnified without loss\nretouching possible, but not editing\nwell suited for pictures or plots with huge number of data (color maps)\ncannot be converted to vector without complications and quality loss\n\nVector formats\n\nsvg, pdf, [wmf, emf]\ncan be up- and downscaled and edited\nwell suited drawings and diagrams (except if huge amount of data)\ncan always be converted to bitmap",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#writing-figures-directly-to-pdf",
    "href": "slides/x2-r-graphics.html#writing-figures-directly-to-pdf",
    "title": "x2-Graphics with R",
    "section": "Writing figures directly to PDF",
    "text": "Writing figures directly to PDF\n\n\n\npdf(\"myfile.pdf\", width=8, height=6)\npar(las=1)\nplot(iris$Sepal.Length, iris$Petal.Length, col=iris$Species)\ndev.off()\n\n\n\nwidth and height in inch (1 inch = 2.54cm)\nprofessional quality, size can be changed without quality loss\nconversion to PNG can be done later with free programs\n\n\\(\\rightarrow\\) Inkscape, SumatraPDF, ImageMagick",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#writing-figures-directly-to-png",
    "href": "slides/x2-r-graphics.html#writing-figures-directly-to-png",
    "title": "x2-Graphics with R",
    "section": "Writing figures directly to PNG",
    "text": "Writing figures directly to PNG\n\n\npng(\"myfile.png\", width=1600, height=1200, res=300)  # good for Word\n#png(\"myfile.png\", width=800, height=600, res=150)   # good for Powerpoint\npar(las=1)\npar(mar=c(5, 5, 1, 1))\nplot(iris$Sepal.Length, iris$Petal.Length)\ndev.off()\n\n\nwidth and height given in pixels\nHint: play with res to change nominal resolution and font size\nuse at least 300 dpi (dots per inch, i.e. number of pixels = 300/2.54 * width in cm)\nprofessionals use 600 or even 1200 pixels per inch, but then .docx and .pptx files will dramatically increase\n1600 x 1200px is good for 13.3 x 10 cm size in the printed document",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#font-size-of-ggplot-figures",
    "href": "slides/x2-r-graphics.html#font-size-of-ggplot-figures",
    "title": "x2-Graphics with R",
    "section": "Font size of ggplot figures",
    "text": "Font size of ggplot figures\n\nAppearance and font sizes of ggplot figures can be controlled with themes.\nIt makes sense to create a theme separately and then add it with “+”.\n\n\n\nlibrary(ggplot2)\ndata(iris) \n\n# define a theme with  user-specified font sizes\nfigure_theme &lt;- theme(\n  axis.text    = element_text(size = 12),\n  axis.title   = element_text(size = 12, face = \"bold\"),\n  legend.title = element_text(size = 12, face = \"bold\"),\n  legend.text  = element_text(size = 12))\n\n# ggplots can be stored in a variable\np &lt;- iris |&gt; \n  ggplot(aes(Petal.Length, Petal.Width, colour = Species)) +  \n  geom_point() + figure_theme\n\nPrint to a file:\n\npng(\"iris.png\", width=1600, height=1000, res=300)\nprint(p)\ndev.off()\n\n\nPrint to the screen:\n\n\n\n\n\n\n\n\n\nMore about themes can be found in the books of Chang (2024) and Wickham et al. (in press).",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#example-solar-radiation-data-in-dresden",
    "href": "slides/x2-r-graphics.html#example-solar-radiation-data-in-dresden",
    "title": "x2-Graphics with R",
    "section": "Example: Solar Radiation Data in Dresden",
    "text": "Example: Solar Radiation Data in Dresden\n\nradiation &lt;- read.csv(\"../data/radiation.csv\")\nradiation$Date &lt;- as.Date(radiation$date)\n\n\nplot(radiation$Date, radiation$rad)\n\n\nNote: The data set contains derived data from the German Weather Service (http://www.dwd.de), station Dresden. Missing data were interpolated.",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#date-and-time-classes-in-r",
    "href": "slides/x2-r-graphics.html#date-and-time-classes-in-r",
    "title": "x2-Graphics with R",
    "section": "Date and time classes in R",
    "text": "Date and time classes in R\n\n\nMost important classes\n\nas.Date (dates only)\nas.POSIXct (date and time)\n\nformat and strptime\nextract day, month, year, Julian day\ntime series objects tseriesand zoo",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#format-and-strptime",
    "href": "slides/x2-r-graphics.html#format-and-strptime",
    "title": "x2-Graphics with R",
    "section": "format and strptime",
    "text": "format and strptime\n\nformat(x, format = \"\", tz = \"\", usetz = FALSE, ...)\n\n\n\n\n%Y\nyear with century\n\n\n%m\nmonth as decimal number\n\n\n%d\nday of the month\n\n\n%H\nhours as decimal number (00-23)\n\n\n%M\nminute as decimal number (00-59)\n\n\n%S\nsecond as decimal number (00-59)\n\n\n%j\nday of year (001-366)\n\n\n%u\nweekday, Monday is 1\n\n\n\n\nas.Date(\"11.03.2015\", format=\"%d.%m.%Y\")\n\n[1] \"2015-03-11\"",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#date-conversion-for-the-solar-radiation-data-set",
    "href": "slides/x2-r-graphics.html#date-conversion-for-the-solar-radiation-data-set",
    "title": "x2-Graphics with R",
    "section": "Date conversion for the solar radiation data set",
    "text": "Date conversion for the solar radiation data set\n\nradiation$year &lt;- format(radiation$Date, \"%Y\")\nradiation$month &lt;- format(radiation$Date, \"%m\")\nradiation$doy &lt;- format(radiation$Date, \"%j\")\nradiation$weekday &lt;- format(radiation$Date, \"%u\")\n\nhead(radiation)\n\n        date rad interpolated       Date year month doy weekday\n1 1981-01-01 197            0 1981-01-01 1981    01 001       4\n2 1981-01-02  89            0 1981-01-02 1981    01 002       5\n3 1981-01-03  49            0 1981-01-03 1981    01 003       6\n4 1981-01-04 111            0 1981-01-04 1981    01 004       7\n5 1981-01-05 161            0 1981-01-05 1981    01 005       1\n6 1981-01-06  55            0 1981-01-06 1981    01 006       2\n\n\n\nThe lubridate package has date and time functions that are easier to use.",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#summarize-data-with-aggregate",
    "href": "slides/x2-r-graphics.html#summarize-data-with-aggregate",
    "title": "x2-Graphics with R",
    "section": "Summarize data with aggregate",
    "text": "Summarize data with aggregate\nSyntax\n\naggregate(x, by, FUN, ..., simplify = TRUE)\n\nExample\n\nyearmax &lt;- aggregate(\n  list(rad = radiation$rad),\n  list(year = radiation$year),\n  max)\n\nmonmean &lt;- aggregate(\n  list(radiation = radiation$rad),\n  list(year = radiation$year, month = radiation$month),\n  mean)\n\n\naggregate is essentially a wrapper to apply",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#plot-aggregated-radiation-data",
    "href": "slides/x2-r-graphics.html#plot-aggregated-radiation-data",
    "title": "x2-Graphics with R",
    "section": "Plot aggregated radiation data",
    "text": "Plot aggregated radiation data\n\npar(mfrow=c(1,2), las=1)\nboxplot(rad ~ year, data = radiation)\nboxplot(rad ~ month, data = radiation)\n\n\nMost functions that support a formula argument (containing ~) allow to specify the data frame with a data argument.",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#different-plotting-packages-with-different-philosophies",
    "href": "slides/x2-r-graphics.html#different-plotting-packages-with-different-philosophies",
    "title": "x2-Graphics with R",
    "section": "Different plotting packages with different philosophies",
    "text": "Different plotting packages with different philosophies\n\n\nbase graphics\npackage lattice\npackage ggplot2\nManipulation of plots\n\nset size and fonts; save plots to disk\nuse pdf, svg or png – not jpg - except for photographs\n\nRelated software\n\nedit/convert svg (and pdf) with Inkscape\nconvert images with ImageMagick",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#base-graphics-1",
    "href": "slides/x2-r-graphics.html#base-graphics-1",
    "title": "x2-Graphics with R",
    "section": "Base Graphics",
    "text": "Base Graphics\n\nx &lt;- rnorm(100)\npar(mfrow=c(2,2))\nplot(x)\nhist(x)\nqqnorm(x)\nboxplot(x)",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#grid-and-gridbase",
    "href": "slides/x2-r-graphics.html#grid-and-gridbase",
    "title": "x2-Graphics with R",
    "section": "grid and gridBase",
    "text": "grid and gridBase\n\ncomplete freedom to organise plotting area\ninterface relatively raw\nbasis of other plotting packages",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#lattice-graphics",
    "href": "slides/x2-r-graphics.html#lattice-graphics",
    "title": "x2-Graphics with R",
    "section": "Lattice Graphics",
    "text": "Lattice Graphics\n\nImplements “trellis graphics” (i.e. gridded graphics) in R\nSarkar, D. (2008). Lattice: multivariate data visualization with R. Springer Science & Business Media.\n\n\nrequire(lattice)\ndata(iris)\nxyplot(Sepal.Length ~ Sepal.Width|Species, data=iris, layout=c(3,1))",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#ggplot2",
    "href": "slides/x2-r-graphics.html#ggplot2",
    "title": "x2-Graphics with R",
    "section": "ggplot2",
    "text": "ggplot2\n\n\nImplements the “Grammar of Graphics”\n\nLeland Wilkinson (2005) The Grammar of Graphics. 2nd edn. Springer\nHadley Wickham (2009, 2016) ggplot2: Elegant Graphics for Data Analysis. Springer.\n\nvery popular, part of the tidyverse family of packages\nhttps://ggplot2.tidyverse.org/",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#ggplot-example",
    "href": "slides/x2-r-graphics.html#ggplot-example",
    "title": "x2-Graphics with R",
    "section": "ggplot-Example",
    "text": "ggplot-Example\n\nlibrary(ggplot2)\ndata(iris)\nggplot(iris, aes(Sepal.Length, Sepal.Width, color = factor(Species))) + \n  geom_point() + \n  stat_smooth(method = \"lm\")",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#pipelines-and-faceting-in-ggplot2",
    "href": "slides/x2-r-graphics.html#pipelines-and-faceting-in-ggplot2",
    "title": "x2-Graphics with R",
    "section": "Pipelines and faceting in ggplot2",
    "text": "Pipelines and faceting in ggplot2\n\nlibrary(\"dplyr\")\nlibrary(\"lubridate\")\nlibrary(\"ggplot2\")\nread.csv(\"../data/radiation.csv\") |&gt;\n  mutate(year=year(date), doy=yday(date)) |&gt;\n  ggplot(aes(doy, rad)) + geom_line() + facet_wrap(. ~ year)",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x2-r-graphics.html#further-reading",
    "href": "slides/x2-r-graphics.html#further-reading",
    "title": "x2-Graphics with R",
    "section": "Further Reading",
    "text": "Further Reading\n\nMore presentations\n\nR Basics\nFunctions everywhere\n\nBooks\n\nChang, W. (2024) R Graphics Cookbook. O’Reilly.\nWickham, H. Navarro, D. and Pedersen, T.L. (in press) ggplot2: Elegant Graphics for Data Analysis\n\nManuals\nMore details in the official R manuals, especially in An Introduction to R\nVideos\nMany videos can be found on Youtube, at the Posit webpage and somewhere else.\nThis tutorial was made with Quarto\nContact\nAuthor: tpetzoldt +++ Homepage +++ Github page",
    "crumbs": [
      "Selected Programming Topics",
      "x2-Graphics with R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#prerequisites",
    "href": "slides/x4-pipes-intro.html#prerequisites",
    "title": "x4-Pipelines in R",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nThe examples in slis slide require the following R packages: packages, that must be installed and loaded.\n\nInstallation\n\ninstall.packages(c(\"dplyr\", \"tiryr\", \"lubridate\", \"readxl\", \"ggplot2\"))\n\n\nLoading\n\nlibrary(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"lubridate\")\nlibrary(\"readxl\")\nlibrary(\"ggplot2\")\n\n\nThe examples were tested with R 4.3.1 and RStudio 2023.06.1",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#an-introductory-example",
    "href": "slides/x4-pipes-intro.html#an-introductory-example",
    "title": "x4-Pipelines in R",
    "section": "An introductory example",
    "text": "An introductory example\n\nIn a statistics course, two samples of Maple (Acer platanoides) leaves were collected by two groups of students:\ngroup HSE: had the freedom to collect leaves individually from trees close to the institute\ngroup HYB: got a random sample from the supervisor\n\nHypothesis: sampling bias may affect statistical parameters, especially mean and variance.\n\nDownload the file leaves.csv, save it to a working directory and then read it with read.csv:\n\nleaves &lt;- read.csv(\"leaves.csv\") \n\n\nHave a look at the data:\n\nhead(leaves)\n\n  group no length width stalk\n1   HSE  1     83    87    74\n2   HSE  2    130   153   105\n3   HSE  3    140   148   135\n4   HSE  4    102   110    94\n5   HSE  5    190   151    89\n6   HSE  6    225   139    91",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#a-boxplot",
    "href": "slides/x4-pipes-intro.html#a-boxplot",
    "title": "x4-Pipelines in R",
    "section": "A boxplot",
    "text": "A boxplot\n\n\n\nboxplot(width ~ group, data=leaves)",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#summary-statistics",
    "href": "slides/x4-pipes-intro.html#summary-statistics",
    "title": "x4-Pipelines in R",
    "section": "Summary statistics",
    "text": "Summary statistics\n\n\nsummary(leaves)\n\n    group                 no             length           width      \n Length:126         Min.   :  1.00   Min.   : 37.00   Min.   : 44.0  \n Class :character   1st Qu.: 32.25   1st Qu.: 72.00   1st Qu.: 96.0  \n Mode  :character   Median : 63.50   Median : 90.00   Median :118.5  \n                    Mean   : 63.50   Mean   : 95.83   Mean   :117.4  \n                    3rd Qu.: 94.75   3rd Qu.:102.00   3rd Qu.:138.5  \n                    Max.   :126.00   Max.   :250.00   Max.   :199.0  \n     stalk       \n Min.   : 29.00  \n 1st Qu.: 62.00  \n Median : 82.00  \n Mean   : 81.89  \n 3rd Qu.:101.00  \n Max.   :175.00",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#summary-statistics-per-group",
    "href": "slides/x4-pipes-intro.html#summary-statistics-per-group",
    "title": "x4-Pipelines in R",
    "section": "Summary statistics per group",
    "text": "Summary statistics per group\n\n\ndifferent ways to calculate summary statistics\nclassical method with aggregate\n\nA few examples\n\naggregate(cbind(length, width, stalk) ~ group, mean, data=leaves)\n\n  group    length    width     stalk\n1   HSE 137.82857 139.0286 102.02857\n2   HYB  79.67033 109.1319  74.14286\n\naggregate(cbind(length, width, stalk) ~ group, sd, data=leaves)\n\n  group   length    width    stalk\n1   HSE 47.99356 26.07285 26.47917\n2   HYB 19.93771 30.90423 25.24087\n\naggregate(cbind(length, width, stalk) ~ group, min, data=leaves)\n\n  group length width stalk\n1   HSE     83    87    52\n2   HYB     37    44    29\n\n\n\naggregate is very powerful, but the modern “tidyverse” approach is easier to understand. This is explained in the following.",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#summary-statistics-with-the-dplyr-package",
    "href": "slides/x4-pipes-intro.html#summary-statistics-with-the-dplyr-package",
    "title": "x4-Pipelines in R",
    "section": "Summary statistics with the dplyr-package",
    "text": "Summary statistics with the dplyr-package\nPackage dplyr contains two handy functions:\n\ngroup_by\nsummarize\n\nThe functions can be combined in different ways:\nA) Two separate code lines\n\nleaves_grouped &lt;- group_by(leaves, group)\nsummarize(leaves_grouped, mean = mean(width), sd = sd(width), min = min(width), max = max(width))\n\n\\(\\ominus\\) needs a temporary variable: leaves_grouped\n B) One line, group_by enclosed in parentheses\n\nsummarize(group_by(leaves, group), mean=mean(width), sd=sd(width), min=min(width), max=max(width))\n\n\\(\\oplus\\) no temporary variables necessary  \\(\\ominus\\) nested parentheses",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#more-streamlined-pipelines",
    "href": "slides/x4-pipes-intro.html#more-streamlined-pipelines",
    "title": "x4-Pipelines in R",
    "section": "More streamlined: pipelines",
    "text": "More streamlined: pipelines\n\nAim to make code easier to understand:\n\navoids nested parentheses\navoids temporary variables\n\nRecent versions of R (since 4.1) have built-in support for pipelines:\n\nNative pipeline operator |&gt;\n\nA predecessor was the so-called “magrittr” pipeline operator %&gt;%\n\nMost examples from these slides will work with both pipeline operators.\nThere are a few differences regarding use of so-called placeholders.\nI recommended to prefer native pipes |&gt;\n\n\n\nThe `%&gt;%-pipeline was introduced by the user-contributed magrittr package (Bache & Wickham, 2022) and became very popular. It is automatically loaded by the dplyr package (Wickham, François, et al., 2023). In his new book, Hadley Wickham recommends native pipes (Wickham, Çetinkaya-Rundel, et al., 2023).",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#application-of",
    "href": "slides/x4-pipes-intro.html#application-of",
    "title": "x4-Pipelines in R",
    "section": "Application of |>",
    "text": "Application of |&gt;\n\nThe output from the first function is piped to the next\n\ngroup_by(leaves, group) |&gt;\nsummarize(mean = mean(width), sd = sd(width), \n          min = min(width), max = max(width))\n\n\nOr, even more streamlined: start pipeline with the data frame\n\nleaves |&gt;\n  group_by(group) |&gt;\n  summarize(mean = mean(width), sd = sd(width), \n            min = min(width), max = max(width))\n\n# A tibble: 2 × 5\n  group  mean    sd   min   max\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt;\n1 HSE    139.  26.1    87   195\n2 HYB    109.  30.9    44   199",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#how-it-works",
    "href": "slides/x4-pipes-intro.html#how-it-works",
    "title": "x4-Pipelines in R",
    "section": "How it works",
    "text": "How it works\nThe pipe operator |&gt; inserts the output from one function into the first argument of the next function.\n\n\nClassical functional style\n\ngroup_by(leaves, group)\n\n\n\n\n\n\n\n\nPipeline style\n\nleaves |&gt; group_by(group)",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#summary-statistics-for-all-variables",
    "href": "slides/x4-pipes-intro.html#summary-statistics-for-all-variables",
    "title": "x4-Pipelines in R",
    "section": "Summary statistics for all variables",
    "text": "Summary statistics for all variables\n\nThe leaves dataset contains different variables length, width and stalk length.\nWe can now, in principle, extend summarize:\n\nAdd more code rows\n\nleaves |&gt;\n  group_by(group) |&gt;\n  summarize(mean_l=mean(width),  sd_l=sd(width),  min_l=min(width),  max_l=max(width),\n            mean_w=mean(length), sd_w=sd(length), min_w=min(length), max_w=max(length),\n            mean_s=mean(stalk),  sd_s=sd(stalk),  min_s=min(stalk),  max_s=max(stalk)\n  )\n\n\nIs copy and paste a good idea?\nNo, at least not in excess.\n\nCopy and paste can lead to errors.\n… and there are more compact and elegant ways.",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#tidy-your-data-and-use-long-data-formats",
    "href": "slides/x4-pipes-intro.html#tidy-your-data-and-use-long-data-formats",
    "title": "x4-Pipelines in R",
    "section": "Tidy your data and use “long” data formats!",
    "text": "Tidy your data and use “long” data formats!\n\n\nLong data formats are more database like and more flexible.\n\nIf you are used to working with LibeOffiice or Excel, you will probably prefer “wide” tables that fit well on the computer screen. However, this is not such a good idea for data bases and scripted data science.\nModern data analysis packages like dplyr and ggplot2 mandatorily require the long format.",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#long-data-format-tidy-format",
    "href": "slides/x4-pipes-intro.html#long-data-format-tidy-format",
    "title": "x4-Pipelines in R",
    "section": "Long data format (= tidy format)",
    "text": "Long data format (= tidy format)\n\nPut data from all 3 variables in one column: length, width, stalk \\(\\rightarrow\\) value\nIdentifier column for the variables: name\n\n\nWide format\n\n\n\n\n\ngroup\nno\nlength\nwidth\nstalk\n\n\n\n\nHSE\n1\n83\n87\n74\n\n\nHSE\n2\n130\n153\n105\n\n\nHSE\n3\n140\n148\n135\n\n\nHSE\n4\n102\n110\n94\n\n\nHSE\n5\n190\n151\n89\n\n\nHSE\n6\n225\n139\n91\n\n\nHSE\n7\n195\n165\n76\n\n\nHSE\n8\n216\n135\n113\n\n\nHSE\n9\n250\n195\n119\n\n\nHSE\n10\n152\n168\n158\n\n\n\n\n\n\nLong format\n\n\n\n\n\ngroup\nno\nname\nvalue\n\n\n\n\nHSE\n1\nlength\n83\n\n\nHSE\n1\nwidth\n87\n\n\nHSE\n1\nstalk\n74\n\n\nHSE\n2\nlength\n130\n\n\nHSE\n2\nwidth\n153\n\n\nHSE\n2\nstalk\n105\n\n\nHSE\n3\nlength\n140\n\n\nHSE\n3\nwidth\n148\n\n\nHSE\n3\nstalk\n135\n\n\nHSE\n4\nlength\n102\n\n\n\n\n\n… … …",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#long-data-format-with-pivot_longer",
    "href": "slides/x4-pipes-intro.html#long-data-format-with-pivot_longer",
    "title": "x4-Pipelines in R",
    "section": "Long data format with pivot_longer",
    "text": "Long data format with pivot_longer\n\n\n\nleaves |&gt; \n  pivot_longer(c(\"length\", \"width\", \"stalk\"))\n\n# A tibble: 378 × 4\n   group    no name   value\n   &lt;chr&gt; &lt;int&gt; &lt;chr&gt;  &lt;int&gt;\n 1 HSE       1 length    83\n 2 HSE       1 width     87\n 3 HSE       1 stalk     74\n 4 HSE       2 length   130\n 5 HSE       2 width    153\n 6 HSE       2 stalk    105\n 7 HSE       3 length   140\n 8 HSE       3 width    148\n 9 HSE       3 stalk    135\n10 HSE       4 length   102\n# ℹ 368 more rows",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#summary-statistics-for-all-variables-groupwise",
    "href": "slides/x4-pipes-intro.html#summary-statistics-for-all-variables-groupwise",
    "title": "x4-Pipelines in R",
    "section": "Summary statistics for all variables groupwise",
    "text": "Summary statistics for all variables groupwise\n\n\n\nleaves |&gt; \n  pivot_longer(c(\"length\", \"width\", \"stalk\")) |&gt;\n  group_by(group, name) |&gt;\n  summarize(mean = mean(value), \n            sd   = sd(value), \n            min  = min(value),\n            max  = max(value))\n\n# A tibble: 6 × 6\n# Groups:   group [2]\n  group name    mean    sd   min   max\n  &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt;\n1 HSE   length 138.   48.0    83   250\n2 HSE   stalk  102.   26.5    52   175\n3 HSE   width  139.   26.1    87   195\n4 HYB   length  79.7  19.9    37   124\n5 HYB   stalk   74.1  25.2    29   144\n6 HYB   width  109.   30.9    44   199",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#pipes-and-the-assignment-operator--",
    "href": "slides/x4-pipes-intro.html#pipes-and-the-assignment-operator--",
    "title": "x4-Pipelines in R",
    "section": "Pipes and the assignment operator <-",
    "text": "Pipes and the assignment operator &lt;-\n\n\nIn the examples before, the pipe-output was directly printed to the screen\nIf we need the result in a subsequent operation, we assign it to a variable as usual with &lt;-\n\n\n\ntotals &lt;- \n  leaves |&gt; \n  pivot_longer(c(\"length\", \"width\", \"stalk\")) |&gt;\n  group_by(group, name) |&gt;\n  summarize(mean=mean(value), sd=sd(value), min=min(value), max=max(value))\n\n\nDon’t get confused!\n\nthe pipe starts with leaves in the second code line\nthe direction of the pipeline is from left \\(\\rightarrow\\) right\nthen the of the complete pipeline is assigned to totals\n\nIt follows the convention, that the result of an equation is assigned from right to the left.",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#reverse-assignment",
    "href": "slides/x4-pipes-intro.html#reverse-assignment",
    "title": "x4-Pipelines in R",
    "section": "Reverse assignment?",
    "text": "Reverse assignment?\n\n“More logical”, but less common would be a consequent left to the right notation with -&gt;\n\n\nleaves |&gt; \n  pivot_longer(c(\"length\", \"width\", \"stalk\")) |&gt;\n  group_by(group, name) |&gt;\n  summarize(mean=mean(value), sd=sd(value), min=min(value), max=max(value)) -&gt;\n  totals\n\n\nAmelia McNamara used this style in her keynote talk at the 2020 use!R conference about Speaking R on youtube.\nBut, Headley Wickham discouraged this style, because the -&gt; breaks with mathematical convention and is difficult to spot in the code.",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#indentation",
    "href": "slides/x4-pipes-intro.html#indentation",
    "title": "x4-Pipelines in R",
    "section": "Indentation",
    "text": "Indentation\n\n\ntotals &lt;- \n  leaves |&gt; \n  pivot_longer(c(\"length\", \"width\", \"stalk\")) |&gt;\n  group_by(group, name) |&gt;\n  summarize(mean=mean(value), sd=sd(value), min=min(value), max=max(value))\n\n\nThe pipeline above shows essentially one single line of code.\n\nTo improve readability, code lines should not be longer than 80 characters.\nRemember: Line breaks can be at any position, as long as a code line is not complete.\nCommon style: make a newline after &lt;- and |&gt; and use 2 characters for indentation.",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#the-clementine-orange-data-set",
    "href": "slides/x4-pipes-intro.html#the-clementine-orange-data-set",
    "title": "x4-Pipelines in R",
    "section": "The Clementine orange data set",
    "text": "The Clementine orange data set",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#clementine-orange-data-set",
    "href": "slides/x4-pipes-intro.html#clementine-orange-data-set",
    "title": "x4-Pipelines in R",
    "section": "Clementine orange data set",
    "text": "Clementine orange data set\n\n\nSamples of clementine oranges, measured, weighed and consumed in a statistic course.\nExcel file with two tables:\n\nlong table with the fruits\nshorter table brands with meta data\n\nData can be downloaded from here.\n\n\nRead data directly from Excel file\n\nbrands  &lt;- read_excel(\"clementines_2019.xlsx\", \"Brands\")\nfruits  &lt;- read_excel(\"clementines_2019.xlsx\", \"Fruits\")",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#clementine-orange-data-set-1",
    "href": "slides/x4-pipes-intro.html#clementine-orange-data-set-1",
    "title": "x4-Pipelines in R",
    "section": "Clementine orange data set",
    "text": "Clementine orange data set\n\n\nTable “fruits”\n\n\n\n\n\nyear\nbrand\nweight\nwidth\nheight\n\n\n\n\n2019\nEB\n107\n61.0\n54\n\n\n2019\nEB\n100\n65.0\n55\n\n\n2019\nEB\n89\n58.0\n49\n\n\n2019\nEB\n99\n62.0\n52\n\n\n2019\nEB\n99\n64.0\n58\n\n\n2019\nEB\n96\n63.0\n59\n\n\n2019\nEB\n100\n54.0\n54\n\n\n2019\nEB\n89\n58.5\n47\n\n\n2019\nEB\n86\n66.0\n48\n\n\n2019\nEB\n92\n43.0\n33\n\n\n2019\nEB\n102\n48.0\n33\n\n\n2019\nEB\n92\n43.0\n32\n\n\n\n\n\n\nTable “brands”\n\n\n\n\n\nyear\nbrand\ntype\nkilogram\nprice\n\n\n\n\n2019\nEB\nBasic\n1.50\n2.99\n\n\n2019\nEP\nGold\n0.75\n1.49\n\n\n2019\nLB\nBasic\n1.00\n1.49\n\n\n2019\nLO\nBio\n0.50\n1.49\n\n\n2019\nNX\nBox\n2.30\n2.99\n\n\n2019\nNP\nPremium\n1.00\n2.29\n\n\n2019\nNB\nBasic\n1.00\n1.49\n\n\n2019\nNC\nBasic\n1.00\n1.49",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#database-join",
    "href": "slides/x4-pipes-intro.html#database-join",
    "title": "x4-Pipelines in R",
    "section": "Database join",
    "text": "Database join\n\njoin two tables to bring the information together\nIn case of left_join, the (larger) main table is at the left.\nThe tables have two key fields in common: year and brand.\nThe key fields can be automatically detected or explicitly specified or renamed \\(\\rightarrow\\) help page of left_join\n\n\n\nfruits2 &lt;- left_join(fruits, brands)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nno\nyear\nbrand\nweight\nwidth\nheight\ntaste\nshop\ntype\nquality\nkilogram\nprice\n\n\n\n\n1\n2019\nEB\n107\n61\n54\n6\nEdeka\nBasic\nBasic\n1.5\n2.99\n\n\n2\n2019\nEB\n100\n65\n55\n7\nEdeka\nBasic\nBasic\n1.5\n2.99\n\n\n3\n2019\nEB\n89\n58\n49\n10\nEdeka\nBasic\nBasic\n1.5\n2.99\n\n\n4\n2019\nEB\n99\n62\n52\n7\nEdeka\nBasic\nBasic\n1.5\n2.99\n\n\n5\n2019\nEB\n99\n64\n58\n8\nEdeka\nBasic\nBasic\n1.5\n2.99\n\n\n6\n2019\nEB\n96\n63\n59\n8\nEdeka\nBasic\nBasic\n1.5\n2.99\n\n\n7\n2019\nEB\n100\n54\n54\n7\nEdeka\nBasic\nBasic\n1.5\n2.99",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#selection-of-columns-and-rows-select-and-filter",
    "href": "slides/x4-pipes-intro.html#selection-of-columns-and-rows-select-and-filter",
    "title": "x4-Pipelines in R",
    "section": "Selection of columns and rows: select and filter",
    "text": "Selection of columns and rows: select and filter\n\n\nselect: select columns\nfilter: filters rows\n\n\n\n\nfruits2 |&gt;\n  select(brand, shop, type, weight, width) |&gt;\n  filter(shop %in% c(\"Edeka\", \"Lidl\"))\n\n# A tibble: 44 × 5\n   brand shop  type  weight width\n   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 EB    Edeka Basic    107  61  \n 2 EB    Edeka Basic    100  65  \n 3 EB    Edeka Basic     89  58  \n 4 EB    Edeka Basic     99  62  \n 5 EB    Edeka Basic     99  64  \n 6 EB    Edeka Basic     96  63  \n 7 EB    Edeka Basic    100  54  \n 8 EB    Edeka Basic     89  58.5\n 9 EB    Edeka Basic     86  66  \n10 EB    Edeka Basic     92  43  \n# ℹ 34 more rows",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#create-or-transform-columns-mutate",
    "href": "slides/x4-pipes-intro.html#create-or-transform-columns-mutate",
    "title": "x4-Pipelines in R",
    "section": "Create or transform columns: mutate",
    "text": "Create or transform columns: mutate\n\nExample\nTransform a variable, e.g. weight by \\(x^{1/3}\\) into a theoretical mean diameter\n\nfruits2 &lt;- \n  fruits2 |&gt;\n  mutate(L_mean = weight^(1/3))\n\n\nShow results\nClassical boxplot\n\n\nboxplot(L_mean ~ brand, data=fruits2)",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#plot-in-tidyverse-style-with-pipes-and-ggplot",
    "href": "slides/x4-pipes-intro.html#plot-in-tidyverse-style-with-pipes-and-ggplot",
    "title": "x4-Pipelines in R",
    "section": "Plot in “tidyverse”-style with pipes and ggplot",
    "text": "Plot in “tidyverse”-style with pipes and ggplot\n\nfruits2 |&gt;\n  mutate(L_mean = weight^(1/3)) |&gt;\n  ggplot(aes(brand, L_mean)) + geom_boxplot()",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#another-mutate-example",
    "href": "slides/x4-pipes-intro.html#another-mutate-example",
    "title": "x4-Pipelines in R",
    "section": "Another mutate example",
    "text": "Another mutate example\nLet’s compare the measured weight of our fruits with a “theoretical volume” calculated from length and height using the formula of an ellipsoid. This is of course an approximation:\n\\[\nV = 4/3 \\pi \\cdot \\rm (length/2)^2 \\cdot height/2\n\\]\n\nfruits &lt;-\n  fruits |&gt;\n  mutate(V = 0.001 * 4/3 * pi * (width/2)^2 * height/2, index = weight / V)\n\n\n\n\nlibrary(ggplot2)\nfruits |&gt;\n  ggplot(aes(weight, index)) + \n  geom_point()\n\nThe “+” operator in ggplot looks like a pipeline, but works differently.\nIt adds elements to a plot.",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#color-coded-points",
    "href": "slides/x4-pipes-intro.html#color-coded-points",
    "title": "x4-Pipelines in R",
    "section": "Color coded points",
    "text": "Color coded points\n\nlibrary(ggplot2)\nfruits |&gt; ggplot(aes(weight, index, color=brand)) + geom_point()",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#categorial-split-faceting-and-regression-line",
    "href": "slides/x4-pipes-intro.html#categorial-split-faceting-and-regression-line",
    "title": "x4-Pipelines in R",
    "section": "Categorial split (faceting) and regression line",
    "text": "Categorial split (faceting) and regression line\n\nfruits |&gt; \n  ggplot(aes(weight, V)) + \n  geom_point() + \n  geom_smooth(method=lm, se=FALSE) + \n  facet_wrap( ~ brand)",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#modify-font-size",
    "href": "slides/x4-pipes-intro.html#modify-font-size",
    "title": "x4-Pipelines in R",
    "section": "Modify font size",
    "text": "Modify font size\n\nfruits |&gt; \n  ggplot(aes(weight, V)) + \n  geom_point() + \n  geom_smooth(method=lm, se=FALSE) + \n  facet_wrap( ~ brand) +\n  theme(text = element_text(size=24))\n\n\n\\(\\rightarrow\\) themes allow to configure “almost everything” …",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#discharge-of-the-elbe-river",
    "href": "slides/x4-pipes-intro.html#discharge-of-the-elbe-river",
    "title": "x4-Pipelines in R",
    "section": "Discharge of the Elbe River",
    "text": "Discharge of the Elbe River\nElbe River in Dresden 2006-04-01",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#read-data-to-r",
    "href": "slides/x4-pipes-intro.html#read-data-to-r",
    "title": "x4-Pipelines in R",
    "section": "Read data to R",
    "text": "Read data to R\n\nThe example file elbe.csv contains daily discharge of the Elbe River in \\(\\mathrm{m^3 s^{-1}}\\) from gauging station Dresden, river km 55.6. The data are from the Federal Waterways and Shipping Administration (WSV) and where provided by the Federal Institute for Hydrology (BfG).\n\nWe can skip downloading and read the file directly from its internet location:\n\n\nelbe &lt;- read.csv(\"https://raw.githubusercontent.com/tpetzoldt/datasets/main/data/elbe.csv\")\n\n\nThe third column “validated” indicate whether the values were finally approved by WSV and BfG. Data of the 19th century are particularly uncertain. Please consult the file elbe_info.txt for details.",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#date-and-time-conversion",
    "href": "slides/x4-pipes-intro.html#date-and-time-conversion",
    "title": "x4-Pipelines in R",
    "section": "Date and time conversion",
    "text": "Date and time conversion\n\nNow, let’s extend the elbe data frame by adding information about the day, month, year and day of year. Here function mutate adds additional columns.\nNote also that the day of year function in the date and time package lubridate is named yday.\nDetails about date and time conversion can be found in the lubridate cheatsheet.\n\n\nlibrary(lubridate) # a tidyverse package for dates\nelbe &lt;- mutate(elbe,\n               date  = as.POSIXct(date),\n               day   = day(date), \n               month = month(date), \n               year  = year(date), \n               doy   = yday(date))",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#inspect-data-structure",
    "href": "slides/x4-pipes-intro.html#inspect-data-structure",
    "title": "x4-Pipelines in R",
    "section": "Inspect data structure",
    "text": "Inspect data structure\nIf we work with RStudio, may have a look at the “Global Environment” pane and inspect the data structure of the elbe data frame.\n\n\n\n\n\ndate\ndischarge\nvalidated\nday\nmonth\nyear\ndoy\n\n\n\n\n1989-01-01\n765\nTRUE\n1\n1\n1989\n1\n\n\n1989-01-02\n713\nTRUE\n2\n1\n1989\n2\n\n\n1989-01-03\n684\nTRUE\n3\n1\n1989\n3\n\n\n1989-01-04\n612\nTRUE\n4\n1\n1989\n4\n\n\n1989-01-05\n565\nTRUE\n5\n1\n1989\n5\n\n\n1989-01-06\n519\nTRUE\n6\n1\n1989\n6\n\n\n1989-01-07\n522\nTRUE\n7\n1\n1989\n7\n\n\n1989-01-08\n524\nTRUE\n8\n1\n1989\n8\n\n\n1989-01-09\n544\nTRUE\n9\n1\n1989\n9\n\n\n1989-01-10\n539\nTRUE\n10\n1\n1989\n10\n\n\n1989-01-11\n606\nTRUE\n11\n1\n1989\n11\n\n\n1989-01-12\n606\nTRUE\n12\n1\n1989\n12",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#annual-summary-statistics",
    "href": "slides/x4-pipes-intro.html#annual-summary-statistics",
    "title": "x4-Pipelines in R",
    "section": "Annual summary statistics",
    "text": "Annual summary statistics\n\nSummarize data\n\n## calculate annual mean, minimum, maximum\ntotals &lt;- elbe |&gt;\n  group_by(year) |&gt;\n  summarize(mean = mean(discharge), \n            min = min(discharge), \n            max = max(discharge))\n\n\nShow table of summary statistics\n\nhead(totals)\n\n# A tibble: 6 × 4\n   year  mean   min   max\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  1989  268.   122   765\n2  1990  217.    89   885\n3  1991  189.    97   634\n4  1992  267.    89  1090\n5  1993  256.    92  1610\n6  1994  317.    92  1030\n\n\n Exercise: Compute monthly discharge mean values and monthly sums.",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#more-about-pivot-tables",
    "href": "slides/x4-pipes-intro.html#more-about-pivot-tables",
    "title": "x4-Pipelines in R",
    "section": "More about pivot tables",
    "text": "More about pivot tables\n\n\nIn a section before, we already used pivot_longer to reorganize data. Now we do the opposite and convert a data base table (long data format) into a cross-table (wide data format) and vice versa.\nR provides several function pairs for this, so you may see functions like melt and cast or gather and spread.\nRecently the two functions pivot_wider and pivot_longer were recommended for this purpose.\n\nThe first argument is a data base table, the other arguments define the structure of the desired crosstable.\nid_cols is the name of a column in a long table that will become the rows\nnames_from indicates where the names of the columns are taken from\nvalues_from is the column with the values for the cross table.\n\n\n\\(\\rightarrow\\) If more than one value exists for a row x column combination, an optional aggregation function values_fn can be given.",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#crosstable-with-one-column-per-year",
    "href": "slides/x4-pipes-intro.html#crosstable-with-one-column-per-year",
    "title": "x4-Pipelines in R",
    "section": "Crosstable with one column per year",
    "text": "Crosstable with one column per year\n\n\nelbe_wide &lt;-  elbe |&gt;\n  pivot_wider(id_cols = doy, \n              names_from = year, \n              values_from = discharge, \n              values_fn = mean)\nelbe_wide\n\n\nExercise\n\nCreate a suitable crosstable elbe_wide.\nThen create a crosstable for monthly maximum discharge over all years.",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#back-conversion-of-a-crosstable-into-a-data-base-table",
    "href": "slides/x4-pipes-intro.html#back-conversion-of-a-crosstable-into-a-data-base-table",
    "title": "x4-Pipelines in R",
    "section": "Back-conversion of a crosstable into a data base table",
    "text": "Back-conversion of a crosstable into a data base table\n\nThe inverse case is also possible, e.g. the conversion of a cross table into a data base table. It can be done with the function pivot_longer. The column of the id.vars variable(s) will become identifier(s) downwards.\n\n\npivot_longer(elbe_wide, names_to=\"year\", cols=as.character(1989:2019))\n\n\nExercise\nTry it yourself.",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#minimum-maximum-plot-with-summarize-and-ggplot2",
    "href": "slides/x4-pipes-intro.html#minimum-maximum-plot-with-summarize-and-ggplot2",
    "title": "x4-Pipelines in R",
    "section": "Minimum-Maximum plot with summarize and ggplot2",
    "text": "Minimum-Maximum plot with summarize and ggplot2\n\nelbe |&gt; \n  mutate(doy = yday(date)) |&gt;\n  group_by(doy) |&gt;\n  summarize(max = max(discharge), \n            mean = mean(discharge), \n            min = min(discharge)) |&gt;\n  pivot_longer(cols = c(\"min\", \"mean\", \"max\"), \n               names_to = \"statistic\", \n               values_to = \"discharge\") |&gt;\n  ggplot(aes(doy, discharge, color = statistic)) + geom_line()\n\n\nExercise\n\nRead the code and try to understand it. Then add a dry and a wet year.",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#cumulative-sums",
    "href": "slides/x4-pipes-intro.html#cumulative-sums",
    "title": "x4-Pipelines in R",
    "section": "Cumulative sums",
    "text": "Cumulative sums\nAnnual cumulative sum plots are a hydrological standard tool used by reservoir managers. We can use the R function cumsum, that by successive cumulation converts a sequence of:\n\\(x_1, x_2, x_3, x_4, \\dots\\)\ninto\n\\((x_1), (x_1+x_2), (x_1+x_2+x_3), (x_1+x_2+x_3+x_4), \\dots\\)\n\nExample\n\nx &lt;- c(1, 3, 2, 6, 4, 2, 3)\ncumsum(x)\n\n[1]  1  4  6 12 16 18 21",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#cumulative-sums-of-the-elbe-river",
    "href": "slides/x4-pipes-intro.html#cumulative-sums-of-the-elbe-river",
    "title": "x4-Pipelines in R",
    "section": "Cumulative sums of the Elbe River",
    "text": "Cumulative sums of the Elbe River\nCummulative sums allow to detect dry and wet years, or periods within years.\nIf we just use cumsum, we get a cumulative sum for all years:\n\nelbe |&gt; \n  mutate(doy = yday(date), year = year(date)) |&gt;\n  filter(year %in% 2000:2010) |&gt;\n  group_by(year = factor(year)) |&gt;\n  mutate(cum_discharge = cumsum(discharge) * 60*60*24) |&gt;\n  ggplot(aes(doy, cum_discharge, color = year)) + geom_line()\n\n\nThe multiplication with \\(60 \\cdot 60 \\cdot 24\\) converts \\(\\rm m^3 s^{-1}\\) in \\(\\rm m^3 d^{-1}\\).",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#exercises",
    "href": "slides/x4-pipes-intro.html#exercises",
    "title": "x4-Pipelines in R",
    "section": "Exercises",
    "text": "Exercises\n\n\nRepeat the same for other time periods (years).\nWhich year was the wettest, which one the driest year in total? Find a year with dry spring and wet summer.\nIdentify some (e.g. 3 or 5) large floods in the historical time series and plot it together.\nModify the commands so that the hydrological year is shown. Note that the German hydrological year goes from 1st November to 31st October of the following year. Other countries have different regulations.",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#further-reading",
    "href": "slides/x4-pipes-intro.html#further-reading",
    "title": "x4-Pipelines in R",
    "section": "Further reading",
    "text": "Further reading\n\nOnline material\n\n“Welcome to tidyverse: https://dplyr.tidyverse.org/.\n“ggplot Elegant Graphics for Data Analysis: https://ggplot2-book.org/\n“R for Data Science”: https://r4ds.had.co.nz/\nHadley Wickham’s homepage: https://hadley.nz/\n\n\nPrinted books\n\n“R for Data Science” (Wickham, Çetinkaya-Rundel, et al., 2023)\n“ggplot Elegant Graphics for Data Analysis” (Wickham, 2016)",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "slides/x4-pipes-intro.html#references",
    "href": "slides/x4-pipes-intro.html#references",
    "title": "x4-Pipelines in R",
    "section": "References",
    "text": "References\n\n\n\n\nBache, S. M., & Wickham, H. (2022). Magrittr: A forward-pipe operator for r. https://CRAN.R-project.org/package=magrittr\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H., Çetinkaya-Rundel, M., & Grolemund, G. (2023). R for data science (2nd ed.). O’Reiley. https://r4ds.hadley.nz/\n\n\nWickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). Dplyr: A grammar of data manipulation. https://CRAN.R-project.org/package=dplyr",
    "crumbs": [
      "Selected Programming Topics",
      "x4-Pipelines in R"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Elemente der statistischen Datenanalyse und Statistik mit R",
    "section": "",
    "text": "Diese Website enthält eine Sammlung von Materialien für einführende Statistikkurse mit R. Das Ziel ist es, einen Einblick in grundlegende Prinzipien zu geben und einen Einstieg zu vermitteln, um weiterführende Fachbücher und Online-Materialien auswählen und verstehen zu können und so tiefer in das vielfältige und faszinierende Gebiet des “Statistical Computing” einzusteigen.\nDie Auswahl der Themen spiegelt meine persönliche Erfahrung wider, als Türöffner zu Themen, die für die Ökologie und die Hydrowissenschaften nützlich sind. Es handelt sich um ein forlaufendes Projekt, basierend auf früheren PDF-Folien und anderem Kursmaterial.\nDie deutschsprachige Version ist eine Übersetzung aus dem englischen. Für die Korrektheit wird keine Gewähr übernommen. Konstruktive Kommentare und Verbesserungsvorschläge sind willkommen.\nDie dazugehörigen Übungsaufgaben befinden sich unter: https://tpetzoldt.github.io/element-labs/."
  },
  {
    "objectID": "index.html#weiterführende-literatur",
    "href": "index.html#weiterführende-literatur",
    "title": "Elemente der statistischen Datenanalyse und Statistik mit R",
    "section": "Weiterführende Literatur",
    "text": "Weiterführende Literatur\n\nDalgaard, P, 2008: Introductory Statistics with R. Springer Verlag, New York, 2nd edition. https://link.springer.com/book/10.1007/b97671\nKleiber, C and Zeileis, A, 2008: Applied Econometrics with R. Springer Verlag, New York. https://link.springer.com/book/10.1007/978-0-387-77318-6\nVerzani, J, 2014: Using R for introductory statistics. CRC press. https://www.routledge.com/Using-R-for-Introductory-Statistics/Verzani/p/book/9781466590731\nWickham, H., Çetinkaya-Rundel, M and Grolemund, G, 2023: R for Data Science. https://r4ds.hadley.nz/"
  },
  {
    "objectID": "index.html#querverweise",
    "href": "index.html#querverweise",
    "title": "Elemente der statistischen Datenanalyse und Statistik mit R",
    "section": "Querverweise",
    "text": "Querverweise\n\nElements of Data Analysis and Statistics (englische Version)\nÜbungen: Collection of lab exercises (englisch)\nDatasets\nQuelltexte der Folien: deutsch, englisch"
  },
  {
    "objectID": "index.html#autor",
    "href": "index.html#autor",
    "title": "Elemente der statistischen Datenanalyse und Statistik mit R",
    "section": "Autor",
    "text": "Autor\nhomepage +++ github\n2025-11-05"
  }
]