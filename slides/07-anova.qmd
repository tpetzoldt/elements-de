---
title: "07-ANOVA und ANCOVA"
date:   "`r Sys.Date()`"
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library("dplyr")
library("tidyr")
library("kableExtra")
library("car")
mypar <- list(las=1, cex.lab=1.4, cex.axis=1.4, lwd=2)
```


## ANOVA - Varianzanalyse

<br>

* Prüfung komplexer Hypothesen als Ganzes, z.B.:
    * mehr als zwei Stichproben (Mehrfachtestproblem),
    * mehrere multiple Faktoren (Mehrfach- ANOVA)
    * Eliminierung von Kovariaten (ANCOVA)
    * feste und/oder zufällige Effekte
    (Varianzzerlegung, Modelle mit gemischten Effekten)
* Unterschiedliche Anwendungsszenarien:
    * explorative Anwendung: Welche Einflussfaktoren sind wichtig?
    * Signifikanztests
    * statistische Modellierung: Quantifizierung von Effekten und Abhängigkeiten.
* ANOVA-Verfahren basieren (meistens) auf linearen Modellen.


## Ein Praxisbeispiel


::: {.column width="49%"}

[Suche nach einem geeigneten Medium für Wachstumsexperimente mit Grünalgen]{.darkred}

* Schulprojekt aus "Jugend Forscht"
* geeignet für Kurse in Schule und Studium
* preisgünstig, einfach zu handhaben

:::

::: {.column width="49%"}
![](../img/ansaetze.jpg)

:::

**Idee**

* Verwendung eines kommerziellen Düngers mit den Hauptnährstoffen N und P
* Mineralwasser mit Spurenelementen
* Enthält stilles Mineralwasser genügend $\mathrm{CO_2}$?
* testen, wie man die Verfügbarkeit von $\mathrm{CO_2}$ für die Photosynthese verbessern kann


## Anwendung

<br>

**7 Verschiedene Behandlungen**

<br>

1. Düngemittellösung in geschlossenen Flaschen 
2. Düngemittellösung in offenen Flaschen ($\mathrm{CO_2}$ aus der Luft)
3. Düngemittel + Zucker (organische C-Quelle)
4. Dünger + zusätzliches $\mathrm{HCO_3^-}$ (Zusatz von $\mathrm{CaCO_3}$ zu sprudelndem Mineralwasser)
5. Standard-Algenwachstumsmedium („Basalmedium“) zum Vergleich
6. Deionisiertes („destilliertes“) Wasser und 
7. Leitungswasser zum Vergleich


## Versuchsaufbau


![](../img/ruettler.jpg){fig-align="center" fig-alt="Flaschen mit Algenkulturen auf einem Schüttler"}

* jede Behandlung mit 3 Wiederholungen
* randomisierte Platzierung auf dem Schüttler
* 16:8 Licht:Dunkel-Zyklus
* Transmissionsmessung direkt in den Flaschen mit einem selbstgebauten [Messgerät](https://tpetzoldt.github.io/growthlab/doc/versuchsaufbau.html)

## Ergebnisse


<div class="vbox"></div>
<div class="hbox">
![](../img/ansaetze2.jpg)
Dünger -- offene Flasche -- + Zucker -- + CaCO3 -- Basalmedium -- A. dest -- Leitungswasser
</div>


## Der Datensatz

<br>

```{r, echo=FALSE}
algae <- data.frame(
  treat  = factor(c("Fertilizer", "Fertilizer", "Fertilizer", 
             "F. open", "F. open", "F. open", 
             "F.+sugar", "F.+sugar", "F.+sugar", 
             "F.+CaCO3", "F.+CaCO3", "F.+CaCO3", 
             "Bas.med.", "Bas.med.", "Bas.med.", 
             "A.dest", "A.dest", "A.dest", 
             "Tap water", "Tap water"),
             levels=c("Fertilizer", "F. open", "F.+sugar", 
                    "F.+CaCO3", "Bas.med.", "A.dest", "Tap water")),
  rep   = c(1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2), 
  growth = c(0.02, -0.217, -0.273, 0.94, 0.78, 0.555, 0.188, -0.1, 0.02, 
             0.245, 0.236, 0.456, 0.699, 0.727, 0.656, -0.01, 0, -0.01, 0.03, -0.07)
)

xalgae <- 
  algae |> 
  pivot_wider(id_cols = treat, names_from = rep, values_from = growth, names_prefix = "replicate ")
```


```{r}
#| label: tbl-algae-growth

xalgae |>
  kable('html') |> 
  kable_styling(bootstrap_options = "striped", full_width = FALSE)
```

* Wachstum von Tag 2 bis Tag 6 (relative Einheiten)
* [NA]{.red} bedeutet „nicht verfügbar“, d.h. ein fehlender Wert
* Die Kruztabelle ist kompakt und übersichtlich, jedoch nicht ideal für die Datenanalyse.
* $\Rightarrow$ Konvertierung in das Langformat


## Daten im Langformat

::: {.column width="59%"}

<br>

### Vorteile

* sieht „unpraktisch“ aus, ist aber viel besser für die Datenanalyse
* abhängige Variable **Wachstum** und <br>Erklärungsvariable **Behandlung** deutlich sichtbar
* Modellformel: `growth ~ treat`
* leicht erweiterbar auf $>1$ Erklärungsvariable

:::


::: {.column width="39%"}
```{r}
algae |> 
  head(12) |>
  kable('html') |>
  kable_styling(bootstrap_options = c("striped"), full_width = FALSE)
```
:::


## Die Daten in R

<br>

```{r, echo=TRUE}
algae <- data.frame(
  treat  = factor(c("Fertilizer", "Fertilizer", "Fertilizer", 
             "F. open", "F. open", "F. open", 
             "F.+sugar", "F.+sugar", "F.+sugar", 
             "F.+CaCO3", "F.+CaCO3", "F.+CaCO3", 
             "Bas.med.", "Bas.med.", "Bas.med.", 
             "A.dest", "A.dest", "A.dest", 
             "Tap water", "Tap water"),
             levels=c("Fertilizer", "F. open", "F.+sugar", 
                    "F.+CaCO3", "Bas.med.", "A.dest", "Tap water")),
  rep   = c(1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2), 
  growth = c(0.02, -0.217, -0.273, 0.94, 0.78, 0.555, 0.188, -0.1, 0.02, 
             0.245, 0.236, 0.456, 0.699, 0.727, 0.656, -0.01, 0, -0.01, 0.03, -0.07)
)
```

<br>

* Kleine Datensätze können direkt in den Code eingebunden werden. 
* Eine csv-Datei im Langformat ist ebenfalls möglich.
* Wichtig: `treat` als Faktor (nominale Variable).
* Mit `levels` kann man die Reihenfolge fixieren.


## Boxplot

```{r algae-boxplot, echo=TRUE}
boxplot(growth ~ treat, data = algae)
abline(h = 0, lty = "dashed", col = "grey")
```

## Streifendiagramm

```{r algae-stripchart, echo=TRUE}
stripchart(growth ~ treat, data = algae, vertical = TRUE)
```
Besser als Boxplot, denn wir haben nur 2-3 Wiederholungen. Boxplot braucht mehr.


## Umwandlung einer wissenschaftlichen Frage in eine statistische Hypothese

<br>

**Wissenschaftliche Fragen**

* Sind die Behandlungen unterschiedlich?
* Welches Medium ist das beste?
* Ist das beste Medium signifikant besser als die anderen?
* Wieviel besser ist das beste Medium (Efektstärke)?

<br>
**Statistische Hypothesen**

* $H_0$: das Wachstum ist bei allen Behandlungen gleich
* $H_A$: Unterschiede zwischen den Medien

## Warum nicht einfach mehrere t-Tests?

<br>

* Wenn wir bei 7 Behandlungen jede gegen jede testen wollen, brauchen wir:

$$7 \cdot (7 - 1) / 2 = 21 \qquad\text{Tests.}$$

* Bei $\alpha = 0.05$, erhält man 5% falsch positive Ergebnisse.<br> $\Rightarrow$ [Einer]{.red} von 20 Tests ist im Durchschnitt [falsch positiv]{.red}.
* Bei $N$ Tests erhöht sich der Gesamtfehler von $\alpha$ im schlimmsten Fall auf $N\cdot\alpha$.
* Dies wird **alpha-Fehler-Inflation** oder **Bonferroni-Ungleichung** genannt:

$$
\alpha_{total} \le \sum_{i=1}^{N} \alpha_i = N \cdot \alpha
$$


Wird die Regel ignoriert, erhält man zufällige falsch-positive Ergebnisse (*statistical fishing*).

# Lösungsansätze

:::{.bigfont}
1. Korrektur der Alpha-Fehler, so dass $\alpha_{total} = 0.05$ bleibt;<br>
$\rightarrow$ Bonferroni-Regel.
2. Verfahren, das das Gesamtproblem behandelt:<br>
$\rightarrow$ ANOVA.
:::

## ANOVA: Varianzanalyse

<br>

**Grundgedanke**

* Aufteilung der Gesamtvarianz in Wirkung(en) und Fehler:


:::{.bigfont}
$$
s_y^2 = s^2_\mathrm{effect} + s^2_{\varepsilon}
$$
:::

* Etwas überraschend: Analyse von Varianzen, um Mittelwerte zu vergleichen. 
* **Erklärung:** Mittelwertunterschiede tragen zur Gesamtvarianz der ganzen Stichprobe bei. 
* Die Varianzkomponenten können als **Varianz innerhalb** ($s^2_\varepsilon$) und **Varianz zwischen** Stichproben bezeichnet werden.
* Die Varianz-Zerlegung erfolgt über ein [lineares Modell]{.blue}.

## Beispiel

<br>

Zwei Marken von Clementinen aus einem Geschäft „E“, die wir als „EB“ und „EP“ bezeichnen.
Wir wollen wissen, ob die Premiummarke („P“) und die Basismarke („B“) ein unterschiedliches Gewicht haben.


```{r, echo=TRUE, eval=TRUE}
clem <- data.frame(
  brand = c("EP", "EB", "EB", "EB", "EB", "EB", "EB", "EB", "EB", "EB", "EB", 
            "EB", "EB", "EB", "EP", "EP", "EP", "EP", "EP", "EP", "EP", "EB", "EP"),
  weight = c(88, 96, 100, 96, 90, 100, 92, 92, 102, 99, 86, 89, 99, 89, 75, 80, 
             81, 96, 82, 98, 80, 107, 88))
```

<br>
Wir kodieren eine Stichprobe („EB“) mit 1 und die andere Stichprobe („EP“) mit 2: 


```{r, echo=TRUE, eval=TRUE}
clem$code <- as.numeric(factor(clem$brand))
clem$code
```

## Dann wird eine lineare Regression angewandt


```{r eb-ep-linear, echo=TRUE, eval=TRUE}
plot(weight ~ code, data = clem, axes = FALSE)
m <- lm(weight ~ code, data = clem)
axis(1, at = c(1,2), labels = c("EB", "EP")); axis(2); box()
abline(m, col = "blue")
```




## Lineares Modell und Varianzkomponenten

<br>


```{r eval=FALSE, echo=TRUE}
m <- lm(weight ~ code, data = clem)
```


**Gesamtvarianz**

```{r, echo=TRUE}
(var_tot <- var(clem$weight))
```

**Restvarianz** (= Varianz innerhalb der Behandlungen)

```{r, echo=TRUE}
(var_res <- var(residuals(m)))
```

**Erklärte Varianz** (= Varianz zwischen den Behandlungen)

```{r, echo=TRUE}
var_tot - var_res
```
<br>

* Das Beispiel zeigt das Grundprinzip.
* **Aber:**  Die „erklärte Varianz“ ist nicht für den F-Test der ANOVA geeignet, weil die [Freiheitsgrade]{.red} nicht berücksichtigt sind.

## Korrekte Berechnung mit Freiheitsgraden

```{r, echo=TRUE}
# Freiheitsgrade
n <- nrow(clem)
k <- length(unique(clem$brand))

df_total     <- n - 1      # -1 df für den Gesamtmittelwert (Intercept)
df_between   <- k - 1      # df für Gruppenunterschiede (nach Berücksichtigung des Gesamtmittelwerts)
df_residuals <- n - k      # -1 df pro Gruppe (insgesamt k Gruppen)
# Prüfung: df_total sollte gleich df_between + df_residuals sein
c(n = n, k = k, df_total = df_total, df_between = df_between, df_residuals = df_residuals)



# Sums of squares
SS_total     <- var_tot * df_total
SS_residuals <- var_res * df_total  # var(residuals) nutzt n−1
SS_between   <- SS_total - SS_residuals

# Mean sums of squares
MS_between   <- SS_between / df_between
MS_residuals <- SS_residuals / df_residuals
c(MS_between = MS_between, MS_residuals = MS_residuals)

# F-Test
F_stat <- MS_between / MS_residuals
p_val  <- pf(F_stat, df1 = df_between, df2 = df_residuals, lower.tail = FALSE)

c(F = round(F_stat, 3), p = round(p_val, 4))
```
[Die ANOVA arbeitet direkt mit den Summen der Quadrate, ohne den Umweg über die Varianzen.]{.gray .smallfont}

## ANOVA in einem Schritt

```{r, echo=TRUE}
anova(m)
```

<br>

**Ein t-Test zum Vergleich**

```{r, echo=TRUE}
t.test(weight ~ code, data = clem, var.equal=TRUE)
```

$\Rightarrow$ Die p-Werte sind identisch.

* Bei zwei Gruppen ist die ANOVA (F-Test) äquivalent zum t-Test mit gleichen Varianzen.
* $F = t^2$, $p$ gleich.



## ANOVA mit mehr als 2 Stichproben


<br>
Zurück zum Algenwachstums-Experiment:

```{r echo=TRUE}
m <- lm(growth ~ treat, data = algae)
```

<br>

* Wir könnten die Koeffizienten mit `summary(m)` ausgeben.
* Zunächst interessiert uns der Gesamteffekt, daher verwenden wir `anova(m)`.

```{r echo=TRUE}
anova(m)
```

* zeigt den F-Test für den Gesamteffekt des Faktors `treat`.

$\Rightarrow$ Der p-Wert ist sehr klein → der Behandlungseffekt ist signifikant.


## Posthoc-Tests

* Der F-Test zeigte, dass der Faktor „Behandlung“ einen signifikanten Effekt hat.
* Wir wissen jedoch noch nicht, **welche spezifischen Gruppen** sich unterscheiden.
* **Tukey-HSD-Test** (HSD = Honest Significant Difference): am häufigsten verwendeter Post-hoc-Test für ANOVA.  
* vergleicht alle Paare von Gruppen und berücksichtigt die *family-wise error rate*.

```{r, echo=TRUE}
tk <- TukeyHSD(aov(m))
tk
```

## Grafische Darstellung

```{r algae-tukey, echo=TRUE}
par(las = 1)              # Achsenbeschriftungen horizontal
par(mar = c(4, 10, 3, 1)) # mehr Platz für lange Gruppenbezeichnungen
plot(tk)
```



## ANOVA Annahmen und Diagnostik


::: {.column width="49%"}

Für die ANOVA gelten dieselben Annahmen wie für das lineare Modell.

<br>

1. Unabhängigkeit der Fehler
2. Homogenität der Varianzen  (Homoskedastizität)
3. Annähernde Normalverteilung der Fehler

Grafische Diagnostik wird bevorzugt – sie ist robuster als numerische Tests.

:::

::: {.column width="49%"}
```{r algae-diagnostics, echo=TRUE, fig.height=5, fig.width=5}
par(mfrow=c(2, 2))
plot(m)
```
:::



## Test der Varianzhomogenität

<br>

* Der F-Test ist nur für zwei Gruppen geeignet.
* Für mehr als zwei Gruppen: Bartlett-, Levene- oder Fligner-Killeen-Test.
* **Empfohlen:** Fligner-Killeen-Test - robust gegenüber Abweichung von Normalverteilung.


```{r, echo=TRUE}
fligner.test(growth ~ treat, 
             data = algae)
```



## Test auf Normalverteilung

* Teste die **Residuen**, nicht die Rohdaten!
* Der Shapiro-Wilk-Test wird nicht mehr empfohlen:
    - Bei kleinen Stichproben: hohe Wahrscheinlichkeit für Fehlertyp II<br>
    [(keine Ablehnung, obwohl Unterschiede existieren).]{.gray}
    - Bei großen Stichproben: hohe Wahrscheinlichkeit für Fehlertyp I<br>
    [(Ablehnung, obwohl Unterschiede vernachlässigbar sind.)]{.gray}
* **Empfohlen**: Grafische Methoden – insbesondere der **QQ-Plot**.

```{r algae-qqnorm, echo=TRUE, fig.width=6, fig.height=5, fig.align='center'}
qqnorm(residuals(m))
qqline(residuals(m))
```


## Moderne Sichtweise: Keine Vortests mehr!

<br>

Die traditionelle Praxis – Residuen zu testen, **bevor** man ANOVA durchführt – <br>
ist nicht mehr zeitgemäß und führt zu gravierenden Problemen:

- Residuen sind erst nach Modellanpassung verfügbar.
- Bei Vortests müsste man sie „irgendwie vorher“ schätzen, oft durch Pooling.
- Häufig wurden **Rohdaten** statt Residuen getestet - **Kardinalfehler**.
- Die Methode stammt aus der Ära manueller Berechnungen.

**Empfohlene Vorgehensweise:**

1. Prüfe, ob ANOVA grundsätzlich angemessen ist:
    - Fragestellung, 
    - Unabhängigkeit, 
    - mögliche Nichtnormalität auf Grund des Versuchsdesigns
2. Führe die ANOVA durch – ohne Vortests.
3. **Diagnostik im Anschluss** – grafisch und kritisch (QQ-Plot, Residuals vs. Fitted).



## Einfache ANOVA mit heterogenen Varianzen

<br>

* Erweiterung des Welch-Tests für $\ge 2$ Stichproben
* in R `oneway.test` genannt.

```{r, echo=TRUE}
oneway.test(growth ~ treat, data = algae)
```
<br>

* Der `oneway.test` berücksichtigt ungleiche Varianzen durch gewichtete Mittelwerte und Freiheitsgrade und eine angepasste F-Statistik.
* Die Varianzhomogenität ist wichtiger als die Normalverteilung – insbesondere bei unbalancierten Designs.
* Ein Varianzunterschied kann den F-Test stärker verzerren als leichte Abweichungen von der Normalverteilung.

 
## Zweifache ANOVA


```{r}
plants <- data.frame(No=1:12,
  growth     =c(6.6, 7.2, 6.9, 8.3, 7.9, 9.2,
                8.3, 8.7, 8.1, 8.5, 9.1, 9.0),
  fertilizer = rep(c("A", "B", "C"), each=2),
  light      = rep(c("low", "high"), each=6)
)
```


* Beispiel aus einem Statistik-Lehrbuch [@Crawley2002], angewandt auf einen neuen Kontext
* Auswirkungen von Dünger und Licht auf das Wachstum der Pflanzenhöhe in cm pro Zeit

| Dünger     | helles Licht| schwaches Licht|
|------------|-------------|----------------|
| A          | 8.3         | 6.6            |
| A          | 8.7         | 7.2            |
| B          | 8.1         | 6.9            |
| B          | 8.5         | 8.3            |
| C          | 9.1         | 7.9            |
| C          | 9.0         | 9.2            |
|            |             |                |


* faktorielles Experiment (**mit Wiederholungen**)
* für jede Faktorkombination mehr als eine Beobachtung
* Es können Wechselwirkungen identifiziert werden
    
[Falls keine Wiederholungen: Keine Schätzung des Fehlers für Interaktionen - keine Identifizierung von Wechselwirkungen möglich.]{.gray .smallfont}

## Daten im Langformat eingeben

::: {.column width="59%"}

<br><br>

```{r, echo=TRUE}
plants <- data.frame(No = 1:12,
                    growth = c(6.6, 7.2, 6.9, 8.3, 7.9, 9.2,
                               8.3, 8.7, 8.1, 8.5, 9.1, 9.0),
                    fert   = rep(c("A", "B", "C"), each=2),
                    light  = rep(c("low", "high"), each=6)
          )
```
:::

::: {.column width="39%"}

```{r}
plants %>% 
  kable('html') %>% 
  kable_styling(bootstrap_options = c("striped"), full_width = FALSE)
```

:::

## Beispiele für Modellformeln

| Modell Typ                              | Formel                                              |
|-----------------------------------------|-----------------------------------------------------|
| Nullmodell                              | `y ~ 1`                                             |
| Einfache lineare Regression             | `y ~ x`                                             |
| Linear ohne Achsenschnittpunkt          | `y ~ x - 1`                                         |
| Multiple Regression, keine Interaktion  | `y ~ x1 + x2 + x3`                                  |
| Multiple Regression mit Interaktion     | `y ~ x1 * x2 * x3`                                  |
| ... ohne 3-fache Interaktion            | `y ~ x1 * x2 * x3 - x1 : x2 : x3`                   |
| Transformiert mit `I()` ('as is')       | `y ~ x + I(x^2)`                                    |
| Einfache ANOVA                          | `y ~ f`                                             |
| ANOVA mit Interaktion                   | `y ~ f1 * f2`                                       |
| ANCOVA mit Interaktion                  | `y ~ x * f`                                         |
| Verschachtelte ANOVA                    | `y ~ x + (1 | a / b)`                               |
| GAM mit glättendem `s`                  | `y ~ s(x) + f`                                      |
|                                         |                                                     |

* `y` = Antwortvariable (abhängige, target)
* `x` = metrische Erklärungsvariable (Prädiktor, unabhängig)
* `f` = Faktorvariable (nominal)



## Lineares Modell und ANOVA

```{r plants-boxplot, fig.align='center'}
par(mfrow=c(1, 2))
boxplot(growth ~ fert,  data = plants, col = "wheat")
boxplot(growth ~ light, data = plants, col = "wheat")
```

**ANOVA**

```{r, echo=TRUE}
m <- lm(growth ~ light * fert, data = plants)
anova(m)
```

## Interaktionsplot

```{r plants-interaction, echo=TRUE}
with(plants, interaction.plot(fert, light, growth, 
                            col = c("orange", "brown"), lty = 1, lwd = 2))
```

* Wenn die Linien nicht parallel sind, deutet es auf eine Wechselwirkung hin.

## Diagnostik


<br>

1. Unabhängigkeit der Messungen (innerhalb der Gruppen)
2. Homogenität der Varianz der Residuen
3. Normalverteilung der Residuen

<br>
[Der Test der Annahmen benötigt Residuen des angepassten Modells.]{.red} <br></br>
$\Rightarrow$ Passe zuerst das ANOVA-Modell an und prüfe dann, ob es richtig war!

<br>

**Diagnostikinstrumente**

* Boxplot (Gruppenvergleich)  
* Residuen vs. Fitted
* Q-Q-Diagramm der Residuen  
* Fligner-Killeen-Test (von manchen wird alternativ der Levene-Test empfohlen)

## Diagnostik II

```{r plants-diagnostics, echo=TRUE, fig.align='center'}
par(mfrow=c(1, 2))
par(cex=1.2, las=1)
qqnorm(residuals(m))
qqline(residuals(m))

plot(residuals(m)~fitted(m))
abline(h=0)
```  

```{r, echo=TRUE}  
fligner.test(growth ~ interaction(light, fert), data=plants)
```

Residuen: sehen in Ordnung aus und der p-Wert des Fligner-Tests ist noch ok. 

## Anmerkungen

<br>

**Lineare Regression oder ANOVA?**

* Im Wesentlichen dasselbe Modell - nur unterschiedliche Sichtweise
* Metrische unabhängige Variablen → lineares Modell  
* Nominalskalierte unabhängige Variablen (Faktoren) → ANOVA  
* Mischung aus beidem → ANCOVA

**Pre-Tests sind theoretisch und praktisch fragwürdig**

1. Eine Nullhypothese $H_0$ kann **nicht bestätigt**, sondern nur verworfen werden.  
2. Bei großen Stichproben ist die Normalität der Residuen **nicht zwingend erforderlich**.
3. Wenn $p$ in der Nähe des Schwellenwerts liegt und der Stichprobenumfang klein ist, bleiben wir im Ungewissen.


* All dies lässt sich nur durch sorgfältiges Nachdenken, Erfahrung und kritische Reflexion überwinden.
* Es ist immer eine gute Idee, die Ergebnisse mit anderen zu besprechen -- nicht nicht um die Entscheidung zu delegieren, sondern um sie zu **verstehen und zu verteidigen**.


## Sequentielles Holm-Bonferroni-Verfahren

* Auch bekannt als Holm-Korrektur [@Holm1979]
* Einfach zu verwenden
* Kann auf jedes Problem mit Mehrfachtests angewendet werden
* Weniger konservativ als die normale Bonferroni-Korrektur, aber ...
* ... immer noch ein sehr konservativer Ansatz
* siehe auch [Wikipedia](https://en.wikipedia.org/wiki/Holm%E2%80%93Bonferroni_method)

**Algorithmus**

1. Wähle den kleinsten $p$-Wert aus allen $n$ $p$-Werten
2. Wenn $p \cdot n < \alpha$ $\Rightarrow$ signifikant, sonst <bf>STOPP</bf>
3. Setze $n - 1 \rightarrow n$, entferne das kleinste $p$ aus der Liste und gehe zu Schritt 1.

<br>

Der Algorithmus ist **sequenziell**

* Er prüft die Hypothesen in der Reihenfolge der kleinsten $p$-Werte.

## Beispiel

<br>

Wachstumsrate pro Tag ($d^{-1}$) von Blaualgenkulturen (*Pseudanabaena*) nach Zugabe toxischer Peptide einer anderen Blaualge (*Microcystis*).

Die ursprüngliche Hypothese:

* Microcystin LR (MCYST) oder ein Derivat davon (Substanz A) hemmt das Wachstum.

<br>

```{r, echo=TRUE}
mcyst <-  data.frame(treat = factor(c(rep("Control", 5),
                                       rep("MCYST", 5),
                                       rep("Subst A", 5)),
                                levels=c("Control", "MCYST", "Subst A")),
                      mu   = c(0.086, 0.101, 0.086, 0.086, 0.099,
                               0.092, 0.088, 0.093, 0.088, 0.086,
                               0.095, 0.102, 0.106, 0.106, 0.106)
                     )
```

## Ansatz 1: einfache ANOVA

```{r mcyst-tukey, echo=TRUE}
par(mar=c(4, 8, 2, 1), las=1)
m <- lm(mu ~ treat, data=mcyst)
anova(m)
plot(TukeyHSD(aov(m)))
```

## Ansatz 2: multiple t-Tests mit sequentieller Bonferroni-Korrektur

Wir trennen den Datensatz in einzelne Teilmengen:

```{r, echo=TRUE}
Control <- mcyst$mu[mcyst$treat == "Control"]
MCYST   <- mcyst$mu[mcyst$treat == "MCYST"]
SubstA  <- mcyst$mu[mcyst$treat == "Subst A"]
```

und führen 3 t-Tests durch:

```{r, echo=TRUE}
p1 <- t.test(Control, MCYST)$p.value
p2 <- t.test(Control, SubstA)$p.value
p3 <- t.test(MCYST, SubstA)$p.value
```

p-Werte ohne Korrektur:

```{r, echo=TRUE}
c(p1, p2, p3)
```

Mit Holm-Korrektur:

```{r, echo=TRUE}
p.adjust(c(p1, p2, p3))
```

## Schlussfolgerungen


**Statistische Methoden**

* Beim Holm-korrigierten t-Test bleibt nur ein einziger p-Wert (MCYST vs. Subst A) signifikant, bei der ANOVA sind es zwei.
* ANOVA berücksichtigt Struktur der Daten und die Abhängigkeit der Vergleiche.
* Holm-Methode konservativer als TukeyHSD $\Rightarrow$ ANOVA + Posthoc ist zu bevorzugen.


**Interpretation hinsichtlich der ursprünglichen Hypothese**

* MCYST und Subst A hemmen das Wachstum von *Pseudanabaena* nicht.
* Im Gegenteil: Subst A **stimuliert** das Wachstum.
* Widerspruch zur Erwartung: der biologische Grund wurde 10 Jahre später entdeckt.

* **Wichtig**: Statistische Signifikanz sagt nichts über die biologische Relevanz aus.
* Falsche Hypothesen können zu falschen Erwartungen führen - oder zu neuen Entdeckungen.

Mehr dazu in @Jahnichen2001, @Jahnichen2007, @Jahnichen2011, @Zilliges2011, @Dziallas2011, @Wei2024


## ANCOVA


**Statistische Frage**

* Vergleich von Regressionslinien zwischen Gruppen
* Ähnlich wie bei der ANOVA, enthält aber auch **metrische** Variablen (Kovariaten)
* Haben Gruppen unterschiedliche **Anfangswerte** (Intercept) und/oder unterschiedliche **Steigungen** (Slope)?


**Beispiel**

```{r dobson-lines, echo=FALSE, fig.align='center'}
## Daten zum Geburtsgewicht siehe stats/demo/lm.glm.R
dobson <- data.frame(
  week = c(40, 38, 40, 35, 36, 37, 41, 40, 37, 38, 40, 38,
	 40, 36, 40, 38, 42, 39, 40, 37, 36, 38, 39, 40),
  weight = c(2968, 2795, 3163, 2925, 2625, 2847, 3292, 3473, 2628, 3176,
	    3421, 2975, 3317, 2729, 2935, 2754, 3210, 2817, 3126, 2539,
	    2412, 2991, 2875, 3231),
  gender = gl(2, 12, labels=c("M","F"))
)
plot(weight ~ week, data = dobson, col=c("blue", "red")[as.numeric(gender)], pch=16)
fem <- lm(weight ~ week, data = dobson, subset = gender=="F")
mal <- lm(weight ~ week, data = dobson, subset = gender=="M")
abline(fem, col = "red")
abline(mal, col = "blue")
```

Annette Dobsons Geburtsgewichts-Daten -- aus einem Statistik-Lehrbuch [@Dobson2013]: Geburtsgewicht von Jungen und Mädchen in Abhängigkeit von der Schwangerschaftswoche.


## Der Datensatz zum Geburtsgewicht

<br>

Dieser Datensatz ist künstlich – nicht realistisch, aber ideal für die Demonstration.

Er ist in der R-Demo `demo(lm.glm)` enthalten.

<br>

```{r echo=TRUE, eval=FALSE}
## Daten zum Geburtsgewicht siehe stats/demo/lm.glm.R
dobson <- data.frame(
  week   = c(40, 38, 40, 35, 36, 37, 41, 40, 37, 38, 40, 38,
             40, 36, 40, 38, 42, 39, 40, 37, 36, 38, 39, 40),
  weight = c(2968, 2795, 3163, 2925, 2625, 2847, 3292, 3473, 2628, 3176,
             3421, 2975, 3317, 2729, 2935, 2754, 3210, 2817, 3126, 2539,
             2412, 2991, 2875, 3231),
  gender = gl(2, 12, labels = c("M", "F")) # generate factor levels
)
```


## Warum nicht einfach einen t-Test durchführen?


```{r dobson-boxplot, fig.align='center', echo=TRUE}
boxplot(weight ~ gender,data = dobson, ylab = "weight")
t.test(weight ~ gender, data = dobson, var.equal = TRUE)
```

* Der t-Test zeigt keine signifikante Differenz und der Boxplot zeigt starke Überlappung.
* Aber: Der t-Test ignoriert die Schwangerschaftswoche, eine wichtige Kovariate.


## ANCOVA: Berücksichtigung der Kovariate


```{r, echo=TRUE}
m <- lm(weight ~ week * gender, data = dobson)
anova(m)
```

```{r dobson-ancova, echo=FALSE, fig.align='center'}
plot(weight ~ week, data=dobson, col=c("blue","red")[as.numeric(gender)], pch=16)
p <- coef(m)
abline(a=p[1], b=p[2], col="red")
abline(a=p[1]+p[3], b=p[2]+p[4], col="blue")

fem <- lm(weight ~ week, data=dobson, subset = gender=="F")
mal <- lm(weight ~ week, data=dobson, subset = gender=="M")
#abline(fem, col="black", lty="dashed")
#abline(mal, col="black", lty="dashed")
```

[Beispiel: Aus Gründen, die wir später besprechen, muss die Kovariate `week` als erstes in der Modellformel stehen.]{.gray}


# Tücken der ANOVA/ANCOVA 

## Bisher beschriebene Tücken von ANOVA und ANCOVA

<br>

1. Heterogenität der Varianz
    * p-Werte können verzerrt sein (d.h. irreführend oder falsch)
    * Verwendung einer einfachen ANOVA für ungleiche Varianzen (in R: `oneway.test`)
2. Unbalanzierter Fall
    * Ungleiche Anzahl von Stichproben für jede Faktorkombination
    * $\rightarrow$ ANOVA-Ergebnisse sind von der Reihenfolge der Faktoren in der Modellformel abhängig.
    * Klassische Lösung: Typ II oder Typ III ANOVA
    * Moderner Ansatz: Modellselektion und Likelihood-Ratio-Tests


## Typ II und Typ III ANOVA

<br><br>

* Funktion `Anova` (mit Großbuchstabe `A`) im Paket **car**
* Hilfeseite der Funktion `Anova`:

> Type-II tests are calculated according to the principle of marginality, testing each term after all others, except ignoring the term's higher-order relatives; so-called type-III tests violate marginality, testing each term in the model after all of the others.

* Schlussfolgerung: Verwende Typ II und nicht Typ III. 
* Interpretiere **keine einzelnen Haupteffekte**, wenn eine signifikante Wechselwirkung vorliegt.

## Typ II ANOVA: Beispiel


```{r plants-boxplot-ancova, echo=FALSE, fig.height=3}
par(mar=c(4.1, 5.1, 1.1, 1.1))
par(cex=1.2, las=1)
par(mfrow=c(1,2))
boxplot(growth~fert, data=plants, col="wheat", xlab="fert", ylab="growth")
boxplot(growth~light, data=plants, col="wheat", xlab="light")
```


```{r, echo=TRUE}
library("car")
m <- lm(growth ~ light * fert, data = plants)
Anova(m, type="II")
```


# Modellselektion - <br> ein Paradigmenwechsel

## Modellkandidaten und Auswahl eines optimalen Modells

<br>

**Problem:**

* Bei komplexen ANOVA-Modellen hängen die p-Werte von der Anzahl (und manchmal von der Reihenfolge) der einbezogenen Faktoren und Wechselwirkungen ab.
* Der H~0~-basierte Ansatz wird eventuell verwirrend, z.B. wegen widersprüchlicher p-Werte.

**Alternativer Ansatz:**

* Modellselektion -- nutzt das Prinzip der Parsimonie

Es werden verschiedene Modellkandidaten verglichen:

* Modell mit allen potentiellen Effekten → [vollständiges Modell]{.blue}
* Weglassen einzelner Faktoren → [reduzierte Modelle]{.blue} (mehrere!)
* Keine Einflussfaktoren (nur Mittelwert) → [Nullmodell]{.blue}
* Welches Modell ist das beste? → [minimales adäquates Modell]{.darkred}

## Wie können wir messen, welches Modell das beste ist?

<br>

Kompromiss zwischen Modellanpassung und Modellkomplexität (Anzahl der
Parameter, k).

* Güte der Anpassung: Likelihood L -- wie gut die Daten zu einem bestimmten Modell passen.
* Log Likelihood: macht das Kriterium additiv.
* AIC (Akaike Information Criterion):

$$AIC = −2 \ln(L) + 2k$$

* BIC ( Bayesian Information Criterion), berücksichtigt den Stichprobenumfang ($n$):

$$BIC = −2 \ln(L) + k \cdot \ln(n)$$

Das Modell mit dem kleinsten AIC (oder BIC) ist das [minimal adäquate]{.darkred} Modell.



## Modellselektion und Likelihood-Ratio-Tests

<br>

**Ansatz**

1. Mehrere Modelle einzeln anpassen
2. Modelle paarweise mit ANOVA (Likelihood Ratio Test) vergleichen

**Daten und Beispiel**

```{r, echo=TRUE}
plants <- data.frame(No=1:12,
                   growth=c(6.6, 7.2, 6.9, 8.3, 7.9, 9.2,
                            8.3, 8.7, 8.1, 8.5, 9.1, 9.0),
                   fert= rep(c("A", "B", "C"), each=2),
                   light= rep(c("low", "high"), each=6)
                   )
```

```{r, echo=TRUE}
m3 <- lm(growth ~ fert * light, data=plants)  # f1 + f2 + f1:f2
m2 <- lm(growth ~ fert + light, data=plants)  # f1 + f2
anova(m3, m2)
```

* Likelihood-Ratio-Test vergleicht zwei Modelle (`anova` in R mit > 1 Modell)
* Modell mit Interaktion (`m3`) nicht signifikant besser als Modell ohne Interaktion (`m2`).

## AIC-basierte Modellselektion


* Der paarweise Modellvergleich ist umständlich, insbesondere bei einer großen Anzahl von Modellen.
* **Lösung:** Erstelle eine Menge von Kandidatenmodellen
* Verwende [kleinstes AIC]{.blue}, um das [minimal angemessene]{.blue} Modell auszuwählen.

```{r, echo=TRUE}
m3  <- lm(growth ~ light * fert, data = plants) # Gesamtmodell
m2  <- lm(growth ~ light + fert, data = plants)
m1a <- lm(growth ~ fert, data = plants)
m1b <- lm(growth ~ light, data = plants)
m0  <- lm(growth ~ 1, data = plants)            # Nullmodell

AIC(m0, m1a, m1b, m2, m3)
```
**Anmerkungen**

* AIC-Werte sind [bis zu einer additiven Konstante definiert]{.blue}
* $\rightarrow$ Absolute Werte können je nach Software oder Methode variieren.
* $\Rightarrow$ Betrachte die Differenzen, nicht die absoluten Werte.
* Faustregel: die „AIC-Einheit“ ist 2, Unterschiede $\approx$ 2.0 $\rightarrow$ geringe Bedeutung

## Schrittweise Modellselektion (automatisch)


::: {.column width="45%"}
Automatische Modellselektion
```{r, echo=TRUE}
m1 <- lm(growth ~ fert * light, data=plants)
opt <- step(m1)
```
[Modell mit dem kleinsten AIC $\rightarrow$ optimales Modell.]{.smallfont}
:::

:::  {.column width="8%"}

:::

::: {.column width="45%"}
Zum Vergleich: klassische ANOVA
```{r, echo=TRUE}
anova(opt)
```
:::


**Ergebnisse des Beispiels:** 

* optimales Modell (`opt`), enthält beide Faktoren (`fert`, `light`), aber keine Interaktion.
* Die Modellselektion identifiziert `fert` und `light` als wichtige Erklärungsvariablen.
* im Gegensatz zur klassischen ANOVA-Tabelle, in der nur `light` signifikant war, zeigt die Modellselektion, dass auch `fert` zur Erklärung beiträgt.


## Signifikanztests vs. Modellselektion

<br>

* Das Konzept der Modellselektion ersetzt die p-Wert-basierte Statistik, zumindest teilweise.
* Einige Autoren raten davon ab, p-Werte in diesem Kontext noch zu verwenden.
* Andere empfehlen einen Kompromiss: p-Werte als **Hilfsmittel**, nicht als Entscheidungskriterium.

**Derzeitige Empfehlung** 

Wenn p-Werte benötigt werden, vergleiche das optimale Modell mit reduzierten Modellen:

```{r, eval = FALSE, echo=TRUE}
anova(m2, m1a) # fert
anova(m2, m1b) # light
```

* Interpretiere p-Werte mit Vorsicht:
    - Sie sind abhängig von der Modellstruktur.
    - Sie können irreführend sein, wenn das Modell nicht optimal ist.
* Gib auch Effektstärken und Vertrauensintervalle an!


## Zusammenfassung des Kapitels ANOVA

* Lineare Modelle bilden die **Grundlage** für viele statistische Methoden
    * Lineare Regression
    * ANOVA/ANCOVA anstelle von Mehrfachtests
    * MANOVA, GLM, GAM, GLMM, . . .
* ANOVA ist **leistungsfähiger** als Mehrfachtests:
    * vermeidet [$\alpha$-Fehlerinflation]{.blue}
    * identifiziert [Interaktionseffekte]{.blue}
    * eliminiert [Kovariate]{.blue}
    * ein großes Experiment benötigt [weniger Stichprobengröße]{.blue} als viele kleine Experimente
* Modellselektion vs. p-Wert-basierte Tests
    * **Paradigmenwechsel**: AIC anstelle von p-Werten
    * zuverlässiger, besonders bei unausgewogenen oder komplexen Designs
    * erweiterbar auf GLM, GAM, LME, GLMM, ...
    * aber: p-Wert-basierte Tests sind manchmal leichter zu verstehen

**Selbststudium:** Lies das Paper von @JohnsonOmland2004 zum Thema Modellselektion.

## Vermeide Manipulation von p-Werten

<br>

**Experimente NICHT wiederholen, bis ein signifikanter p-Wert gefunden wird!**

<br>

@Leek2017 in **Nature**:

> “... Nature asked influential statisticians to recommend one change to improve science.
> The common theme? The problem is not our maths, but ourselves.”:

**Five ways to fix statistics. Comment on Nature**

1. Jeff Leek: Adjust for human cognition
2. Blakeley B. McShane & Andrew Gelman: Abandon statistical significance
3. David Colquhoun: State false-positive risk, too
4. Michèle B. Nuijten: Share analysis plans and results
5. Steven N. Goodman: Change norms from within

<br>



## The "ASA Statement ..." 

<br>

Das **ASA Statement on Statistical Significance and P-Values** der American Statistical Association [@ASA2016] befasst sich mit der Bedeutung des p-Werts, ohne ihn komplett in Frage zu stellen. Es definiert 6 Prinzipien:

::: {style="background-color: #dddddd"}
1. P-values can indicate how incompatible the data are with a specified statistical model.
2. P-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone.
3. Scientific conclusions and business or policy decisions should not be based only on whether a p-value passes a specific threshold.
4. Proper inference requires full reporting and transparency.
5. A p-value, or statistical significance, does not measure the size of an effect or the importance of a result.
6. By itself, a p-value does not provide a good measure of evidence regarding a model or hypothesis.
:::

Die Details sind im Statement weiter ausgeführt.

**Selbststudium:** Lies dazu neben @ASA2016 auch @Hurlbert2019.

<!--
**Hurlbert und andere empfehlen, dem Begriff „signifikant“ den „Coup de Grâce“ zu geben.**  
  
Ich stimme dieser Kritik grundsätzlich zu:  

 - p-Werte werden missverstanden  
 - Signifikanz ist kein Maß für Bedeutung  
 - Die Kultur des "p < 0.05" führt zu Manipulation und Verzerrung  
  
Dennoch habe ich mich entschieden, den Begriff weiter zu lehren: **als historisches und praktisches Werkzeug**.  
  
Warum?

- Er ist immer noch weit verbreitet in der Literatur  
- Studierende müssen ihn verstehen, um Forschung zu lesen  
- Aber: Wir lehren ihn **kritisch**, mit klaren Grenzen und Alternativen  
  
**Ziel: Nicht „p < 0.05“ zu lehren, sondern: „Was sagt mir dieser p-Wert wirklich?“**
-->

## Literaturverzeichnis
