---
title: "07-One and two-way ANOVA"
subtitle: "Applied Statistics -- A Practical Course" 
date:   "`r Sys.Date()`"
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library("dplyr")
library("tidyr")
library("kableExtra")
library("car")
mypar <- list(las=1, cex.lab=1.4, cex.axis=1.4, lwd=2)
```


## ANOVA - Analyse der Varianzen

<br>

* Prüfung komplexer Hypothesen als Ganzes, z.B.:
    * mehr als zwei Stichproben (Problem des Mehrfachtests),
    * mehrere multiple Faktoren (multiway ANOVA)
    * Eliminierung von Kovariaten (ANCOVA)
    * feste und/oder zufällige Effekte
    (Varianzzerlegungsmethoden, Modelle mit gemischten Effekten)
* Verschiedene Anwendungsszenarien:
    * explorative Anwendung: Welche Einflussfaktoren sind wichtig?
    * deskriptive Anwendung: Anpassen von Modellen zur Prozessbeschreibung und Vorhersage.
    * Signifikanztests.
* ANOVA-Methoden basieren (in den meisten Fällen) auf linearen Modellen.



## Ein praxisbezogenes Beispiel


::: {.column width="49%"}

[Suche nach einem geeigneten Medium für Wachstumsexperimente mit Grünalgen]{.darkred}

* billig, einfach zu handhaben
* geeignet für Schülerkurse und Experimente im Unterricht

:::

::: {.column width="49%"}
![](../img/ansaetze.jpg)

:::

**Idee**

* Verwendung eines kommerziellen Düngers mit den Hauptnährstoffen N und P
* Mineralwasser mit Spurenelementen
* Enthält Mineralwasser ohne Kohlensäure genügend $\mathrm{CO_2}$?
* testen, wie man die Verfügbarkeit von $\mathrm{CO_2}$ für die Photosynthese verbessern kann


## Anwendung

<br>

**7 Verschiedene Behandlungen**

<br>

1. Düngemittellösung in geschlossenen Flaschen 
2. Düngemittellösung in offenen Flaschen ($\mathrm{CO_2}$ aus der Luft)
3. Düngemittel + Zucker (organische C-Quelle)
4. Dünger + zusätzliches $\mathrm{HCO_3^-}$ (Zusatz von $\mathrm{CaCO_3}$ zu sprudelndem Mineralwasser)
5. ein Standard-Algenwachstumsmedium („Basalmedium“) zum Vergleich
6. deionisiertes („destilliertes“) Wasser und 
7. Leitungswasser zum Vergleich


## Versuchsaufbau



![](../img/ruettler.jpg){fig-align="center" fig-alt="bottles with algae on a shaker"}

* jede Behandlung mit 3 Wiederholungen
* zufällige Platzierung auf einem Schüttler
* 16:8 Licht:Dunkel-Zyklus
* Messung direkt in den Flaschen mit einem selbstgebauten [Trübungsmessgerät](https://tpetzoldt.github.io/growthlab/doc/versuchsaufbau.html)

## Ergebnisse


<div class="vbox"></div>
<div class="hbox">
![](../img/ansaetze2.jpg)
Dünger -- Offene Flasche-- D. + Zucker -- D. + CaCO3 -- Basalmedium -- A. dest -- Leitungswasser
</div>


## Der Datensatz

<br>

```{r, echo=FALSE}
algae <- data.frame(
  treat  = factor(c("Fertilizer", "Fertilizer", "Fertilizer", 
             "F. open", "F. open", "F. open", 
             "F.+sugar", "F.+sugar", "F.+sugar", 
             "F.+CaCO3", "F.+CaCO3", "F.+CaCO3", 
             "Bas.med.", "Bas.med.", "Bas.med.", 
             "A.dest", "A.dest", "A.dest", 
             "Tap water", "Tap water"),
             levels=c("Fertilizer", "F. open", "F.+sugar", 
                    "F.+CaCO3", "Bas.med.", "A.dest", "Tap water")),
  rep   = c(1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2), 
  growth = c(0.02, -0.217, -0.273, 0.94, 0.78, 0.555, 0.188, -0.1, 0.02, 
             0.245, 0.236, 0.456, 0.699, 0.727, 0.656, -0.01, 0, -0.01, 0.03, -0.07)
)

xalgae <- 
  algae |> 
  pivot_wider(id_cols = treat, names_from = rep, values_from = growth, names_prefix = "replicate ")
```


```{r}
#| label: tbl-algae-growth
#| tbl-cap: "Wachstum von Tag 2 bis Tag 6 (relative Einheiten)"

xalgae |>
  kable('html') |> 
  kable_styling(bootstrap_options = "striped", full_width = FALSE)
```

* [NA]{.red} bedeutet „nicht verfügbar“, d.h. ein fehlender Wert
* Die Crosstable-Struktur ist kompakt und leicht zu lesen, aber nicht ideal für die Datenanalyse.
* $\Rightarrow$ konvertiere sie in ein Long-Format


## Daten im Long-Format

::: {.column width="59%"}

<br>

### Vorteile

* sieht „blöd“ aus, ist aber besser für die Datenanalyse
* abhängige Variable **Wachstum** und <br>Erklärungsvariable **Behandlung** deutlich sichtbar
* Modellformel: `growth ~ treat`
* leicht erweiterbar auf $>1$ Erklärungsvariable

:::


::: {.column width="39%"}
```{r}
algae |> 
  head(12) |>
  kable('html') |>
  kable_styling(bootstrap_options = c("striped"), full_width = FALSE)
```
:::


## Die Daten in R

<br><br>

```{r, echo=TRUE}
algae <- data.frame(
  treat  = factor(c("Fertilizer", "Fertilizer", "Fertilizer", 
             "F. open", "F. open", "F. open", 
             "F.+sugar", "F.+sugar", "F.+sugar", 
             "F.+CaCO3", "F.+CaCO3", "F.+CaCO3", 
             "Bas.med.", "Bas.med.", "Bas.med.", 
             "A.dest", "A.dest", "A.dest", 
             "Tap water", "Tap water"),
             levels=c("Fertilizer", "F. open", "F.+sugar", 
                    "F.+CaCO3", "Bas.med.", "A.dest", "Tap water")),
  rep   = c(1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2), 
  growth = c(0.02, -0.217, -0.273, 0.94, 0.78, 0.555, 0.188, -0.1, 0.02, 
             0.245, 0.236, 0.456, 0.699, 0.727, 0.656, -0.01, 0, -0.01, 0.03, -0.07)
)
```

... können direkt in den Code eingegeben werden. Eine csv-Datei im Long-Format ist ebenfalls möglich.

## Boxplot

```{r algae-boxplot, echo=TRUE}
boxplot(growth ~ treat, data = algae)
abline(h = 0, lty = "dashed", col = "grey")
```

## Streifendiagramm

```{r algae-stripchart, echo=TRUE}
stripchart(growth ~ treat, data = algae, vertical = TRUE)
```
Besser, denn wir haben nur 2-3 Wiederholungen. Boxplot braucht mehr.


## Umwandlung einer wissenschaftlichen Frage in eine statistische Hypothese

<br>

**Wissenschaftliche Fragen**

* Sind die Behandlungen unterschiedlich?
* Welches Medium ist das beste?
* Ist das beste Medium signifikant besser als die anderen?

<br>
**Statistische Hypothesen**

* $H_0$: das Wachstum ist bei allen Behandlungen gleich
* $H_A$: Unterschiede zwischen den Medien

## Warum können wir nicht einfach mehrere t-Tests anwenden?

<br>

* Wenn wir 7 Behandlungen haben und alle gegeneinander testen wollen, brauchen wir:

$$7 \cdot (7 - 1) / 2 = 21 \qquad\text{Tests.}$$

* Wenn wir $\alpha = 0,05$ setzen, erhalten wir 5% falsch positive Ergebnisse. $\Rightarrow$ [Einer]{.red} von 20 Tests ist im Durchschnitt ein [falsch positiver]{.red}
* Wenn wir $N$ Tests durchführen, erhöht sich der Gesamtfehler von $\alpha$ im schlimmsten Fall auf $N\cdot\alpha$.
* Dies wird **alpha-Fehler-Inflation** oder das **Bonferroni-Gesetz** genannt:

$$
\alpha_{total} \le \sum_{i=1}^{N} \alpha_i = N \cdot \alpha
$$


Wenn wir das Bonferroni-Gesetz ignorieren, landen wir beim **statistischen Fischen** und erhalten zufällige falsche Ergebnisse.

# Lösungen

:::{.bigfont}
1. Korrigiere die Alpha-Fehler nach unten, so dass $\alpha_{total} = 0,05$. $\rightarrow$ Bonferroni-Regel.
2. Verwende eine Methode, die alle Tests gleichzeitig durchführt: die ANOVA.
:::

## ANOVA: Analyse der Varianzen

<br>

**Grundgedanke**

* Aufteilung der Gesamtvarianz in Wirkung(en) und Fehler:


:::{.bigfont}
$$
s_y^2 = s^2_\mathrm{effect} + s^2_{\varepsilon}
$$
:::

* Etwas überraschend: Wir verwenden Varianzen, um Mittelwerte zu vergleichen. 
* **Erklärung:** Mittelwertunterschiede tragen zur Gesamtvarianz der ganzen Stichprobe bei. 
* Die Varianzkomponenten können als **Varianz innerhalb** ($s^2_\varepsilon$) und **Varianz zwischen** Stichproben bezeichnet werden.
* Die Art und Weise, wie man die Varianzen trennt, ist ein [lineares Modell]{.blue}.

## Beispiel

<br>

Zwei Marken von Clementinenfrüchten aus einem Geschäft „E“, die wir als „EB“ und „EP“ kodieren.
Wir wollen wissen, ob die Premiummarke („P“) und die Basismarke („B“) ein unterschiedliches Gewicht haben.


```{r, echo=TRUE, eval=TRUE}
clem <- data.frame(
  brand = c("EP", "EB", "EB", "EB", "EB", "EB", "EB", "EB", "EB", "EB", "EB", 
            "EB", "EB", "EB", "EP", "EP", "EP", "EP", "EP", "EP", "EP", "EB", "EP"),
  weight = c(88, 96, 100, 96, 90, 100, 92, 92, 102, 99, 86, 89, 99, 89, 75, 80, 
             81, 96, 82, 98, 80, 107, 88))
```

<br>
Wir kodieren eine Stichprobe („EB“) mit 1 und die andere Stichprobe („EP“) mit 2: 


```{r, echo=TRUE, eval=TRUE}
clem$code <- as.numeric(factor(clem$brand))
clem$code
```

## Dann wird eine lineare Regression angewandt:


```{r eb-ep-linear, echo=TRUE, eval=TRUE}
plot(weight ~ code, data = clem, axes = FALSE)
m <- lm(weight ~ code, data = clem)
axis(1, at = c(1,2), labels = c("EB", "EP")); axis(2); box()
abline(m, col = "blue")
```




## Varianzkomponenten

<br>

Wir passen ein lineares Modell an und vergleichen die Varianzen:

```{r eval=FALSE, echo=TRUE}
m <- lm(weight ~ code, data = clem)
```


**Gesamtvarianz**

```{r, echo=TRUE}
(var_tot <- var(clem$weight))
```

**Restvarianz (= innere Varianz)**

```{r, echo=TRUE}
(var_res <- var(residuals(m)))
```

**Erklärte Varianz (= Zwischenvarianz)**

```{r, echo=TRUE}
var_tot - var_res
```
Nun können wir analysieren, ob die Zwischenvarianz groß genug ist, um einen signifikanten Effekt zu begründen. 

Dies nennt man eine ANOVA.

## ANOVA

```{r, echo=TRUE}
anova(m)
```

<br>

**Ein t-Test zum Vergleich**

```{r, echo=TRUE}
t.test(weight ~ code, data = clem, var.equal=TRUE)
```

$\Rightarrow$ die p-Werte sind genau gleich.



## ANOVA mit mehr als 2 Stichproben


Zurück zu den Daten über das Algenwachstum. Nennen wir das lineare Modell „m“:

```{r echo=TRUE}
m <- lm(growth ~ treat, data = algae)
```

<br>

* Wir können die Koeffizienten des linearen Modells mit `summary(m)` ausgeben.
* Wir interessieren uns aber für den Gesamteffekt und verwenden `anova`.

```{r echo=TRUE}
anova(m)
```

* Die ANOVA-Tabelle zeigt F-Tests, die die Signifikanz aller Faktoren prüfen.
* In der obigen Tabelle haben wir nur einen einzigen Faktor.

$\Rightarrow$ Wir sehen, dass die Behandlung einen signifikanten Effekt hat.


## Posthoc-Tests


* Der Test zeigte, dass der **Faktor** „Behandlung“ einen signifikanten Effekt hatte.
* Wir wissen noch nicht, welche **Faktorlevel** unterschiedlich waren. 

Der **Tukey-HSD-Test** ist der häufigste.

```{r, echo=TRUE}
tk <- TukeyHSD(aov(m))
tk
```

## Grafische Darstellung

```{r algae-tukey, echo=TRUE}
par(las = 1)             # las = 1 macht y-Anmerkung horizontal
par(mar = c(4, 10, 3, 1)) # mehr Platz auf der linken Seite für Achsenbeschriftungen
plot(tk)
```



## ANOVA Annahmen und Diagnosen



::: {.column width="49%"}

Für die ANOVA gelten dieselben Annahmen wie für das lineare Modell.

<br>

1. Unabhängigkeit von Fehlern
2. Homogenität der Varianz
3. Annähernde Normalität der Fehler

Grafische Überprüfungen werden bevorzugt.

:::

::: {.column width="49%"}
```{r algae-diagnostics, echo=TRUE, fig.height=5, fig.width=5}
par(mfrow=c(2, 2))
plot(m)
```
:::

## Numerische Tests

<br><br>

::: {.column width="49%"}

**Test der Varianzhomogenität**

* Der F-Test vergleicht nur zwei Varianzen.
* Verschiedene Tests für multiple Varianzen, z.B. Bartlett, Levene, Fligner-Killeen
* Empfohlen: Fligner-Killeen-Test

```{r, echo=TRUE}
fligner.test(growth ~ treat, 
             data = algae)
```

:::

::: {.column width="49%"}
**Test der Normalverteilung**

* Der Shapiro-Wilks-Test kann irreführend sein.
* Verwende eine grafische Methode!

```{r algae-qqnorm, echo=TRUE, fig.width=6, fig.height=3}
qqnorm(residuals(m))
qqline(residuals(m))
```

:::


## Einseitige ANOVA mit heterogenen Varianzen

<br><br>

* Erweiterung des Welch-Tests für $\ge 2$ Stichproben
* in R genannt `oneway.test`

```{r, echo=TRUE}
oneway.test(growth ~ treat, data = algae)
```


## Zweiseitige ANOVA


```{r}
plants <- data.frame(No=1:12,
  growth     =c(6.6, 7.2, 6.9, 8.3, 7.9, 9.2,
                8.3, 8.7, 8.1, 8.5, 9.1, 9.0),
  fertilizer = rep(c("A", "B", "C"), each=2),
  light      = rep(c("low", "high"), each=6)
)
```


* Beispiel aus einem Statistik-Lehrbuch [@Crawley2002], angewandt auf einen neuen Kontext
* Auswirkungen von Dünger und Lichtregime auf das Wachstum der Pflanzenhöhe in cm pro Zeit

| Dünger     | helles Licht| schwaches Licht|
|------------|-------------|----------------|
| A          | 8.3         | 6.6            |
| A          | 8.7         | 7.2            |
| B          | 8.1         | 6.9            |
| B          | 8.5         | 8.3            |
| C          | 9.1         | 7.9            |
| C          | 9.0         | 9.2            |
|            |             |                |


* faktorielles Experiment (**mit Wiederholungen**): jede Faktorkombination hat mehr als eine Beobachtung.
* ohne Wiederholungen: 
   - keine Wiederholungen pro Faktorkombination
   - dies ist möglich, erlaubt aber keine Identifizierung von Wechselwirkungen

## Daten im Long-Format eingeben

::: {.column width="59%"}

<br><br>

```{r, echo=TRUE}
plants <- data.frame(No = 1:12,
                    growth = c(6.6, 7.2, 6.9, 8.3, 7.9, 9.2,
                               8.3, 8.7, 8.1, 8.5, 9.1, 9.0),
                    fert   = rep(c("A", "B", "C"), each=2),
                    light   = rep(c("low", "high"), each=6)
          )
```
:::

::: {.column width="39%"}

```{r}
plants %>% 
  kable('html') %>% 
  kable_styling(bootstrap_options = c("striped"), full_width = FALSE)
```

:::

## Beispiele für Modellformeln

| Modell Typ                              | Formel                                            |
|-----------------------------------------|-----------------------------------------------------|
| Nullmodell                              | `y ~ 1`                                             |
| Einfache lineare Regression             | `y ~ x`                                             |
| Lineares Modell ohne Achsenschnittpunkt | `y ~ x - 1`                                         |
| Multiple Regression, keine Interaktion  | `y ~ x1 + x2 + x3`                                  |
| Multiple Regression mit Interaktion     | `y ~ x1 * x2 * x3`                                  |
| Multiple Regression, keine 3-fache Interaktion  | `y ~ x1 * x2 * x3 - x1 : x2 : x3`                   |
| Transformiert mit 'as is' Funktion      | `y ~ x + I(x^2)`                                    |
| Einseitige ANOVA                        | `y ~ f`                                             |
| ANOVA mit Interaktion                   | `y ~ f1 * f2`                                       |
| ANCOVA mit Interaktion                  | `y ~ x * f`                                         |
| Verschachtelte ANOVA                    | `y ~ x + (1 | a / b)`                               |
| GAM mit glättendem `s`                  | `y ~ s(x) + f`                                      |
|                                         |                                                     |

* `y` = Antwortvariable (abhängig, Ziel)
* `x` = metrische Erklärungsvariable (Prädiktor, unabhängig)
* `f` = Faktorvariable (nominal)



## Lineares Modell und ANOVA

```{r plants-boxplot, fig.align='center'}
par(mfrow=c(1, 2))
boxplot(growth ~ fert,  data = plants, col = "wheat")
boxplot(growth ~ light, data = plants, col = "wheat")
```

**ANOVA**

```{r, echo=TRUE}
m <- lm(growth ~ light * fert, data = plants)
anova(m)
```

## Interaktionsplot

```{r plants-interaction, echo=TRUE}
with(plants, interaction.plot(fert, light, growth, 
                            col = c("orange", "brown"), lty = 1, lwd = 2))
```

## Diagnostik


**Annahmen**

1. Unabhängigkeit der Messungen (innerhalb von Stichproben)
2. Homogenität der Varianz der Residuen
3. Normalverteilung der Residuen

<br>
[Der Test der Annahmen benötigt Residuen des angepassten Modells.]{.red} <br></br>
$\Rightarrow$ Passe zuerst das ANOVA-Modell an und prüfe dann, ob es richtig war!

<br>

**Diagnoseinstrumente**

* Boxplot
* Plot der Residuen im Vergleich zu den Mittelwerten
* Q-Q-Diagramm der Residuen
* Fligner-Killeen-Test (alternativ: von manchen wird der Levene-Test empfohlen)

## Diagnostik II

```{r plants-diagnostics, echo=TRUE, fig.align='center'}
par(mfrow=c(1, 2))
par(cex=1.2, las=1)
qqnorm(residuals(m))
qqline(residuals(m))

plot(residuals(m)~fitted(m))
abline(h=0)
```  

```{r, echo=TRUE}  
fligner.test(growth ~ interaction(light, fert), data=plants)
```

Residuen: sehen in Ordnung aus und der p-Wert des Fligner-Tests $> 0,05$, $\rightarrow$ sieht gut aus. 

## Anmerkungen

**Lineare Regression oder ANOVA?**

* im Wesentlichen dasselbe
* unabhängige Variablen sind **metrisch**: lineares Modell
* unabhängige Variablen sind nominal (= Faktor): ANOVA
* Mischung aus metrischen und nominalen Variablen: ANCOVA

**Verwendung von Pre-Tests**

Pre-Tests sind im Allgemeinen aus theoretischen Gründen fragwürdig:

1. Die Nullhypothesen $H_0$ können nur verworfen und nicht endgültig bestätigt werden. 
2. Wenn der Stichprobenumfang groß ist, ist die Normalität der Residuen nicht erforderlich
3. Wenn $p$ in der Nähe des Schwellenwerts liegt und der Stichprobenumfang klein ist, bleiben wir im Ungewissen.



All dies lässt sich nur durch sorgfältiges Nachdenken und mit etwas Erfahrung überwinden.

Es ist immer eine gute Idee, die Ergebnisse mit Kollegen und Vorgesetzten zu besprechen.

## Sequentielles Holm-Bonferroni-Verfahren

* Auch Holm-Verfahren genannt [@Holm1979]
* Einfach zu verwenden
* Kann auf jedes Problem mit Mehrfachtests angewendet werden
* Weniger konservativ als die normale Bonferroni-Korrektur, aber ...
* ... immer noch ein sehr konservativer Ansatz
* siehe auch [Wikipedia](https://en.wikipedia.org/wiki/Holm%E2%80%93Bonferroni_method)

**Algorithmus**

1. Wähle den kleinsten $p$-Wert aus allen $n$ $p$-Werten
2. Wenn $p \cdot n < \alpha$ $\Rightarrow$ signifikant, sonst <bf>STOPP</bf>
3. Setze $n - 1 \rightarrow n$, entferne das kleinste $p$ aus der Liste und gehe zu Schritt 1.


## Beispiel

<br>

Wachstumsrate pro Tag ($d^{-1}$) von Blaualgenkulturen (*Pseudanabaena*) nach Zugabe toxischer Peptide einer anderen Blaualge (*Microcystis*).

Die ursprüngliche Hypothese war, dass Microcystin LR (MCYST) oder ein Derivat davon (Substanz A) das Wachstum hemmt.

<br>

```{r, echo=TRUE}
mcyst <-  data.frame(treat = factor(c(rep("Control", 5),
                                       rep("MCYST", 5),
                                       rep("Subst A", 5)),
                                levels=c("Control", "MCYST", "Subst A")),
                      mu   = c(0.086, 0.101, 0.086, 0.086, 0.099,
                               0.092, 0.088, 0.093, 0.088, 0.086,
                               0.095, 0.102, 0.106, 0.106, 0.106)
                     )
```

## Ansatz 1: einseitige ANOVA

```{r mcyst-tukey, echo=TRUE}
par(mar=c(4, 8, 2, 1), las=1)
m <- lm(mu ~ treat, data=mcyst)
anova(m)
plot(TukeyHSD(aov(m)))
```

## Ansatz 2: multiple t-Tests mit sequentieller Bonferroni-Korrektur

Wir trennen den Datensatz in einzelne Teilmengen:

```{r, echo=TRUE}
Control <- mcyst$mu[mcyst$treat == "Control"]
MCYST   <- mcyst$mu[mcyst$treat == "MCYST"]
SubstA  <- mcyst$mu[mcyst$treat == "Subst A"]
```

und führen 3 t-Tests durch:

```{r, echo=TRUE}
p1 <- t.test(Control, MCYST)$p.value
p2 <- t.test(Control, SubstA)$p.value
p3 <- t.test(MCYST, SubstA)$p.value
```

Im Folgenden sind die rohen p-Werte ohne Korrektur dargestellt:

```{r, echo=TRUE}
c(p1, p2, p3)
```

... und mit Holm-Korrektur:

```{r, echo=TRUE}
p.adjust(c(p1, p2, p3))
```

## Schlussfolgerungen


**Statistische Methoden**

* Im Falle der Holm-korrigierten t-Tests bleibt nur ein einziger p-Wert (MCYST vs. Subst A) signifikant. 
Dies zeigt, dass die Holm-Methode in diesem Fall konservativer ist als TukeyHSD (nur ein signifikanter Effekt im Vergleich zu zwei signifikanten).
* Eine ANOVA mit Posthoc-Test ist im Allgemeinen vorzuziehen,
* aber die sequentielle Holm-Bonferroni-Methode kann in besonderen Fällen hilfreich sein. 
* Außerdem zeigt es deutlich, dass massive Mehrfachtests vermieden werden müssen.

$\Rightarrow$ ANOVA ist zu bevorzugen, wenn möglich.

**Interpretation**

* Hinsichtlich unserer ursprünglichen Hypothese können wir feststellen, dass MCYST und SubstA das Wachstum von *Pseudanabaena* nicht hemmen. Vielmehr stimulierte SubstA das Wachstum.
* Dies widersprach unseren Erwartungen - der biologische Grund wurde dann 10 Jahre später gefunden.

Mehr dazu ist zu finden in @Jahnichen2001, @Jahnichen2007, @Jahnichen2011, @Zilliges2011 oder @Dziallas2011.


## ANCOVA


**Statistische Frage**

* Vergleich von Regressionslinien
* Ähnlich wie bei der ANOVA, enthält aber auch **metrische** Variablen (Kovariaten)


**Beispiel**

Annette Dobsons Daten zum Geburtsgewicht. Ein Datensatz aus einem Statistik-Lehrbuch [@Dobson2013], Geburtsgewicht von Jungen und Mädchen in Abhängigkeit von der Schwangerschaftswoche.

```{r dobson-lines, echo=FALSE}
## Daten zum Geburtsgewicht siehe stats/demo/lm.glm.R
dobson <- data.frame(
  week = c(40, 38, 40, 35, 36, 37, 41, 40, 37, 38, 40, 38,
	 40, 36, 40, 38, 42, 39, 40, 37, 36, 38, 39, 40),
  weight = c(2968, 2795, 3163, 2925, 2625, 2847, 3292, 3473, 2628, 3176,
	    3421, 2975, 3317, 2729, 2935, 2754, 3210, 2817, 3126, 2539,
	    2412, 2991, 2875, 3231),
  gender = gl(2, 12, labels=c("M","F"))
)
plot(weight ~ week, data = dobson, col=c("blue", "red")[as.numeric(gender)], pch=16)
fem <- lm(weight ~ week, data = dobson, subset = gender=="F")
mal <- lm(weight ~ week, data = dobson, subset = gender=="M")
abline(fem, col = "red")
abline(mal, col = "blue")
```

## Der Datensatz zum Geburtsgewicht

<br>

Der Datensatz ist an verschiedenen Stellen im Internet und in verschiedenen Versionen zu finden.

Hier die Version, die in einer R-Demo zu finden ist: `demo(lm.glm)`

```{r echo=TRUE, eval=FALSE}
## Daten zum Geburtsgewicht siehe stats/demo/lm.glm.R
dobson <- data.frame(
  week = c(40, 38, 40, 35, 36, 37, 41, 40, 37, 38, 40, 38,
	 40, 36, 40, 38, 42, 39, 40, 37, 36, 38, 39, 40),
  weight = c(2968, 2795, 3163, 2925, 2625, 2847, 3292, 3473, 2628, 3176,
	    3421, 2975, 3317, 2729, 2935, 2754, 3210, 2817, 3126, 2539,
	    2412, 2991, 2875, 3231),
  gender = gl(2, 12, labels=c("M", "F"))
)
```

<br>

Anmerkung: Dies ist ein künstlicher Datensatz, nicht die Realität.

<!------------------------------------------------------------------------------
## Linear regression, ANOVA and ANCOVA


* ANCOVA (analysis of covariance) deals with the comparison of regression lines
* Simply speaking, we can distinguish the following:
    * independent variables have metric scale: linear regression
    * independent variables all nominal (factor): ANOVA
    * independent variables are mixed nominal and metric: ANCOVA
    
For the linear models discussed so far, the **dependent** variable is always 
metric, while binary or nominal dependent variables can be handled with generalized
linear models (GLM).
------------------------------------------------------------------------------->

## Anette Dobsons Daten zum Geburtsgewicht

Warum nicht einfach einen t-Test durchführen?

```{r dobson-boxplot, fig.align='center', echo=TRUE}
boxplot(weight ~ gender,data = dobson, ylab = "weight")
t.test(weight ~ gender, data = dobson, var.equal = TRUE)
```

Der Boxplot zeigt viele Überschneidungen, und der Unterschied ist nicht signifikant, weil der t-Test wichtige Informationen außer Acht lässt: die Schwangerschaftswoche.


## ANCOVA verwendet Kovariaten


```{r, echo=TRUE}
m <- lm(weight ~ week * gender, data = dobson)
anova(m)
```

```{r dobson-ancova, echo=FALSE, fig.align='center'}
plot(weight ~ week, data=dobson, col=c("blue","red")[as.numeric(gender)], pch=16)
p <- coef(m)
abline(a=p[1], b=p[2], col="red")
abline(a=p[1]+p[3], b=p[2]+p[4], col="blue")

fem <- lm(weight ~ week, data=dobson, subset = gender=="F")
mal <- lm(weight ~ week, data=dobson, subset = gender=="M")
abline(fem, col="black", lty="dashed")
abline(mal, col="black", lty="dashed")
```

<!---------------------
## How this works

```{r, echo=TRUE, eval=FALSE}
plot(weight ~ week, data=dobson, col=c("blue","red")[as.numeric(gender)], pch=16)

#summary(m)
p <- coef(m)

## lines fitted by the ANCOVA
abline(a=p[1],      b=p[2],      col="red")
abline(a=p[1]+p[3], b=p[2]+p[4], col="blue")

## the result is the same as when we would fit separate linear models
fem <- lm(weight ~ week, data=dobson, subset = gender=="F")
mal <- lm(weight ~ week, data=dobson, subset = gender=="M")
abline(fem, col="black", lty="dashed")
abline(mal, col="black", lty="dashed")
```
--------------------------->

# Tücken der ANOVA/ANCOVA 

## Bisher beschriebene Tücken von ANOVA und ANCOVA

<br>

1. Heterogenität der Varianz
    * p-Werte können verzerrt sein (d. h. irreführend oder falsch)
    * Verwendung einer einseitigen ANOVA für ungleiche Varianzen (in R: `oneway.test`)
2. Unausgeglichener Fall:<br>
  Ungleiche Anzahl von Stichproben für jede Faktorkombination<br>
 $\rightarrow$ Die Ergebnisse der ANOVA hängen von der Reihenfolge der Faktoren in der Modellformel ab.
    * Klassische Methode: Typ II oder Typ III ANOVA
    * Moderner Ansatz: Modellauswahl und Likelihood-Ratio-Tests


## Typ II und Typ III ANOVA

<br>

* Funktion `Anova` (mit Großbuchstabe `A`) im Paket **car**
* Hilfsdatei der Funktion `Anova`:

> „Typ-II-Tests werden nach dem Prinzip der 
> Marginalität berechnet, wobei jeder Term nach allen anderen getestet wird, 
> ohne die Verwandten höherer Ordnung zu berücksichtigen;  so genannte Typ-III-Tests verletzen
> die Marginalität, indem sie jeden Term im Modell nach allen anderen testen.“

* Schlussfolgerung: Verwende Typ II und nicht Typ III. 
* Versuche nicht, einzelne Terme im Falle signifikanter Wechselwirkungen zu interpretieren.

## Typ II ANOVA: Beispiel


```{r plants-boxplot-ancova, echo=FALSE, fig.height=3}
par(mar=c(4.1, 5.1, 1.1, 1.1))
par(cex=1.2, las=1)
par(mfrow=c(1,2))
boxplot(growth~fert, data=plants, col="wheat", xlab="fert", ylab="growth")
boxplot(growth~light, data=plants, col="wheat", xlab="light")
```


```{r, echo=TRUE}
library("car")
m <- lm(growth ~ light * fert, data = plants)
Anova(m, type="II")
```
# Modellauswahl - <br> ein Paradigmenwechsel

## Auswahl eines optimalen Modells aus einer Menge von Kandidaten

<br>

**Problem:**

* Bei komplexen ANOVA-Modellen hängen die p-Werte von der Anzahl (und manchmal von der Reihenfolge) der einbezogenen Faktoren und Wechselwirkungen ab.
* Der $H_0$-basierte Ansatz wird verwirrend, z.B. wegen widersprüchlicher p-Werte.

**Alternativer Ansatz:**

* Nutzt das Prinzip der Parsimonie

Anstelle von p-Wert-basierten Tests werden verschiedene Modellkandidaten verglichen:

* Modell mit allen potentiellen Effekten → [vollständiges Modell]{.blue}
* Weglassen einzelner Faktoren → [reduzierte Modelle]{.blue} (mehrere!)
* Keine Einflussfaktoren (nur Mittelwert) → [Nullmodell]{.blue}
* Welches Modell ist das beste → [minimales adäquates Modell]{.blue}?

## Wie können wir messen, welches Modell das beste ist?

<br>

Kompromiss zwischen Modellanpassung und Modellkomplexität (Anzahl der
Parameter, k).

* Güte der Anpassung: Likelihood L (misst, wie gut die Daten zu einem bestimmten Modell passen).
* Log Likelihood: macht das Kriterium additiv.
* AIC (Akaike Information Criterion):

$$AIC = −2 \ln(L) + 2k$$

* BIC ( Bayesian Information Criterion), berücksichtigt den Stichprobenumfang ($n$):

$$BIC = −2 \ln(L) + k · \ln(n)$$

Das Modell mit dem kleinsten AIC (oder BIC) ist das [minimal adäquate]{.blue} (d.h. optimale) Modell.



## Modellauswahl und Likelihood-Ratio-Tests


**Ansatz**

1. Mehrere Modelle einzeln anpassen
2. Vergleiche die Modelle paarweise mit ANOVA (Likelihood Ratio Test)

**Daten und Beispiel**

```{r, echo=TRUE}
plants <- data.frame(No=1:12,
                   growth=c(6.6, 7.2, 6.9, 8.3, 7.9, 9.2,
                            8.3, 8.7, 8.1, 8.5, 9.1, 9.0),
                   fert= rep(c("A", "B", "C"), each=2),
                   light= rep(c("low", "high"), each=6)
                   )
```

```{r, echo=TRUE}
m3 <- lm(growth ~ fert * light, data=plants)  # f1 + f2 + f1:f2
m2 <- lm(growth ~ fert + light, data=plants)  # f1 + f2
anova(m3, m2)
```

* Likelihood-Ratio-Test vergleicht zwei Modelle (`anova` mit > 1 Modell)
* Modell mit Interaktion (`m3`) nicht signifikant besser als Modell ohne Interaktion (`m2`).

## AIC-basierte Modellauswahl


* Der paarweise Modellvergleich ist umständlich, insbesondere bei einer großen Anzahl von Modellen.
* **Lösung:** Erstelle eine Menge von Kandidatenmodellen
* Verwende [kleinstes AIC]{.blue}, um das [minimal angemessene]{.blue} Modell auszuwählen.

```{r, echo=TRUE}
m3  <- lm(growth ~ light * fert, data = plants) # Gesamtmodell
m2  <- lm(growth ~ light + fert, data = plants)
m1a <- lm(growth ~ fert, data = plants)
m1b <- lm(growth ~ light, data = plants)
m0  <- lm(growth ~ 1, data = plants)            # Nullmodell

AIC(m0, m1a, m1b, m2, m3)
```
**Anmerkung**

* AIC-Werte sind [bis zu einer additiven Konstante definiert]{.blue}
* $\rightarrow$ absolute Werte unterscheiden sich manchmal, abhängig von der angewandten Methode
* $\Rightarrow$ betrachtet den Bereich des AIC und die Unterschiede, ignoriert die absoluten Werte
* Faustregel: die „AIC-Einheit“ ist 2, Unterschiede $\approx 2.0\rightarrow$ geringe Bedeutung

## Schrittweise Modellauswahl (automatisch)


* Das vollständige Modell wird an die Funktion `step` übergeben:

::: {.column width="49%"}
```{r, echo=TRUE}
m1 <- lm(growth ~ fert * light, data=plants)
opt <- step(m1)
```
* Modell mit dem kleinsten AIC<br> $\rightarrow$ optimales Modell.
:::

::: {.column width="49%"}
```{r, echo=TRUE}
anova(opt)
```

<br><br>

* p < 0.05 <br> $\rightarrow$ signifikant
:::


**Ergebnisse des Beispiels:** 

* optimales Modell (`m2`, `opt`), enthält beide Faktoren `fert` und `light`, aber keine Interaktion.
* Die Modellauswahl hat `fert` und `light` als notwendige erklärende Variablen identifiziert,<br>
im Gegensatz zur klassischen ANOVA-Tabelle, in der nur `light` signifikant ist.


## Signifikanztests?

<br>

* Das Konzept der Modellauswahl überlagert die p-Wert-basierte Statistik.
* Einige Autoren raten generell davon ab, p-Werte in diesem Zusammenhang zu verwenden, andere empfehlen einen Kompromiss.
* Wenn man einen p-Wert erhalten möchte, sollte man das optimale Modell mit weiteren reduzierten Modellen vergleichen, die p-Werte aber dennoch mit Vorsicht interpretieren:

```{r, eval = FALSE, echo=TRUE}
anova(m2, m1a) # fert
anova(m2, m1b) # light
```
* In jedem Fall gilt: Konzentriere dich auf die praktischen Implikationen und vergiss nicht, die Effektgrößen anzugeben!


## Zusammenfassung des Kapitels ANOVA

* Lineare Modelle bilden die Grundlage für viele statistische Methoden.
    * Lineare Regression
    * ANOVA, ANCOVA, GLM, GAM, GLMM, . . .
    * ANOVA/ANCOVA anstelle von Mehrfachtests
* ANOVA ist leistungsfähiger als Mehrfachtests:
    * vermeidet $\alpha$-Fehlerinflation
    * ein großes Experiment benötigt weniger n als viele kleine Experimente
    * Identifizierung von Interaktionseffekten
    * Eliminierung von Kovariaten
* Modellauswahl vs. p-Wert-basierte Tests
    * Paradigmenwechsel in der Statistik: AIC anstelle des p-Wertes
    * zuverlässiger, insbesondere bei unausgewogenen oder komplexen Designs
    * erweiterbar auf generalisierte, additive und gemischte Modelle (GLM, GAM, LME, GLMM, ...)
    * aber: p-Wert-basierte Tests sind manchmal leichter zu verstehen


## Vermeide Manipulation von p-Werten


**Experimente NICHT wiederholen, bis ein signifikanter p-Wert gefunden wird.**

Die hochrangige Zeitschrift „... Nature hat einflussreiche Statistiker gebeten, eine Änderung zur Verbesserung der Wissenschaft zu empfehlen. Das gemeinsame Thema? Das Problem ist nicht unsere Mathematik, sondern wir selbst.“ [(Leek et al. (2017))](https://doi.org/10.1038/d41586-017-07522-z):


**Fünf Wege, Statistiken zu verbessern. Kommentar zur Nature**


1. Jeff Leek: Anpassung an die menschliche Kognition
2. Blakeley B. McShane & Andrew Gelman: Verzicht auf statistische Signifikanz
3. David Colquhoun: Auch falsch-positives Risiko angeben
4. Michèle B. Nuijten: Analysepläne und Ergebnisse mitteilen
5. Steven N. Goodman: Normen von innen heraus ändern

<!--
See also: [http://daniellakens.blogspot.de/2017/12/understanding-common-misconceptions.html?m=1](http://daniellakens.blogspot.de/2017/12/understanding-common-misconceptions.html?m=1)
-->

**Selbststudium**

Lies das Paper von @JohnsonOmland2004 um mehr über das Paradigma der Modellauswahl zu erfahren.


## Literaturverzeichnis
