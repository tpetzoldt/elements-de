---
title: "12-Multivariate methods II"
author: "Thomas Petzoldt"
date:   "`r Sys.Date()`"
---

```{r setup, include=FALSE}
## this code chunk sets some technical details, it is not shown to the user
library("readxl")
library("vegan")
library("knitr")
library("kableExtra")
library("leaflet")
library("rgl")
library("scatterplot3d")
library("ggplot2")
library("tidyr")
knitr::opts_chunk$set(echo = TRUE, eval=TRUE)
setupKnitr(autoprint = FALSE) # for embedded RGL graphics
```

## Data sets and terms of use

<br>

1. The "UBA-lakes" data set originates from the public data repository of the German 
Umweltbundesamt [@UBA2020]. The data set provided can be used freely according
to the [terms and conditions](https://www.umweltbundesamt.de/datenschutz-haftung#c-urheber-und-kennzeichenrecht) 
published at the [UBA web site](https://www.umweltbundesamt.de/), that refer to
§ 12a EGovG with respect of the data, and to the [Creative Commons CC-BY ND International License 4.0 ](https://creativecommons.org/licenses/by-nd/4.0/deed.de) with respect to other objects directly created by UBA.


2. The "gauernitz" data set contains simplified teaching versions from research data, of the study from @winkelmann_fish_2011

3. The document itself, the codes and the ebedded images are own work and can be shared according to [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/deed.en).



## A Taxonomic Table

<small>
```{r echo=FALSE}
benthos <- read.csv("../data/gauernitz.csv") 
kable(benthos[-(2:4)])
```
</small>

* Aggregated part of taxa list from two small streams.
* Mayfly splitted in most dominant taxa (*Baetis* and *Heptageniidae*) and the 
remaining *Ephemeroptera* for simplicity of the teaching example.

## Bar chart


<!-- use local data -->
```{r gau-barchart, echo=FALSE, fig.height=4, fig.width=12}
benthos <- read.csv("../data/gauernitz.csv")

benthos_long <-
  benthos |>
  pivot_longer(cols=5:17, names_to="Taxon", values_to = "Abundance")

ggplot(benthos_long, aes(x=Site, y=Abundance, fill=Taxon)) + geom_col()
```


```{r, echo=TRUE, eval=FALSE}
library("ggplot2")
library("tidyr")

benthos <- read.csv("https://tpetzoldt.github.io/datasets/data/gauernitz.csv")

benthos_long <-
  benthos |>
  pivot_longer(cols=5:17, names_to="Taxon", values_to = "Abundance")

ggplot(benthos_long, aes(x=Site, y=Abundance, fill=Taxon)) + geom_col()
```


## How to analyse this kind of data?

<br>

**Different approaches**

1. Direct interpretation
    - raw data, mean values, ...
    - tables and plots

2. Calculation of biodiversity indices
    - general-purpose indices (Richness, Simpson, Shannon, Eveness)
    - domain-specific indices (in stream ecology: sapropbic index, Perlodes, EPT)


3. Multivariate statistics
    - ordination methods (CCA, NMDS, dbRDA)
    - cluster analysis


## Diversity indices

<hr></hr>

:::{.column width="44%" .add-space}
**Simpson index**

$$
D = \sum_{i=1}^S p_i^2
$$

* $p_i$: relative abundance of species
* in most cases, Simpson index is given as $\tilde{D} = 1 - D$<br>
  [(large values -- high diversity)]{.gray}
* also possible: inverse Simpson index: $D' = 1 / D$<br> 

:::

:::{.column width="48%"}

**Shannon index**

$$
H = -\sum_{i=1}^S p_i \log_b p_i
$$
  
  * in most cases log base $b=e$ (natural log), some prefer $b=2$ (information theory)
  
  
  **Eveness **
  
  $$
  E = \frac{H}{\log(S)}
  $$
  
* $S$: number of species

:::

<hr></hr>

* more indices: species richness, species deficit, Fisher's $\alpha$ ...

## Diversity indices

:::{.column width="20%"}
:::

:::{.column width="60%"}
<small>
```{r echo=FALSE}
library("vegan")
species <- benthos[c("Mollusca", "Diptera", "Baetis", "Plecoptera", 
                     "Coleoptera", "Turbellaria", "Heptageniidae",
                     "Ephemeroptera", "Gammarus", "Trichoptera", 
                     "Acari", "Nematoda", "Oligochaeta")]
div <- data.frame(
  shannon = diversity(species, index="shannon"),
  simpson = diversity(species, index="simpson"),
  invsimpson = diversity(species, index="invsimpson"),
  eveness = diversity(species, index="shannon") / log(ncol(species)),
  fisher_alpha = fisher.alpha(species)
)
div <- lapply(div, round, 2)
kable(cbind(benthos[c("Site", "Habitat", "Stream", "Flood")], div))
```
</small>
:::

* aggregated data but which of the indices tells what?
* $\rightarrow$ information loss compared to the original list



## Problem

<br>

**The PCA does not work well for this kind of data**

* Without standardization: most frequent taxa dominate the analysis, rare species under-represented

* With standardization: rare species will given too much influence, result dominates much on sampling error

* square root transformation does not help, log-transformation is not possible because of zeros


**Why?**

* the distance measure, used in PCA is the so-called [Euclidean]{.red} distance
* it works not well for species lists

**Approach**

$\rightarrow$ methods that support other distance and dissimilarity measures


# Distance and similarity

## Euclidean distance

<br>

```{r triangle-euclidean, echo=FALSE, fig.align='center'}
par(mar=c(4,4,1,1)+.1)
plot(NULL, xlim=c(0,10), ylim=c(0,10), las=1, type="n", xlab="x", ylab="y")

x <- c(2, 8)
y <- c(1, 7)
points(x, y, pch=16, cex=2, type="b", lwd=2)
text(x, y + 0.2, c("A", "B"), cex=2, pos=3)
lines(c(x, x[2]), c(y[1], y[1], y[2]))
text(mean(x), y[1], "b", pos=1, cex=2)
text(x[2], mean(y), "a", pos=4, cex=2)
text(mean(x), mean(y), "c", pos=3, cex=2)
```


* PCA works with Euclidean distance
* Theorem of Pythagoras

$$
a^2 + b^2 = c^2 \quad \Rightarrow\quad c = \sqrt{a^2 + b^2} = \sqrt{\Delta x^2 + \Delta y^2}
$$

$\rightarrow$ but: Euclidean distance is not always the best option.

## Distance and dissimilarity

<br>

**Axiomatic definition**

Measure of distance $d$ between multidimensional points $x_i$ and $x_j$:


1. $d(x_i, x_j) \ge 0$, distances are similar or equal to zero
2. $d(x_i, x_j)=d(x_j,x_i)$, the distance  from A to B is the
    same as from B to A,
3. $d(x_i, x_i)=0$, the distance from a given point to itself is zero

A distance measure is termed metric, if:

1. $d=0$ applies in the case of equality  only, and
2. the triangle inequality applies.<br>
  [The indirect route is longer than the direct route]{.gray}

If one or both of the additional conditions are violated, we speak about **nonmetric**
measures and use the term **dissimilarity** instead of distance.

## Similarity

<br>

A measure of similarity $s$ can be defined in a similar way:


1. $s(x_i,x_j) \le s_{max}$
2. $s(x_i,x_j)=s(x_j,x_i)$
3. $s(x_i,x_i)=s_{max}$

it is metric, if:

* $s_{max}$ applies only in the case of equality and
* the triangle inequality applies


## Conversion between dissimilarity and similarity


<br>


<br>

:::{.bigfont}

| similarity     |  dissimilarity        |
|----------------|-----------------------|
| $s=1-d/d_{max}$| $d=1-s/s_{max}$       |
| $s=\exp(-d)$   | $d= - \ln(s-s_{min})$ |

:::

<br>

* distance goes from $0$ to $\infty$
* different transformations, as long as the $\Rightarrow$ transformation is monotonic
* in most cases similarity $s$ is limited between $(0, 1)$ or between 0 and 100%.



## Common distance and dissimilarity measures

<br>

<br>

* **Euclidean** distance: shortest connection between 2 points in space
* **Manhattan** distance: around the corner, as in Manhattans grid-like streets
* **Chi-square** distance: for comparison of frequencies
* **Mahalanobis** distance: takes covariance into account
* **Bray-Curtis** dissimilarity: comparison of species lists in ecology
* **Jaccard** index: for binary (presence-absence) data
* **Gower** dissimilarity:  used for mixed-type variables


## Distance and dissimilarity of **metric** variables

<br>


Euclidean distance:

$$
d_{jk} = \sqrt{\sum (x_{ij}-x_{ik})^2}
$$

Manhattan distance:
$$
d_{jk} = \sum |x_{ij}-x_{ik}|
$$


Gower distance:
$$
d_{jk} = \frac{1}{M} \sum\frac{|x_{ij}-x_{ik}|}{\max(x_i)-\min(x_i)}
$$


Bray-Curtis dissimilarity:
$$
d_{jk} = \frac{\sum{|x_{ij}-x_{ik}|}}{\sum{(x_{ij}+x_{ik})}}
$$

* with $x_{ij}, x_{ik}$ abundance of species  $i$ at sites ($j, k$).

## Distance and dissimilarity of binary variables

<br>

* Euclidean: $\sqrt{A+B-2J}$
* Manhattan: $A+B-2J$
* Gower: $\frac{A+B-2J}{M}$
* Bray-Curtis: $\frac{A+B-2J}{A+B}$
* Jaccard: $\frac{2b}{1+b}$ with $b$ = Bray-Curtis dissimilarity


where:

* $A, B$ = numbers of species on compared sites
* $J$ =  (joint) is the number of species that occur on both compared sites
* $M$ =  number of columns (excluding missing values)

<br>

**Applications**

Additional distance measures and application suggestions in
the  [`vegdist`](https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/vegdist) help page.

## Which distances are supported by different methods?

<br>

:::{.smallfont}

|         |                                    |  Matrices     |  Distance |  R function         |
|---------|------------------------------------|---------------|-----------|---------------------|
| PCA     | Principal Components Analysis      | one matrix    | euclidean | `prcomp`, `rda`     |
| RDA     | Redundancy Analysis                | two matices   | euclidean | `rda`               |
| CA      | Correspondence Analysis            | one matrix    | chi square| `cca`               |
| CCA     | Canonical Correspondence Analysis  | two matrices  | chi square| `cca`               |
| PCO/MDS | Principal Correspondence Analysis  | one matrix    | any       | `cmdscale`, ...     |
| dbRDA   | distance-based Redundancy Analysis | two matrices  | any       | `dbrda`, `capscale` |
| PCoA    | Principal Coordinate Analysis      | two matrices  | any       | `wcmdscale`         |
| NMDS    | Non-metric Multidimensional Scaling| one matrix    | any       | `metaMDS`           |
|...      | ...                                |...            |...        | ...                 |
|         |  Cluster analysis                  | one matrix    | any       | several packages    |
|         |                                    |               |           |                     |

<small><br></small>

* many different methods, not all are shown
* one matrix methods: all variables depend on each other; optional matrix of explanation variables can be projected afterwards
* two matrix methods (= constrained methods): additional matrix of explanation variables, both matrices handled simultanaeously
* an additional third matrix is supported by so-called partial methods, e.g. pRDA, pCCA, pdbRDA

:::

## Principal coordinate analysis (PCO)

:::{.column width="54%" .add-space}

<br>

```{r}
library("vegan")
benthos <- read.csv("../data/gauernitz.csv")
row.names(benthos) <- benthos$Site
species <- benthos[-c(1:4)]

d   <- vegdist(species, method="bray")
ord <- cmdscale(d)
```
```{r gauernitz-mds, eval=FALSE}
plot(ord, type="n", xlab="PCO 1", ylab="PCO 2")
text(ord, row.names(species))
```

[$\rightarrow$]{.red} distance matrix (`d`) used as input<br>
and not data matrix (`species`) directly
:::

:::{.column width="39%"}
```{r gauernitz-mds, echo=FALSE, fig.width=6, fig.height=6}
```
:::


* works with arbitrary distance measures, e.g. Bray-Curtis dissimilarity
* supported by different packages, e.g. **stats**, **vegan**, **labdsv**, **ecodist**, **ade4** and **ape**
* basic version in package **stats** (base R), other packages with more specialized versions
* basic version has no biplot, can be added separately


## Single matrix methods I

<br>

**PCA:** Principal Components analysis

▶ input: raw data, covariance or correlation matrix

(+) basic method, very easy to understand

(+) biplot: common representation of objects and variables

(--) only Euclidean distance, not suitable for taxa lists

<small><br></small>

**CA:** Correspondence analysis

▶ input: raw data (frequencies)

(+) similar to PCA, but uses $\chi^2$ distance

(+) better for taxa lists


<small><br></small>

**PCO:** Principal Coordinates Analysis ([*metric* MDS]{.gray})

▶ input: distance matrix

(+) any distance measure can be used


## Single matrix methods II: NMDS
<br>

* non-metric multidimensional scaling
* is an extension of the PCO (=MDS)
* $\rightarrow$ attempts to bring similarity structure better into 2 (or 3) dimensions
* iterative procedure, minimize goodness of fit (called "stress")
* several variants, mostly algorithm according to Kruskal

▶ input: random configuration or PCO

(+) popular, relatively easy to interpret

(+/-) geometric distortion

(--) results not always identical

(--) computer intensive, especially for large data sets

<br>

**Note** 

* stress is sometimes given as ratio 0...1, sometimes in 0...100%
* differences between packages and statistics programs, e.g. SPSS


## Example

```{r}
benthos <- read.csv("../data/gauernitz.csv")
row.names(benthos) <- benthos$Site
env <- benthos[c("Habitat", "Stream", "Flood")] # required later

bio <- benthos[c("Mollusca", "Diptera", "Baetis", "Plecoptera", "Coleoptera", 
         "Turbellaria", "Heptageniidae", "Ephemeroptera", "Gammarus", 
         "Trichoptera", "Acari", "Nematoda", "Oligochaeta")]

ord <- metaMDS(bio)
```
## Results of the NMDS

```{r}
ord
```

* `metaMDS` runs a series of NMDS trials and outputs the best
* makes automatic decisions about transformation, distance and scaling

**Recommendation**

* specify distance, scaling and transformation explicitly 
* consider to increase `try` and `trymax` for big and/or difficult data sets, e.g.:

```{r, eval=FALSE}
ord <- metaMDS(bio, distance="bray", autotransform=FALSE, try=40)
```

```{r, echo=FALSE}
ord <- metaMDS(bio, distance="bray", autotransform=FALSE, try=40, trace = FALSE)
```

## NMDS Plot

```{r gau-nmds, fig.width=5, fig.height=5, fig.align='center'}
plot(ord, type="text")
abline(h=0, lty="dashed", col="gray")
abline(v=0, lty="dashed", col="gray")
mtext(paste("Stress=", round(ord$stress,2)), side=3)
```


## Stress

<br>

Compares similarity of the ordination with original dissimilarity in all dimensions.

<br>

::: {.column width="39%"}

* $\theta(d_{ij})$: observed dissimilarity
* $\tilde{d}_{ij}$: ordination dissimilarity

$$
S = \sqrt{\frac{\sum_{i \ne j} (\theta(d_{ij}) - \tilde{d}_{ij})^2}{\sum_{i \ne j}  \tilde{d}_{ij}^2}}
$$

:::

::: {.column width="39%"}

| Quality of ordination | Stress |
|-----------------------|--------|
| poor                  | > 0.2  |
| sufficient            | < 0.1  |
| good                  | <0.05  |
| excellent             | <0.025 |
| perfect               | 0.0    |
|                       |        |

:::


## Stressplot (Shepherd plot)


```{r stressplot1, fig.align='center'}
stressplot(ord)
mtext(paste("Stress =", round(ord$stress,2)), side=3)
```

## Stressplot: a good and a poor example

<br>

:::{.column width="47%" .add-space}
**Good**
```{r stressplot2, echo=FALSE, fig.width=4, fig.height=4}
stressplot(ord, pch=16)
mtext(paste("Stress =", round(ord$stress,2)), side=3)
```
:::

:::{.column width="47%"}
**Poor**
```{r stressplot3, echo=FALSE, fig.width=4, fig.height=4}
set.seed(123)
rdat <- matrix(runif(100), nrow=20)
ord2  <- metaMDS(rdat, distance = "euclid", autotransform=FALSE, trace=FALSE)
stressplot(ord2, pch=16)
mtext(paste("Stress =", round(ord2$stress,2)), side=3)
```
:::


* [Points should be close to the red line.]{.red}
* Pattern of stairs not important (at least not for now)
* The $R^2$ values are always big, ignore or at least don't overinterpret it.



## Environmental fitting

```{r envfit, fig.align='center'}
ord <- metaMDS(bio, trace = FALSE) # trace: show or suppress intermediate output
ef <- envfit(ord, env, permu = 1000)
plot(ord, type = "t")
plot(ef, p.max = 0.1)
```

* Plots arrows if explanation variables are metric.
* Shows only centroids for ordinal explanation variables.

## Numerical results and p-values

```{r}
ef
```
<br>

* p-values are based on a permutation test
* useful, but the ADONIS test is better

## Another example data set from the vegan package

```{r vare-envfit, fig.align='center'}
data(varechem); data(varespec)
mds <- metaMDS(varespec, trace=FALSE)
ef <- envfit(mds, varechem, permu=1000)
plot(mds, type="t")
plot(ef, p.max =0.1)
```

Data from @vare_effects_1995


## The data set

<br>

**varespec**: 24 observations of 44 variables (plant species)

```{r echo=FALSE}
names(varespec)
```

<br>

**varechem**: 24 observations of 16 variables


```{r, echo=FALSE}
names(varechem)
```

<br>

Data from @vare_effects_1995 about influence of reindeer grazin gon understorey 
vegetation in *Pinus sylvestris* forests in eastern Fennoscandia.

## Surface fitting

```{r vare-surf, fig.align='center', echo=FALSE}
ef <- envfit(mds ~ Al + Ca, varechem, permu=1000)
plot(mds, display="sites", type="text")
plot(ef)
invisible(with(varechem, ordisurf(mds, Al, add=TRUE)))
invisible(with(varechem, ordisurf(mds, Ca, add=TRUE, col="green4")))
```


```{r vare-surf2, fig.align='center', eval=FALSE}
ef <- envfit(mds ~ Al + Ca, varechem, permu = 1000)
plot(mds, display = "sites", type = "text")
plot(ef)
with(varechem, ordisurf(mds, Al, add = TRUE))
with(varechem, ordisurf(mds, Ca, add = TRUE, col = "green4"))
```

## Pros and cons of the methods discussed so far

<br>

**PCA** (and also **CCA**)

(+) easy to understand, quick and reproducible

(+) no non-linear distortion

(--) but: horseshoe effect possible

(--) information is often still in a "higher dimension"

(--) Euclidean distance poorly suited for species lists

**NMDS**

(+) any distance measure can be used

(+) better mapping on low dimensions

(--) bias

(--) numerical effort, iterative method, local minima

(--) one-matrix method (no separate matrices for species and environmental factors)


## Problems of CA (and  PCA)

:::{.column width="44%" .add-space}
* arc (CA) or horseshoe effect (PCA)

```{r, echo=FALSE}
tridi <- function(k) {
  x <- matrix(0, nrow=k+2, ncol=k)
  diag(x) <- 1
  x2 <- x
  x2[2:(k+1), ] <- x2[2:(k+1), ] + x[1:k, ]
  x2[3:(k+2), ] <- x2[3:(k+2), ] + x[1:k, ]
  t(x2)
}
x <- tridi(10)
kable(x)
```


:::

:::{.column width=44%}

```{r horseshoe, fig.width=4, fig.height=4, echo=FALSE}
par(mar=c(4,4,1,1))
cc <- cca(x)
plot(cc)
```

:::

**Workaround**

- detrended correspondence analysis (DCA) used in the past, not anymore recommended (except you know what you do)
- better: NMDS or a "constrained" (2-matrix) method, e.g. CCA, RDA, dbRDA)


# Two matrix methods

![](../img/multivar-two-matrix.svg){fig-align='center'}



- taxa matrix ([bio]{.blue}): dependend variables, in ecology typically species
- environmental matrix ([env]{.blue}): explanation variables, also called [constraints]{.blue}

* **Single matrix methods:** ordination of species table alone, environmental variables considered afterwards
* **Two matrix methods:** Species table and environmental variables treated **simultanaeously**


**Many to many relationship**
     
$$\mathbf{Y} = f(\mathbf{X})$$


## CCA: Canonical Correspondence Analysis

**Example Gauernitzbach-data**

```{r}
ord <- cca(bio ~ ., data = env) # ~ . is an abbreviation for all variables in env
ord
```


* [**inertia**]{.blue} measures error and information (similar to variance)
    - allows separation of variability into information and error
    - in case of CCA it is $\chi^2$ distance, in case of RDA it is variance
* in the example
    - 61% is explained by the constrained axes Habitat, Stream and Flood
    - 39% is not explained by the provided environmental variables

## Triplot


```{r gau-cca, fig.width=6, fig.height=6, fig.align='center'}
plot(ord)
```

**Important** 

* The plot shows only the part of variation that is explained by the constraints.
* It the number of constraints is high compared to the number of observations, 
the ordination shows again the full variation, i.e. becomes unconstrained.



## Interpretation of the CCA


```{r gau-cca, echo=FALSE, fig.width=6, fig.height=6, fig.align='center'}
```


* triplot with observations, species and environmental factors, note different scaling!
    - distance from the origin: $\chi^2$
    - species in the middle: either "average species" or poorly explained species
    - species at the very edge: attention, often rare species
- orthogonal angle of species on connecting line origin - centroid of environmental factor


## Statistical significance: ANOVA like permutation test

<br>

```{r}
anova(ord, by = "terms")
```

* `anova(ord, by="axis")` tests significance of the CCA axes and 
`anova(ord, by="margin")` the marginal effects of the terms.
* can also be called via `permutest`

## ADONIS test

```{r}
adonis2(bio ~ Habitat * Stream * Flood, data = env, method = "bray")
```

* Analysis of variance using distance matrices, uses a permutation test with pseudo-F ratios.
* Not directly related to CCA, RDA etc. 
* Can use all dissimilarity measures from the `vegdist`function.
* More powerful that the permutest-ANOVA, as it can handle interaction effects.

## RDA and dbRDA

**RDA:** redundancy analysis

* is the two-matrix extension of the PCA
* uses Euclidean distance for the dependent variables
* very useful, if the dependent matrix ("bio") contains physical and chemical variables, e.g. temperature, nutrients, or aggregated biological data like total biomass or chlorophyll and not abundances of different species

**dbRDA** distance-based RDA / constrained PCoA (Principal Coordinates Analysis)

* extends RDA to use arbitrary distance measures like Bray-Curtis for the dependent matrix (bio)
* sometimes more difficult to apply than CCA and RDA because of negative eigenvalues
* very useful for taxa lists, more flexible than CCA
* works in principle also with Euclidean distance, but is less efficient


## Example dbRDA with the Gauernitz data

```{r echo=TRUE, eval=FALSE}
ord <- dbrda(bio ~ ., data = env, method="bray")
ord
plot(ord)
anova(ord, by="terms")
```

*   `~ .` is an abbreviation for all variables in env
* also possible `dbrda(bio ~ Stream + Flood + Habitat, data=env)`
* similar interpretation like CCA
* RDA with Euclidean distance can, for example, be applied to the UBA-Lakes dada set

## Partial Analyses: pRDA, pCCA, p-dbRDA

* split constraints into covariates and 
* can be used to remove the effect of covariates (e.g. conditioning, background or random variables)

**Example**

We know that pools and riffles are different and that the two streams differ somewhat, so we handle this as covariates

```{r}
ord <- cca(bio ~ Flood + Condition(Habitat, Stream), data = env)
ord
```

So the inertia is splitted in three components, Conditional (the covariates), 
Constrained (flood) and Unconstrained.

The plot shows then the effect of the flood more clearly.


## Which ordination method to start with?

<br>

Multivariate statistics is a very broad field. 
Experience shows that it can become quite complex and challenging, but also that it is relatively easy to start with it.

<br>

**My personal recommendation**

1. Start with **PCA** if working with physical, chemical and hydromorphological data. It often also works well with aggregated biomass data.
2. Use RDA if you have additional explanation variables (two-matrix method)
3. Start with NMDS if working with abundance data of species (taxa lists)
4. Use NMDS with `envfit` to explore influence of explanation variables on the ordination.
5. use CCA, dbRDA or PCoA to get more quantitative results, compared to NMDS.




# Cluster Analysis


## Overview

<br>

* Cluster analysis aims to group data sets in clusters

* Hierarchical clustering
  - build a dendrogram (a tree of grouping)
  - agglomerative methods
  - divisive methods

* Different agglomeration methods
  - define how distance is measured between clusters

* Nonhierarchical clustering
   - split into a given number of groups
   - usually no dendrogram
   - iterative methods
   - e.g. k-means, k-centroids
   
   
## The UBA lake data set again

```{r echo = FALSE}
lakes <- read.csv(file="../data/uba/lakes-combined-data.csv")
valid_columns <- c(
  "name", "shortname",
  #"drainage", 
  #"population", 
  #"altitude", 
  "z_mean",
  "z_max", 
  "t_ret", 
  "volume", 
  "area", 
  #"shore_length", 
  #"shore_devel", 
  #"drain_ratio", 
  "p_tot", 
  "n_no3", 
  "chl",
  "wfd_type"
)

## less columns, so that we get a simplified subset and more complete cases
lakes <- lakes[valid_columns] |> na.omit()
row.names(lakes) <- lakes$shortname

lakes_saved <- lakes # backup copy of the data set for later use

lake_ids <- lakes[c("name", "shortname")]
lakedata <- lakes[, -c(1, 2)]
lakedata$wfd_type <- NULL
lakedata2 <- sqrt(lakedata)
```

<small>
```{r echo=FALSE}
kable(lakedata)
```

</small>

## Cluster analysis

```{r lakes-cluster2 , fig.height=6, wig.width=12, fig.align='center'}
par(mfrow=c(1,2))
hc <- hclust(dist(scale(lakedata2)), method="complete") # the default
plot(hc)

hc2 <- hclust(dist(scale(lakedata2)), method="ward.D2")
plot(hc2)
```

## Identification of clusters in the tree

```{r lake-clusters2}
plot(hc, hang = -1)    # -1: extend vertical lines to the bottom
rect.hclust(hc, 5)
grp <- cutree(hc, 5)
# grp                  # can be used to show the groups
```

## Color NMDS according to clusters

```{r uba-nmds, fig.align='center', fig.width=5, fig.height=5}
md <- metaMDS(lakedata2, scale = TRUE, distance = "euclid", trace=FALSE)
```

```{r lake-nmds-colored}
plot(md, type = "n")
text(md$points, row.names(lakedata2), col = grp)
```


## Non-hierarchical clustering

<br>

* e.g. k-means clustering
* an iterative method
* avoids the problem that cluster assignment depends on the order of clustering and the agglomeration method

**Disadvantages, depending on the question**

* number of clusters needs to be specified beforehand (e.g. from hierarchical clustering)
* no dendrogramm

```{r}
cl <- kmeans(scale(log(lakedata)), centers = 5)
cl$cluster
```

## Scatterplot of data and clusters

```{r kmeans-scatter}
plot(log(lakedata), col = cl$cluster, pch=16)
```


## Further reading

<br>

 

* @oksanen_multivariate_2015 Multivariate analysis of ecological communities in R: Vegan tutorial. 
* Borcard, D., Gillet, F., & Legendre, P. [-@borcard_numerical_2018] Numerical ecology with R. Springer International Publishing. [https://doi.org/10.1007/978-3-319-71404-2](https://doi.org/10.1007/978-3-319-71404-2)





 
## References

<br>

